\documentclass[11pt]{article}
\usepackage[margin=0.8in]{geometry}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{array}

\title{Paper Coding Instructions}
\date{}

\begin{document}
\maketitle

\section{Artifact Selection Criteria}

Papers are selected based on adoption by the following artifacts:

\subsection{Tools (Criterion: $\geq$1,000 GitHub stars)}

\begin{tabular}{p{4cm}p{2cm}p{6cm}}
\toprule
\textbf{Tool} & \textbf{Stars} & \textbf{Description} \\
\midrule
CleverHans & 6,401 & Adversarial example library (Toronto) \\
IBM ART & 5,789 & Adversarial Robustness Toolbox \\
TextAttack & 3,348 & NLP adversarial attacks \\
PyRIT & 3,343 & LLM red-teaming (Microsoft) \\
Foolbox & 2,936 & Adversarial attacks (Bethge Lab) \\
\bottomrule
\end{tabular}

\subsection{Benchmarks (Criterion: Peer-reviewed publication)}

\begin{tabular}{p{4cm}p{3cm}p{5cm}}
\toprule
\textbf{Benchmark} & \textbf{Venue} & \textbf{Description} \\
\midrule
RobustBench & NeurIPS 2021 & Adversarial robustness leaderboard \\
AutoAttack & ICML 2020 & Standardized attack evaluation \\
HarmBench & ICML 2024 & LLM jailbreak evaluation \\
\bottomrule
\end{tabular}

\subsection{Regulatory (Criterion: Industry threat framework)}

\begin{tabular}{p{4cm}p{6cm}}
\toprule
\textbf{Framework} & \textbf{Description} \\
\midrule
MITRE ATLAS & Adversarial ML tactics/techniques (like ATT\&CK) \\
\bottomrule
\end{tabular}

\section{Paper Selection Criteria}

\textbf{71 papers selected for coding:}
\begin{enumerate}
    \item \textbf{61 papers} cited by 2+ artifacts (strongest adoption evidence)
    \item \textbf{10 papers} from MITRE ATLAS only (regulatory adoption)
\end{enumerate}

\section{The 12 Coding Columns}

\subsection{Group 1: Basic Info (G1--G7)}

\begin{longtable}{p{1cm}p{3.5cm}p{3.5cm}p{4.5cm}}
\toprule
\textbf{Col} & \textbf{Question} & \textbf{Options} & \textbf{How to Decide} \\
\midrule
\endhead
G1 & Is this an attack, defense, or evaluation? & Attack / Defense / Evaluation & Read abstract. What did they build? \\
\midrule
G2 & What type of attack? & Evasion / Poisoning / Privacy / N/A & \textbf{Evasion} = fool model at test time. \textbf{Poisoning} = corrupt training data. \textbf{Privacy} = steal data/model. \textbf{N/A} = defense papers \\
\midrule
G3 & What domain? & Vision / NLP / Malware / Audio / Tabular / LLM / Cross-domain & What data did they test on? ImageNet = Vision. Text = NLP. ChatGPT = LLM. \\
\midrule
G4 & Where published? & ML / Security / Journal / arXiv-only & \textbf{ML} = NeurIPS, ICML, ICLR, CVPR, ACL. \textbf{Security} = S\&P, CCS, USENIX, NDSS. \\
\midrule
G5 & Is code available NOW? & Yes / No & Google ``paper name github''. Is there code? \\
\midrule
G6 & When was code released? & At-pub / Post-pub / Never & \textbf{At-pub} = within 1 month of paper. \textbf{Post-pub} = later. \\
\midrule
G7 & Publication year & 2014--2025 & Year of first public version \\
\bottomrule
\end{longtable}

\subsection{Group 2: Threat Model (T1--T2) --- Attack Papers Only}

\begin{tabular}{p{1cm}p{3.5cm}p{3cm}p{5cm}}
\toprule
\textbf{Col} & \textbf{Question} & \textbf{Options} & \textbf{How to Decide} \\
\midrule
T1 & How much model access? & White / Gray / Black & \textbf{White} = has weights/gradients. \textbf{Gray} = surrogate model. \textbf{Black} = queries only \\
\midrule
T2 & Uses gradients? & Yes / No & If they compute $\nabla L$ anywhere, it's Yes \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Leave T1 and T2 blank for defense papers.}

\subsection{Group 3: Practical Evaluation (Q1--Q3)}

\begin{tabular}{p{1cm}p{3.5cm}p{3cm}p{5cm}}
\toprule
\textbf{Col} & \textbf{Question} & \textbf{Options} & \textbf{How to Decide} \\
\midrule
Q1 & Tested on real system? & Yes / Partial / No & \textbf{Yes} = Google API, Tesla, ChatGPT. \textbf{Partial} = realistic sim. \textbf{No} = CIFAR/ImageNet only \\
\midrule
Q2 & Reported cost? & Yes / No & Did they say ``X queries'' or ``Y seconds''? \\
\midrule
Q3 & Tested against defenses? & Yes / No / N/A & \textbf{Yes} = tested vs.\ adversarial training. \textbf{N/A} = for defense papers \\
\bottomrule
\end{tabular}

\section{Pre-filled Columns (Auto-extracted)}

The following columns are already filled:

\begin{tabular}{p{4cm}p{8cm}}
\toprule
\textbf{Column} & \textbf{Description} \\
\midrule
selection\_reason & Why paper was selected (2+ artifacts / MITRE ATLAS) \\
is\_aml\_paper & Always YES for this dataset \\
arxiv\_id & arXiv identifier \\
found\_in\_artifacts & Which artifacts cite this paper \\
num\_artifacts & How many artifacts cite it \\
paper\_title & Full paper title \\
paper\_authors & Author names \\
paper\_pub\_date & Publication date (YYYY-MM-DD) \\
first\_adoption\_date & When first artifact added it \\
first\_adoption\_artifact & Which artifact adopted first \\
all\_adoptions & All adoption events (artifact:date pairs) \\
adoption\_lag\_months & Months from paper to first adoption \\
\bottomrule
\end{tabular}

\section{Your Workflow}

\begin{enumerate}
    \item Open \texttt{extraction\_runs/run1/papers\_for\_coding\_71.csv}
    \item For each paper, fill in: G1, G2, G3, G4, G5, G6, G7, T1, T2, Q1, Q2, Q3
    \item Use arXiv link to read the paper: \texttt{https://arxiv.org/abs/[arxiv\_id]}
    \item Estimated time: 20--30 minutes per paper
\end{enumerate}

\section{Files}

All files are in \texttt{extraction\_runs/run1/}:

\begin{tabular}{p{5cm}p{7cm}}
\toprule
\textbf{File} & \textbf{Purpose} \\
\midrule
papers\_for\_coding\_71.csv & 71 papers for manual coding \\
papers\_all.csv & Full 277 AML papers (for statistics) \\
papers\_by\_artifact.csv & Sorted by artifact (for verification) \\
\bottomrule
\end{tabular}

\end{document}
