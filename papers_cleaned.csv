is_aml_paper,arxiv_id,found_in_artifacts,paper_title,paper_authors,paper_pub_date,G1,G2,G3,G4,G5,G6,G7,T1,T2,Q1,Q2,Q3
YES,1412.6572,"CleverHans, IBM ART",Explaining and Harnessing Adversarial Examples,Ian J. Goodfellow; Jonathon Shlens; Christian Szegedy,2014-12-20,,,,,,,,,,,,
NO - Exclude,1412.6980,"CleverHans, PyRIT",Adam: A Method for Stochastic Optimization,Diederik P. Kingma; Jimmy Ba,2014-12-22,,,,,,,,,,,,
NO - Exclude,1506.02025,Foolbox,Spatial Transformer Networks,Max Jaderberg; Karen Simonyan; Andrew Zisserman; Koray Kavukcuoglu,2015-06-05,,,,,,,,,,,,
YES - Defense,1507.00677,"Foolbox, IBM ART",Distributional Smoothing with Virtual Adversarial Training,Takeru Miyato; Shin-ichi Maeda; Masanori Koyama; Ken Nakae; Shin Ishii,2015-07-02,,,,,,,,,,,,
YES,1511.04599,"Foolbox, IBM ART",DeepFool: a simple and accurate method to fool deep neural networks,Seyed-Mohsen Moosavi-Dezfooli; Alhussein Fawzi; Pascal Frossard,2015-11-14,,,,,,,,,,,,
YES,1511.05122,IBM ART,Adversarial Manipulation of Deep Representations,Sara Sabour; Yanshuai Cao; Fartash Faghri; David J. Fleet,2015-11-16,,,,,,,,,,,,
YES,1511.07528,IBM ART,The Limitations of Deep Learning in Adversarial Settings,Nicolas Papernot; Patrick McDaniel; Somesh Jha; Matt Fredrikson; Z. Berkay Celik...,2015-11-24,,,,,,,,,,,,
YES,1605.07277,IBM ART,Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,Nicolas Papernot; Patrick McDaniel; Ian Goodfellow,2016-05-24,,,,,,,,,,,,
YES,1607.02533,"Foolbox, IBM ART",Adversarial examples in the physical world,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-07-08,,,,,,,,,,,,
YES,1608.04644,"CleverHans, Foolbox, IBM ART",Towards Evaluating the Robustness of Neural Networks,Nicholas Carlini; David Wagner,2016-08-16,,,,,,,,,,,,
YES,1610.05820,IBM ART,Membership Inference Attacks against Machine Learning Models,Reza Shokri; Marco Stronati; Congzheng Song; Vitaly Shmatikov,2016-10-18,,,,,,,,,,,,
YES,1610.08401,IBM ART,Universal adversarial perturbations,Seyed-Mohsen Moosavi-Dezfooli; Alhussein Fawzi; Omar Fawzi; Pascal Frossard,2016-10-26,,,,,,,,,,,,
YES,1611.01236,"CleverHans, IBM ART",Adversarial Machine Learning at Scale,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-11-04,,,,,,,,,,,,
NO - Exclude,1611.05431,RobustBench,Aggregated Residual Transformations for Deep Neural Networks,Saining Xie; Ross Girshick; Piotr Dollár; Zhuowen Tu; Kaiming He,2016-11-16,,,,,,,,,,,,
YES,1703.06857,CleverHans,On the Limitation of Convolutional Neural Networks in Recognizing Negative Images,Hossein Hosseini; Baicen Xiao; Mayoore Jaiswal; Radha Poovendran,2017-03-20,,,,,,,,,,,,
YES,1706.06083,IBM ART,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksander Madry; Aleksandar Makelov; Ludwig Schmidt; Dimitris Tsipras; Adrian Vladu,2017-06-19,,,,,,,,,,,,
YES,1708.03999,IBM ART,ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models,Pin-Yu Chen; Huan Zhang; Yash Sharma; Jinfeng Yi; Cho-Jui Hsieh,2017-08-14,,,,,,,,,,,,
YES,1708.06733,IBM ART,BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain,Tianyu Gu; Brendan Dolan-Gavitt; Siddharth Garg,2017-08-22,,,,,,,,,,,,
YES,1709.04114,IBM ART,EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples,Pin-Yu Chen; Yash Sharma; Huan Zhang; Jinfeng Yi; Cho-Jui Hsieh,2017-09-13,,,,,,,,,,,,
YES,1710.06081,"Foolbox, IBM ART",Boosting Adversarial Attacks with Momentum,Yinpeng Dong; Fangzhou Liao; Tianyu Pang; Hang Su; Jun Zhu...,2017-10-17,,,,,,,,,,,,
YES,1710.08864,IBM ART,One pixel attack for fooling deep neural networks,Jiawei Su; Danilo Vasconcellos Vargas; Sakurai Kouichi,2017-10-24,,,,,,,,,,,,
YES,1712.02779,"Foolbox, IBM ART",Exploring the Landscape of Spatial Robustness,Logan Engstrom; Brandon Tran; Dimitris Tsipras; Ludwig Schmidt; Aleksander Madry,2017-12-07,,,,,,,,,,,,
YES,1712.04248,"Foolbox, IBM ART",Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Wieland Brendel; Jonas Rauber; Matthias Bethge,2017-12-12,,,,,,,,,,,,
YES,1712.06751,TextAttack,HotFlip: White-Box Adversarial Examples for Text Classification,Javid Ebrahimi; Anyi Rao; Daniel Lowd; Dejing Dou,2017-12-19,,,,,,,,,,,,
YES,1712.09665,IBM ART,Adversarial Patch,Tom B. Brown; Dandelion Mané; Aurko Roy; Martín Abadi; Justin Gilmer,2017-12-27,,,,,,,,,,,,
YES,1801.01944,IBM ART,Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,Nicholas Carlini; David Wagner,2018-01-05,,,,,,,,,,,,
YES,1801.04354,TextAttack,Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers,Ji Gao; Jack Lanchantin; Mary Lou Soffa; Yanjun Qi,2018-01-13,,,,,,,,,,,,
YES,1802.00420,CleverHans,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,Anish Athalye; Nicholas Carlini; David Wagner,2018-02-01,,,,,,,,,,,,
YES,1802.05666,CleverHans,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Jonathan Uesato; Brendan O'Donoghue; Aaron van den Oord; Pushmeet Kohli,2018-02-15,,,,,,,,,,,,
YES,1803.01128,TextAttack,Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples,Minhao Cheng; Jinfeng Yi; Pin-Yu Chen; Huan Zhang; Cho-Jui Hsieh,2018-03-03,,,,,,,,,,,,
YES,1804.00792,IBM ART,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks,Ali Shafahi; W. Ronny Huang; Mahyar Najibi; Octavian Suciu; Christoph Studer...,2018-04-03,,,,,,,,,,,,
YES,1804.07781,TextAttack,Pathologies of Neural Models Make Interpretations Difficult,Shi Feng; Eric Wallace; Alvin Grissom; Mohit Iyyer; Pedro Rodriguez...,2018-04-20,,,,,,,,,,,,
YES,1804.07998,TextAttack,Generating Natural Language Adversarial Examples,Moustafa Alzantot; Yash Sharma; Ahmed Elgohary; Bo-Jhang Ho; Mani Srivastava...,2018-04-21,,,,,,,,,,,,
YES,1805.09190,Foolbox,Towards the first adversarially robust neural network model on MNIST,Lukas Schott; Jonas Rauber; Matthias Bethge; Wieland Brendel,2018-05-23,,,,,,,,,,,,
YES,1805.11090,Foolbox,GenAttack: Practical Black-box Attacks with Gradient-Free Optimization,Moustafa Alzantot; Yash Sharma; Supriyo Chakraborty; Huan Zhang; Cho-Jui Hsieh...,2018-05-28,,,,,,,,,,,,
YES,1806.02299,IBM ART,DPatch: An Adversarial Patch Attack on Object Detectors,Xin Liu; Huanrui Yang; Ziwei Liu; Linghao Song; Hai Li...,2018-06-05,,,,,,,,,,,,
YES,1806.05476,IBM ART,Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data,Jacson Rodrigues Correia-Silva; Rodrigo F. Berriel; Claudine Badue; Alberto F. de Souza; Thiago Oliveira-Santos,2018-06-14,,,,,,,,,,,,
YES,1810.08280,IBM ART,Exploring Adversarial Examples in Malware Detection,Octavian Suciu; Scott E. Coull; Jeffrey Johns,2018-10-18,,,,,,,,,,,,
YES,1811.09600,Foolbox,Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses,Jérôme Rony; Luiz G. Hafemann; Luiz S. Oliveira; Ismail Ben Ayed; Robert Sabourin...,2018-11-23,,,,,,,,,,,,
YES,1811.11875,IBM ART,Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers,Nathan Inkawhich; Matthew Inkawhich; Yiran Chen; Hai Li,2018-11-28,,,,,,,,,,,,
YES,1812.02606,IBM ART,The Limitations of Model Uncertainty in Adversarial Settings,Kathrin Grosse; David Pfaff; Michael Thomas Smith; Michael Backes,2018-12-06,,,,,,,,,,,,
YES,1812.02766,IBM ART,Knockoff Nets: Stealing Functionality of Black-Box Models,Tribhuvanesh Orekondy; Bernt Schiele; Mario Fritz,2018-12-06,,,,,,,,,,,,
YES,1812.05271,TextAttack,TextBugger: Generating Adversarial Text Against Real-world Applications,Jinfeng Li; Shouling Ji; Tianyu Du; Bo Li; Ting Wang,2018-12-13,,,,,,,,,,,,
YES,1901.03583,IBM ART,Explaining Vulnerabilities of Deep Learning to Adversarial Malware Binaries,Luca Demetrio; Battista Biggio; Giovanni Lagorio; Fabio Roli; Alessandro Armando,2019-01-11,,,,,,,,,,,,
YES,1902.07906,IBM ART,Wasserstein Adversarial Examples via Projected Sinkhorn Iterations,Eric Wong; Frank R. Schmidt; J. Zico Kolter,2019-02-21,,,,,,,,,,,,
YES,1903.10346,IBM ART,"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition",Yao Qin; Nicholas Carlini; Ian Goodfellow; Garrison Cottrell; Colin Raffel,2019-03-22,,,,,,,,,,,,
YES,1904.02144,"CleverHans, Foolbox, IBM ART",HopSkipJumpAttack: A Query-Efficient Decision-Based Attack,Jianbo Chen; Michael I. Jordan; Martin J. Wainwright,2019-04-03,,,,,,,,,,,,
YES,1904.11042,IBM ART,Physical Adversarial Textures that Fool Visual Object Tracking,Rey Reza Wiyatno; Anqi Xu,2019-04-24,,,,,,,,,,,,
YES,1904.13000,Foolbox,Adversarial Training and Robustness for Multiple Perturbations,Florian Tramèr; Dan Boneh,2019-04-30,,,,,,,,,,,,
YES,1905.07121,IBM ART,Simple Black-box Adversarial Attacks,Chuan Guo; Jacob R. Gardner; Yurong You; Andrew Gordon Wilson; Kilian Q. Weinberger,2019-05-17,,,,,,,,,,,,
YES - Defense,1905.11268,TextAttack,Combating Adversarial Misspellings with Robust Word Recognition,Danish Pruthi; Bhuwan Dhingra; Zachary C. Lipton,2019-05-27,,,,,,,,,,,,
YES,1905.13409,IBM ART,Bypassing Backdoor Detection Algorithms in Deep Learning,Te Juin Lester Tan; Reza Shokri,2019-05-31,,,,,,,,,,,,
YES,1906.06026,IBM ART,Adversarial Robustness Assessment: Why both $L_0$ and $L_\infty$ Attacks Are Necessary,Shashank Kotyan; Danilo Vasconcellos Vargas,2019-06-14,,,,,,,,,,,,
YES,1906.11897,IBM ART,On Physical Adversarial Patches for Object Detection,Mark Lee; Zico Kolter,2019-06-20,,,,,,,,,,,,
YES,1907.01003,"Foolbox, IBM ART","Accurate, reliable and fast robustness evaluation",Wieland Brendel; Jonas Rauber; Matthias Kümmerer; Ivan Ustyuzhaninov; Matthias Bethge,2019-07-01,,,,,,,,,,,,
YES,1907.11932,TextAttack,Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment,Di Jin; Zhijing Jin; Joey Tianyi Zhou; Peter Szolovits,2019-07-27,,,,,,,,,,,,
YES,1909.01838,IBM ART,High Accuracy and High Fidelity Extraction of Neural Networks,Matthew Jagielski; Nicholas Carlini; David Berthelot; Alex Kurakin; Nicolas Papernot,2019-09-03,,,,,,,,,,,,
YES - Defense,1909.06723,TextAttack,Natural Language Adversarial Defense through Synonym Encoding,Xiaosen Wang; Hao Jin; Yichen Yang; Kun He,2019-09-15,,,,,,,,,,,,
YES,1910.00033,IBM ART,Hidden Trigger Backdoor Attacks,Aniruddha Saha; Akshayvarun Subramanya; Hamed Pirsiavash,2019-09-30,,,,,,,,,,,,
YES,1911.03274,IBM ART,Imperceptible Adversarial Attacks on Tabular Data,Vincent Ballet; Xavier Renard; Jonathan Aigrain; Thibault Laugel; Pascal Frossard...,2019-11-08,,,,,,,,,,,,
YES,1911.06502,IBM ART,Simple iterative method for generating targeted universal adversarial perturbations,Hokuto Hirano; Kazuhiro Takemoto,2019-11-15,,,,,,,,,,,,
YES,1912.00049,IBM ART,Square Attack: a query-efficient black-box adversarial attack via random search,Maksym Andriushchenko; Francesco Croce; Nicolas Flammarion; Matthias Hein,2019-11-29,,,,,,,,,,,,
YES,2002.05123,IBM ART,Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks,Roi Pony; Itay Naeh; Shie Mannor,2020-02-12,,,,,,,,,,,,
YES,2002.07088,IBM ART,GRAPHITE: Generating Automatic Physical Examples for Machine-Learning Attacks on Computer Vision Systems,Ryan Feng; Neal Mangaokar; Jiefeng Chen; Earlence Fernandes; Somesh Jha...,2020-02-17,,,,,,,,,,,,
YES,2003.01690,IBM ART,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,Francesco Croce; Matthias Hein,2020-03-03,,,,,,,,,,,,
YES,2003.08937,IBM ART,Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates,Amin Ghiasi; Ali Shafahi; Tom Goldstein,2020-03-19,,,,,,,,,,,,
YES,2003.09461,RobustBench,Adversarial Robustness on In- and Out-Distribution Improves Explainability,Maximilian Augustin; Alexander Meinke; Matthias Hein,2020-03-20,,,,,,,,,,,,
YES,2004.09984,TextAttack,BERT-ATTACK: Adversarial Attack Against BERT Using BERT,Linyang Li; Ruotian Ma; Qipeng Guo; Xiangyang Xue; Xipeng Qiu,2020-04-21,,,,,,,,,,,,
YES,2005.00191,IBM ART,Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved Transferability,Hojjat Aghakhani; Dongyu Meng; Yu-Xiang Wang; Christopher Kruegel; Giovanni Vigna,2020-05-01,,,,,,,,,,,,
YES,2005.04118,TextAttack,Beyond Accuracy: Behavioral Testing of NLP models with CheckList,Marco Tulio Ribeiro; Tongshuang Wu; Carlos Guestrin; Sameer Singh,2020-05-08,,,,,,,,,,,,
YES,2007.07677,Foolbox,Fast Differentiable Clipping-Aware Normalization and Rescaling,Jonas Rauber; Matthias Bethge,2020-07-15,,,,,,,,,,,,
YES,2007.14321,IBM ART,Label-Only Membership Inference Attacks,Christopher A. Choquette-Choo; Florian Tramer; Nicholas Carlini; Nicolas Papernot,2020-07-28,,,,,,,,,,,,
YES,2007.15528,IBM ART,Membership Leakage in Label-Only Exposures,Zheng Li; Yang Zhang,2020-07-30,,,,,,,,,,,,
YES,2008.07125,IBM ART,Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection,Luca Demetrio; Scott E. Coull; Battista Biggio; Giovanni Lagorio; Alessandro Armando...,2020-08-17,,,,,,,,,,,,
YES,2009.02276,IBM ART,Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,Jonas Geiping; Liam Fowl; W. Ronny Huang; Wojciech Czaja; Gavin Taylor...,2020-09-04,,,,,,,,,,,,
YES,2009.07502,TextAttack,Contextualized Perturbation for Textual Adversarial Attack,Dianqi Li; Yizhe Zhang; Hao Peng; Liqun Chen; Chris Brockett...,2020-09-16,,,,,,,,,,,,
YES,2102.12827,Foolbox,Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints,Maura Pintor; Fabio Roli; Wieland Brendel; Battista Biggio,2021-02-25,,,,,,,,,,,,
YES,2103.06504,IBM ART,Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a Blink,Ranjie Duan; Xiaofeng Mao; A. K. Qin; Yun Yang; Yuefeng Chen...,2021-03-11,,,,,,,,,,,,
YES,2106.08970,IBM ART,Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,Hossein Souri; Liam Fowl; Rama Chellappa; Micah Goldblum; Tom Goldstein,2021-06-16,,,,,,,,,,,,
YES,2106.09898,TextAttack,Bad Characters: Imperceptible NLP Attacks,Nicholas Boucher; Ilia Shumailov; Ross Anderson; Nicolas Papernot,2021-06-18,,,,,,,,,,,,
YES,2108.01644,IBM ART,The Devil is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models,Ambrish Rawat; Killian Levacher; Mathieu Sinn,2021-08-03,,,,,,,,,,,,
YES,2109.00544,TextAttack,Towards Improving Adversarial Training of NLP Models,Jin Yong Yoo; Yanjun Qi,2021-09-01,,,,,,,,,,,,
NO - Exclude,2111.14725,RobustBench,Searching the Search Space of Vision Transformer,Minghao Chen; Kan Wu; Bolin Ni; Houwen Peng; Bei Liu...,2021-11-29,,,,,,,,,,,,
YES,2202.04235,IBM ART,Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations,Lei Hsiung; Yun-Yun Tsai; Pin-Yu Chen; Tsung-Yi Ho,2022-02-09,,,,,,,,,,,,
YES,2205.14497,IBM ART,BadDet: Backdoor Attacks on Object Detection,Shih-Han Chan; Yinpeng Dong; Jun Zhu; Xiaolu Zhang; Jun Zhou,2022-05-28,,,,,,,,,,,,
YES,2206.09628,IBM ART,Diversified Adversarial Attacks based on Conjugate Gradient Method,Keiichiro Yamamura; Haruki Sato; Nariaki Tateiwa; Nozomi Hata; Toru Mitsutake...,2022-06-20,,,,,,,,,,,,
YES,2212.11005,RobustBench,Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective,Shihua Huang; Zhichao Lu; Kalyanmoy Deb; Vishnu Naresh Boddeti,2022-12-21,,,,,,,,,,,,
YES,2303.01870,RobustBench,"Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",Naman D Singh; Francesco Croce; Matthias Hein,2023-03-03,,,,,,,,,,,,
YES,2304.05370,IBM ART,Overload: Latency Attacks on Object Detection for Edge Devices,Erh-Chung Chen; Pin-Yu Chen; I-Hsin Chung; Che-rung Lee,2023-04-11,,,,,,,,,,,,
YES,2307.15043,PyRIT,Universal and Transferable Adversarial Attacks on Aligned Language Models,Andy Zou; Zifan Wang; Nicholas Carlini; Milad Nasr; J. Zico Kolter...,2023-07-27,,,,,,,,,,,,
YES,2308.03825,PyRIT,"""Do Anything Now"": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",Xinyue Shen; Zeyuan Chen; Michael Backes; Yun Shen; Yang Zhang,2023-08-07,,,,,,,,,,,,
YES,2308.13387,PyRIT,Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs,Yuxia Wang; Haonan Li; Xudong Han; Preslav Nakov; Timothy Baldwin,2023-08-25,,,,,,,,,,,,
YES,2309.10253,PyRIT,GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,Jiahao Yu; Xingwei Lin; Zheng Yu; Xinyu Xing,2023-09-19,,,,,,,,,,,,
YES,2312.02119,PyRIT,Tree of Attacks: Jailbreaking Black-Box LLMs Automatically,Anay Mehrotra; Manolis Zampetakis; Paul Kassianik; Blaine Nelson; Hyrum Anderson...,2023-12-04,,,,,,,,,,,,
YES,2401.06373,"HarmBench, PyRIT",How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs,Yi Zeng; Hongpeng Lin; Jingwen Zhang; Diyi Yang; Ruoxi Jia...,2024-01-12,,,,,,,,,,,,
YES,2401.15817,PyRIT,Transparency Attacks: How Imperceptible Image Layers Can Fool AI Perception,Forrest McKee; David Noever,2024-01-29,,,,,,,,,,,,
YES,2402.04249,"HarmBench, PyRIT",HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal,Mantas Mazeika; Long Phan; Xuwang Yin; Andy Zou; Zifan Wang...,2024-02-06,,,,,,,,,,,,
YES,2402.16717,PyRIT,CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models,Huijie Lv; Xiao Wang; Yuansen Zhang; Caishuang Huang; Shihan Dou...,2024-02-26,,,,,,,,,,,,
NO - Exclude,2403.12025,PyRIT,A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models,Stephen R. Pfohl; Heather Cole-Lewis; Rory Sayres; Darlene Neal; Mercy Asiedu...,2024-03-18,,,,,,,,,,,,
YES,2404.01318,PyRIT,JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models,Patrick Chao; Edoardo Debenedetti; Alexander Robey; Maksym Andriushchenko; Francesco Croce...,2024-03-28,,,,,,,,,,,,
YES,2404.15881,IBM ART,Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks,Erh-Chung Chen; Pin-Yu Chen; I-Hsin Chung; Che-Rung Lee,2024-04-24,,,,,,,,,,,,
YES,2406.14598,PyRIT,SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal,Tinghao Xie; Xiangyu Qi; Yi Zeng; Yangsibo Huang; Udari Madhushani Sehwag...,2024-06-20,,,,,,,,,,,,
NO - Exclude,2406.18682,PyRIT,The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm, Aakanksha; Arash Ahmadian; Beyza Ermis; Seraphina Goldfarb-Tarrant; Julia Kreutzer...,2024-06-26,,,,,,,,,,,,
YES,2408.03972,IBM ART,Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks,Keiichiro Yamamura; Issa Oe; Hiroki Ishikura; Katsuki Fujisawa,2024-08-07,,,,,,,,,,,,
NO - Exclude,2501.01151,PyRIT,Characteristic oscillations in frequency-resolved heat dissipation of linear time-delayed Langevin systems: Approach from the violation of the fluctuation-response relation,Xin Wang; Ruicheng Bao; Naruo Ohga,2025-01-02,,,,,,,,,,,,
NO - Exclude,2505.21605,PyRIT,SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge,Fengqing Jiang; Fengbo Ma; Zhangchen Xu; Yuetai Li; Bhaskar Ramasubramanian...,2025-05-27,,,,,,,,,,,,
