Year,Filename,Title,Authors,G1,G2,G3,G4,G5,G6,G7,T1,T2,Q1,Q2,Q3,Flag_Grad,Flag_HighQ,Flag_WB,Flag_NoEcon,Flag_NoCode,Flag_NoReal,Traditional_Score
2022,3548606.3559350.pdf,Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception,Rui Duan et al.,atk,Evasion,Both,Audio,NO,NO,YES,Black-box,None,NO,High,High,0,1,0,1,1,0,3
2022,3548606.3559392.pdf,"""Is your explanation stable?"": A Robustness Evaluation Framework for Feature Attribution",Yuyou Gan et al.¬†,def,NA,DL,Images,NO,NO,NO,NA,NA,YES,High,High,1,1,0,1,1,1,5
2022,3548606.3560705.pdf,LPGNet: Link Private Graph Networks for Node Classification,Aashish Kolluri et al.¬†,def,Privacy,DL,Other,NO,YES,NO,Black-box,None,NO,High,High,0,1,0,1,0,1,3
2022,3548606.3560671.pdf,When Evil Calls: Targeted Adversarial Voice over IP Network,Han Liu et al.¬†,atk,Evasion,DL,Audio,YES,YES,YES,Black-box,None,NO,High,High,0,1,0,0,0,0,1
2022,3548606.3559390.pdf,Physical Hijacking Attacks against Object Trackers,Raymond Muller et al.,atk,Evasion,DL,Images,YES,YES,NO,Gray-box,Partial,YES,None,High,1,0,0,0,0,1,2
2022,3548606.3560662.pdf,Group Property Inference Attacks Against Graph Neural Networks,Xinyu Wang et al.,both,Privacy,DL,Other,YES,YES,NO,Multiple,Partial,YES,None,High,1,0,0,0,0,1,2
2022,3548606.3560663.pdf,Are Attribute Inference Attacks Just Imputation?,Bargav Jayaraman et al.,atk,Privacy,Both,Other,NO,YES,NO,White-box,Partial,YES,None,Low,1,0,1,1,0,1,4
2022,3548606.3560675.pdf,Enhanced Membership Inference Attacks against Machine Learning Models,Jiayuan Ye et al.,atk,Privacy,Both,Other,NO,YES,NO,Black-box,Partial,NO,High,High,0,1,0,1,0,1,3
2022,3548606.3559355.pdf,SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders,Tianshuo Cong et al.,def,Privacy,DL,Images,YES,YES,NO,Black-box,Partial,NO,High,High,0,1,0,0,0,1,2
2022,3548606.3560660.pdf,SpecPatch: Human-in-the-Loop Adversarial Audio Spectrogram Patch Attack on Speech Recognition,¬†Hanqing Guo et al.,atk,Evasion,DL,Audio,NO,NO,YES,White-box,None,YES,None,High,1,0,1,1,1,0,4
2022,3548606.3560599.pdf,Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,Wai Man Si et al.,atk,Evasion,DL,Text,YES,NO,NO,Black-box,Partial,NO,High,High,0,1,0,0,1,1,3
2022,3548606.3560566.pdf,Harnessing Perceptual Adversarial Patches for Crowd Counting,Shunchang Liu et al.,both,Evasion,DL,Images,NO,YES,NO,Black-box,None,YES,None,High,1,0,0,1,0,1,3
2022,3548606.3560573.pdf,Feature Inference Attack on Shapley Values,Xinjian Luo et al.,atk,Privacy,Both,Other,YES,NO,YES,Black-box,Partial,NO,Low,Low,0,0,0,0,1,0,1
2022,3548606.3560611.pdf,E FFeL: Ensuring Integrity For Federated Learning,Amrita Roy Chowdhury et al.,def,NA,DL,Images,YES,NO,NO,NA,NA,YES,None,High,1,0,0,0,1,1,3
2022,3548606.3560615.pdf,Phishing URL Detection: A Network-based Approach Robust to Evasion,Taeri Kim et al.,def,Evasion,Both,Text,YES,YES,NO,NA,NA,NO,None,Low,0,0,0,0,0,1,1
2022,3548606.3559335.pdf,Identifying a Training-Set Attack‚Äôs Target Using Renormalized Influence Estimation,Zayd Hammoudeh et al.¬†,def,Poisoning,DL,Images,NO,YES,NO,Gray-box,Partial,YES,None,High,1,0,0,1,0,1,3
2022,3548606.3560561.pdf,Post-breach Recovery:Protectionagainst White-box Adversarial ExamplesforLeaked DNN Models,Shawn Shan et al.¬†,def,NA,DL,Images,YES,NO,NO,White-box,Partial,YES,None,High,1,0,1,0,1,1,4
2022,3548606.3560586.pdf,StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning,Yupei Liu et al.¬†,atk,Privacy,DL,Images,YES,NO,YES,Black-box,Partial,YES,High,High,1,1,0,0,1,0,3
2022,3548606.3560619.pdf,On the Privacy Risks of Cell-Based NAS Architectures Hai Huang CISPA Helmholtz Center for Information SecurityZhikun Zhang CISPA Helmholtz Center for ,Hai Huang et al.¬†,both,Privacy,DL,Images,NO,YES,NO,White-box,Partial,YES,High,High,1,1,1,1,0,1,5
2022,3548606.3560581.pdf,QuerySnout: Automating the Discovery of Attribute Inference Attacks against Query-Based System,Ana-Maria Cre≈£u et al.¬†,atk,Privacy,Traditional,Other,YES,YES,NO,Black-box,Partial,NO,High,High,0,1,0,0,0,1,2
2022,3548606.3560557.pdf,Eluding Secure Aggregation in Federated Learning via Model Inconsistency,Dario Pasquini et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,White-box,Partial,YES,None,Low,1,0,1,1,0,1,4
2022,3548606.3560621.pdf,Adversarial Correctness and Privacy for Probabilistic Data Structures,Mia Filiƒá et al.¬†,def,NA,Traditional,Other,YES,NO,NO,NA,NA,NO,None,Low,0,0,0,0,1,1,2
2022,3548606.3560554.pdf,Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets¬†,Florian Tram√®r et al.¬†,atk,Privacy,DL,Images,NO,NO,NO,Black-box,Partial,NO,High,High,0,1,0,1,1,1,4
2022,3548606.3559359.pdf,Auditing Membership Leakages of Multi-Exit Networks,Zheng Li et al.¬†,both,Privacy,DL,Images,YES,YES,NO,Gray-box,Partial,YES,High,High,1,1,0,0,0,1,3
2022,3548606.3559358.pdf,Finding MNEMON: Reviving Memories of Node Embeddings¬†,Yun Shen et al.¬†,atk,Privacy,DL,Other,NO,NO,NO,Black-box,None,NO,None,High,0,0,0,1,1,1,3
2022,3548606.3560678.pdf,LoneNeuron: A Highly-Effective Feature-Domain Neural Trojan Using Invisible and Polymorphic Watermarks,Zeyan Liu et al.¬†,atk,Poisoning,DL,Images,YES,NO,NO,Gray-box,Partial,YES,None,High,1,0,0,0,1,1,3
2022,3548606.3560684.pdf,Membership Inference Attacks by Exploiting Loss Trajectory,Yiyong Liu et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,Black-box,Partial,NO,Low,High,0,0,0,1,0,1,2
2022,3548606.3560694.pdf,Membership Inference Attacks and Generalization: A Causal Perspective,Teodora Baluta et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,Black-box,None,NO,High,High,0,1,0,1,0,1,3
2022,3548606.3559388.pdf,Understanding Real-world Threats to Deep Learning Models in Android Apps,Zizhuang Deng et al.¬†,atk,Evasion,DL,Images,YES,YES,YES,Black-box,Partial,YES,High,High,1,1,0,0,0,0,2
2022,3548606.3560683.pdf,Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models,Jiawei Liu et al.¬†,atk,Evasion,DL,Text,YES,YES,NO,Black-box,Partial,YES,High,High,1,1,0,0,0,1,3
2023,3576915.3623209.pdf,AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis,Zhiyuan Yu et al.¬†,def,NA,DL,Audio,YES,NO,YES,Black-box,None,YES,High,High,1,1,0,0,1,0,3
2023,3576915.3623134.pdf,martFL: Enabling Utility-Driven Data Marketplace with a Robust and Verifiable Federated Learning Architecture,Qi Li et al.¬†,def,NA,DL,Images,YES,YES,NO,NA,NA,YES,None,High,1,0,0,0,0,1,2
2023,3576915.3623120.pdf,Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks,Zongjie Li et al.¬†,def,NA,DL,Text,YES,YES,NO,Black-box,None,NO,High,High,0,1,0,0,0,1,2
2023,3576915.3616617.pdf,Narcissus : A Practical Clean-Label Backdoor Attack with Limited Information,Yi Zeng et al.¬†,atk,Poisoning,DL,Images,YES,YES,NO,Gray-box,Partial,YES,None,High,1,0,0,0,0,1,2
2023,3576915.3623082.pdf,MDTD: A Multi-Domain Trojan Detector for Deep Neural Networks,Arezoo Rajabi et al.¬†,def,NA,DL,Images,YES,YES,NO,White-box,Partial,YES,Low,Low,1,0,1,0,0,1,3
2023,3576915.3616588.pdf,DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models,Zeyang Sha et al.¬†,def,NA,DL,Images,NO,YES,NO,NA,NA,YES,None,High,1,0,0,1,0,1,3
2023,3576915.3623093.pdf,Unforgeability in Stochastic Gradient Descent,Teodora Baluta et al.¬†,def,NA,DL,Images,NO,YES,NO,White-box,Full,YES,None,Low,1,0,1,1,0,1,4
2023,3576915.3623100.pdf,Verifiable Learning for Robust Tree Ensembles,Stefano Calzavara et al.¬†,def,NA,Traditional,Other,YES,YES,NO,NA,NA,NO,None,Low,0,0,0,0,0,1,1
2023,3576915.3623114.pdf,Turning Privacy-preserving Mechanisms against Federated Learning,Marco Arazzi et al.¬†,atk,Poisoning,DL,Other,NO,NO,NO,Gray-box,Partial,YES,None,High,1,0,0,1,1,1,4
2023,3576915.3623116.pdf,Stateful Defenses for Machine Learning Models Are Not Yet Secure Against Black-box Attacks¬†,Ryan Feng et al.¬†,atk,Evasion,DL,Images,YES,YES,NO,Black-box,None,NO,High,High,0,1,0,0,0,1,2
2023,3576915.3616634.pdf,Privacy Leakage via Speech-induced Vibrations on Room Objects through Remote Sensing based on Phased-MIMO,Cong Shi et al.¬†,atk,Privacy,DL,Audio,NO,NO,NO,Black-box,Partial,NO,None,High,0,0,0,1,1,1,3
2023,3576915.3623117.pdf,Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting¬†,Ping He et al.¬†,atk,Evasion,Both,Malware,YES,NO,YES,Black-box,None,NO,Low,Low,0,0,0,0,1,0,1
2023,3576915.3616593.pdf,DPMLBench: Holistic Evaluation of Differentially Private Machine Learning,Chengkun Wei et al.¬†,both,Privacy,DL,Images,NO,YES,NO,White-box,Partial,YES,High,High,1,1,1,1,0,1,5
2023,3576915.3623189.pdf,Evading Watermark based Detection of AI-Generated Content¬†,Zhengyuan Jiang et al.¬†,atk,Evasion,DL,Images,YES,YES,NO,Multiple,None,YES,High,High,1,1,0,0,0,1,3
2023,3576915.3623177.pdf,Attack Some while Protecting Others: Selective Attack Strategies for Attacking and Protecting Multiple Concepts,Vibha Belavadi et al.¬†,atk,Evasion,Both,Images,NO,NO,NO,White-box,None,YES,None,High,1,0,1,1,1,1,5
2023,3576915.3623175.pdf,Large Language Models for Code: Security Hardening and Adversarial Testing,Jingxuan He et al.¬†,both,NA,DL,Text,YES,YES,NO,NA,NA,YES,None,High,1,0,0,0,0,1,2
2023,3576915.3623212.pdf,MESAS: Poisoning Defense for Federated Learning Resilient against Adaptive Attackers,Torsten Krau√ü et al.¬†,def,Poisoning,DL,Images,YES,NO,NO,White-box,Partial,NO,None,High,0,0,1,0,1,1,3
2023,3576915.3616652.pdf,Stealing the Decoding Algorithms of Language Models,Ali Naseh et al.¬†,atk,Privacy,DL,Text,YES,YES,NO,Black-box,None,NO,High,Low,0,1,0,0,0,1,2
2023,3576915.3616653.pdf,Stolen Risks of Models with Security Properties,Yue Qin et al.¬†,both,Privacy,Both,Other,YES,YES,NO,Black-box,Partial,YES,Low,High,1,0,0,0,0,1,2
2023,3576915.3623173.pdf,Devil in Disguise: Breaching Graph Neural Networks Privacy through Infiltration,Lingshuo Meng et al.¬†,atk,Privacy,DL,Other,NO,NO,NO,Black-box,None,YES,Low,Low,1,0,0,1,1,1,4
2023,3576915.3616679.pdf,Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models,Yiting Qu et al.¬†,both,Multiple,DL,Images,NO,YES,NO,White-box,Partial,YES,High,High,1,1,1,1,0,1,5
2023,3576915.3623199.pdf,A Good Fishman Knows All the Angles: A Critical Evaluation of Google‚Äôs Phishing Page Classifier,Changqing Miao et al.¬†,both,Evasion,DL,Images,YES,YES,YES,White-box,None,YES,None,High,1,0,1,0,0,0,2
2024,3658644.3690187.pdf,Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses,Yuxin Yang et al.¬†,both,Poisoning,DL,Other,NO,YES,NO,Gray-box,Partial,YES,None,High,1,0,0,1,0,1,3
2024,3658644.3690346.pdf,SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via Substitution,Zhongjie Ba et al.¬†,atk,Evasion,DL,Images,YES,NO,YES,Black-box,None,NO,High,Low,0,1,0,0,1,0,2
2024,3658644.3690226.pdf,A General Framework for Data-Use Auditing of ML Models,Zonghao Huang et al.¬†,def,Privacy,DL,Images,YES,YES,NO,Black-box,None,NO,High,High,0,1,0,0,0,1,2
2024,3658644.3670307.pdf,Byzantine-Robust Decentralized Federated Learning,Minghong Fang et al.¬†,def,NA,Both,Other,NO,YES,NO,White-box,None,YES,None,Low,1,0,1,1,0,1,4
2024,3658644.3690335 (1).pdf,SeqMIA: Sequential-Metric Based Membership Inference Attack,Hao Li et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,Black-box,Partial,NO,High,High,0,1,0,1,0,1,3
2024,3658644.3670267.pdf,Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions,Xueluan Gong et al.¬†,def,Privacy,DL,Images,YES,NO,NO,Black-box,None,YES,High,High,1,1,0,0,1,1,4
2024,3658644.3670298.pdf,Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols,Wei Tong et al.¬†,atk,Poisoning,Traditional,Other,NO,YES,NO,Black-box,Partial,NO,None,Low,0,0,0,1,0,1,2
2024,3658644.3690185.pdf,ùëÜ2NeRF: Privacy-preserving Training Framework for NeRF,Bokang Zhang et al.¬†,both,Privacy,DL,Images,NO,YES,NO,Gray-box,None,YES,High,High,1,1,0,1,0,1,4
2024,3658644.3690369.pdf,Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning,Jonathan Knauer et al.¬†,atk,Poisoning,DL,Images,YES,NO,NO,Black-box,None,NO,None,Low,0,0,0,0,1,1,2
2024,3658644.3690194.pdf,Evaluations of Machine Learning Privacy Defenses are Misleading,Michael Aerni et al.¬†,both,Privacy,DL,Images,NO,YES,NO,White-box,Partial,YES,High,High,1,1,1,1,0,1,5
2024,3658644.3690208.pdf,"Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months",Keane Lucas et al.¬†,def,Evasion,DL,Malware,YES,YES,NO,White-box,None,YES,None,Low,1,0,1,0,0,1,3
2024,3658644.3670317.pdf,"I Don‚Äôt Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors",Zijin Lin et al.¬†,def,NA,DL,Images,NO,YES,NO,White-box,Full,YES,None,Low,1,0,1,1,0,1,4
2024,3658644.3690343.pdf,Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence,Hanbin Hong et al.¬†,atk,Evasion,DL,Images,YES,YES,NO,Black-box,None,NO,High,High,0,1,0,0,0,1,2
2024,3658644.3690250.pdf,Fisher Information guided Purification against Backdoor Attacks,Nazmul Karim et al.¬†,def,NA,DL,Images,NO,YES,NO,NA,NA,YES,None,High,1,0,0,1,0,1,3
2024,3658644.3690279.pdf,PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps,Ruixuan Liu et al.¬†,atk,Privacy,DL,Text,NO,YES,NO,Black-box,Partial,NO,High,High,0,1,0,1,0,1,3
2024,3658644.3690292.pdf,Uncovering Gradient Inversion Risks in Practical Language Model Training,Xinguo Feng et al.¬†,atk,Privacy,DL,Text,NO,YES,NO,White-box,None,YES,None,High,1,0,1,1,0,1,4
2024,3658644.3670370.pdf,PLeak: Prompt Leaking Attacks against Large Language Model Applications,Bo Hui et al.¬†,atk,Privacy,DL,Text,NO,YES,YES,Black-box,None,YES,High,High,1,1,0,1,0,0,3
2024,3658644.3690284.pdf,BadMerging: Backdoor Attacks Against Model,Jinghuai Zhang et al.¬†,atk,Poisoning,DL,Images,YES,YES,NO,Black-box,Partial,YES,None,High,1,0,0,0,0,1,2
2024,3658644.3690327.pdf,Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies,Peiran Wang et al.¬†,def,NA,DL,Images,YES,YES,NO,NA,NA,YES,None,High,1,0,0,0,0,1,2
2024,3658644.3690291.pdf,Optimization-based Prompt Injection Attack to LLM-as-a-Judge¬†,Jiawen Shi et al.¬†,atk,Evasion,DL,Text,YES,NO,NO,White-box,Partial,YES,High,High,1,1,1,0,1,1,5
2024,3658644.3670365.pdf,Not One Less: Exploring Interplay between User Profiles and Items in Untargeted Attacks against Federated Recommendation,Yurong Hao et al.¬†,both,Poisoning,DL,Other,NO,NO,NO,Gray-box,Partial,YES,None,High,1,0,0,1,1,1,4
2024,3658644.3670361.pdf,Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense,Hua Ma et al.¬†,atk,Poisoning,DL,Images,YES,YES,NO,White-box,Full,YES,None,High,1,0,1,0,0,1,3
2024,3658644.3690295.pdf,Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack,Muxi Chen et al.¬†,atk,Privacy,DL,Text,YES,YES,NO,Gray-box,Partial,YES,None,High,1,0,0,0,0,1,2
2024,3658644.3690337.pdf,Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines,Eugene Bagdasarian et al.¬†,def,Poisoning,DL,Images,YES,YES,NO,NA,NA,NO,None,High,0,0,0,0,0,1,1
2024,3658644.3690335.pdf,SeqMIA: Sequential-Metric Based Membership Inference Attack,Hao Li et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,Black-box,Partial,NO,High,High,0,1,0,1,0,1,3
2024,3658644.3690334.pdf,Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data,Yifan Lu et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,White-box,Partial,YES,None,High,1,0,1,1,0,1,4
2024,3658644.3690268.pdf,Membership Inference Attacks against Vision Transformers,Qiankun Zhang et al.¬†,both,Privacy,DL,Images,NO,NO,NO,White-box,Partial,YES,None,High,1,0,1,1,1,1,5
2024,3658644.3670388.pdf,‚ÄúDo Anything Now‚Äù: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models,Xinyue Shen et al.¬†,atk,Evasion,DL,Text,NO,YES,NO,Black-box,None,NO,High,High,0,1,0,1,0,1,3
2024,3658644.3690297.pdf,ZeroFake: Zero-Shot Detection of Fake Images Generated and Edited by Text-to-Image Generation Models,Zeyang Sha et al.¬†,def,NA,DL,Images,YES,YES,NO,NA,NA,NO,None,High,0,0,0,0,0,1,1
2024,3658644.3690311.pdf,Trident of Poseidon: A Generalized Approach for Detecting Deepfake Voices,Thien-Phuc Doan et al.¬†,def,NA,DL,Audio,YES,YES,NO,NA,NA,NA,NA,NA,0,0,0,0,0,1,1
2024,3658644.3690305.pdf,"Blind and Low Vision Individuals‚Äô Detection of Audio Deepfakes Filipo Sharevski DePaul University Chicago, IL, United States",Filipo Sharevski et al.¬†,def,NA,DL,Audio,NO,NO,NO,NA,NA,NA,None,Low,0,0,0,1,1,1,3
2024,3658644.3690304.pdf,Analyzing Inference Privacy Risks Through Gradients In Machine Learning,Zhuohang Li et al.¬†,both,Privacy,Both,Other,NO,NO,NO,White-box,Partial,YES,None,High,1,0,1,1,1,1,5
2024,3658644.3690338.pdf,Demystifying RCE Vulnerabilities in LLM-Integrated Apps,Tong Liu et al.¬†,atk,Multiple,DL,Text,YES,NO,YES,Black-box,None,NO,High,High,0,1,0,0,1,0,2
2024,3658644.3690291 (1).pdf,Optimization-based Prompt Injection Attack to LLM-as-a-Judge¬†,Jiawen Shi et al.¬†,atk,Evasion,DL,Text,YES,NO,NO,Black-box,Partial,YES,High,High,1,1,0,0,1,1,4
2024,3658644.3670386.pdf,Inbox Invasion: Exploiting MIME Ambiguities to Evade Email Attachment Detectors,Jiahe Zhang et al.¬†,atk,Evasion,Traditional,Text,YES,YES,YES,Black-box,None,NO,Low,Low,0,0,0,0,0,0,0
2024,3658644.3690306.pdf,Membership Inference Attacks Against In-Context Learning¬†,Rui Wen et al.¬†,atk,Privacy,DL,Text,NO,NO,NO,Black-box,None,NO,High,High,0,1,0,1,1,1,4
2024,3658644.3690317.pdf,HyperTheft: Thieving Model Weights from TEE-Shielded Neural Networks via Ciphertext Side Channels¬†,Yuanyuan Yuan et al.¬†,atk,Privacy,DL,Images,YES,YES,NO,Black-box,None,NO,None,High,0,0,0,0,0,1,1
2024,3658644.3690316.pdf,Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks¬†,Yu He et al.¬†,atk,Privacy,DL,Images,YES,YES,NO,Black-box,Partial,NO,High,High,0,1,0,0,0,1,2
2024,3658644.3670382.pdf,The Invisible Polyjuice Potion: An Effective Physical Adversarial Attack Against Face Recognition,Ye Wang et al.¬†,atk,Evasion,DL,Images,YES,NO,YES,Multiple,None,YES,None,High,1,0,0,0,1,0,2
2024,3658644.3670395.pdf,Alchemy: Data-Free Adversarial Training¬†,Yijie Bai et al.¬†,def,NA,DL,Images,YES,NO,NO,White-box,None,YES,None,High,1,0,1,0,1,1,4
2024,3658644.3670293.pdf,SUB-PLAY : Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems,Oubo Ma et al.¬†,atk,Evasion,DL,Other,YES,YES,NO,Black-box,None,NO,High,High,0,1,0,0,0,1,2
2024,3658644.3690205.pdf,Understanding Implosion in Text-to-Image Generative Models,Wenxin Ding et al.¬†,both,Poisoning,DL,Images,NO,YES,NO,Black-box,Partial,NO,None,High,0,0,0,1,0,1,2
2024,3658644.3670291.pdf,Avara: A Uniform Evaluation System for Perceptibility Analysis Against Adversarial Object Evasion Attacks¬†,Xinyao Ma et al.¬†,both,Evasion,DL,Images,YES,YES,NO,Black-box,None,NO,None,Low,0,0,0,0,0,1,1
2024,3658644.3670285.pdf,SafeEar: Content Privacy-Preserving Audio Deepfake Detection,Xinfeng Li et al.¬†,def,NA,DL,Audio,YES,YES,NO,NA,NA,NO,None,High,0,0,0,0,0,1,1
2024,2309.03466v2.pdf,Neural Dehydration : Effective Erasure of Black-box Watermarks from DNNs with Limited Data¬†,Yifan Lu et al.¬†,atk,Privacy,DL,Images,YES,YES,NO,White-box,Partial,YES,None,High,1,0,1,0,0,1,3
2024,3658644.3690238.pdf,ProFake: Detecting DeepFakes in the Wild against quality degradation with progressive quality adaptive learning,Huiyu Xu et al.¬†,def,NA,DL,Images,YES,NO,NO,NA,NA,YES,None,High,1,0,0,0,1,1,3
2024,3658644.3670295.pdf,SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models,Xinfeng Li et al.¬†,def,NA,DL,Images,YES,YES,NO,NA,NA,NA,None,Low,0,0,0,0,0,1,1
2024,3658644.3690316 (1).pdf,Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks¬†,Yu He et al.¬†,atk,Privacy,DL,Images,YES,YES,NO,Black-box,Partial,NO,High,High,0,1,0,0,0,1,2
2024,3658644.3670296.pdf,VisionGuard: Secure and Robust Visual Perception of Autonomous Vehicles in Practice¬†,Xingshuo Han et al.¬†,def,NA,DL,Images,YES,YES,YES,NA,NA,NO,None,Low,0,0,0,0,0,0,0
2024,3658644.3690202.pdf,A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability,Jie Zhu et al.¬†,atk,Privacy,DL,Images,NO,YES,NO,Black-box,Partial,NO,High,High,0,1,0,1,0,1,3
2024,3658644.3670309.pdf,Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems,Zheng Fang et al.¬†,atk,Evasion,DL,Audio,YES,NO,YES,Black-box,None,YES,None,High,1,0,0,0,1,0,2
2025,2506.21874v1.pdf,arXiv:2506.21874v1  [cs.CR]  27 Jun 2025On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling,Stanley Wu et al.¬†,atk,Poisoning,DL,Images,YES,YES,YES,White-box,None,YES,Low,High,1,0,1,0,0,0,2
2025,2509.15499v1.pdf,Adversarially Robust Assembly Language Model for Packed Executables Detection¬†,Shijia Li et al.¬†,def,NA,DL,Malware,YES,YES,NO,NA,NA,NO,None,High,0,0,0,0,0,1,1
2025,2505.24842v2.pdf,Cascading Adversarial Bias from Injection to Distillation in Language Models¬†,Harsh Chaudhari et al.¬†,atk,Poisoning,DL,Text,YES,NO,NO,Black-box,Partial,NO,None,Low,0,0,0,0,1,1,2
2025,2506.05402v1.pdf,Sylvia: Tailoring Personalized Adversarial Defense in pre-trained Models via collaborative FineTuning,Tianyu Qi et al.¬†,def,NA,DL,Images,YES,NO,NO,NA,NA,YES,None,High,1,0,0,0,1,1,3
2025,2510.01676v1.pdf,Evaluating the Robustness of a Production Malware Detection System to Transferable Adversarial Attacks¬†,Milad Nasr et al.¬†,both,Evasion,DL,Malware,YES,YES,YES,White-box,Partial,YES,None,High,1,0,1,0,0,0,2
2025,2504.15942v1.pdf,Adversarial Observations in Weather Forecasting¬†,Erik Imgrund et al.¬†,atk,Evasion,DL,Other,YES,YES,NO,White-box,None,YES,None,High,1,0,1,0,0,1,3
2025,2505.19840v2.pdf,"One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP¬†",Binyan Xu et al.¬†,atk,Evasion,DL,Images,YES,YES,YES,Gray-box,None,YES,None,High,1,0,0,0,0,0,1
2025,2501.05928v2.pdf,arXiv:2501.05928v2  [cs.CR]  24 Jun 2025Towards Backdoor Stealthiness in Model Parameter Space¬†,Xiaoyun Xu et al.¬†,atk,Poisoning,DL,Images,NO,YES,NO,White-box,Full,YES,None,High,1,0,1,1,0,1,4
2025,2308.11333v2.pdf,FilterFL: Knowledge Filtering-based Data-Free Backdoor Defense for Federated Learning¬†,Yanxin Yang et al.¬†,def,NA,DL,Images,NO,NO,NO,NA,NA,YES,None,High,1,0,0,1,1,1,4
2025,2406.05810v1.pdf,ControlLoc: Physical-World Hijacking Attack on Visual Perception in Autonomous Driving¬†,Chen Ma et al.¬†,atk,Evasion,DL,Images,NO,NO,YES,White-box,None,YES,None,High,1,0,1,1,1,0,4
2025,VNET.pdf,VillainNet: Targeted Poisoning Attacks Against SuperNets Along the Accuracy-Latency¬†,Anonymous Author(s)¬†,atk,Poisoning,DL,Images,YES,YES,NO,White-box,Full,YES,None,High,1,0,1,0,0,1,3
2025,2501.06533v2.pdf,arXiv:2501.06533v2  [cs.CV]  24 Jun 2025DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy,Wenshu Fan et al.¬†,both,Privacy,DL,Images,YES,YES,NO,Black-box,Partial,YES,High,High,1,1,0,0,0,1,3
2025,2509.11745v3.pdf,Removal Attack and Defense on AI-generated Content Latent-based Watermarking¬†,De Zhang Lee et al.¬†,both,Evasion,DL,Images,YES,YES,NO,Gray-box,None,NO,High,High,0,1,0,0,0,1,2
2025,2509.06071v1.pdf,Asymmetry Vulnerability and Physical Attacks on Online Map Construction for Autonomous Driving¬†,Yang Lou et al.¬†,atk,Evasion,DL,Images,YES,NO,NO,Black-box,None,YES,Low,High,1,0,0,0,1,1,3
2025,ccs25.pdf,Deep Learning from Imperfectly Labeled Malware Data¬†,Fahad Alotaibi et al.¬†,def,NA,DL,Malware,YES,YES,NO,NA,NA,YES,None,High,1,0,0,0,0,1,2
2025,2403.02817v2.pdf,Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications¬†,Stav Cohen et al.Retry,both,Multiple,DL,Text,YES,YES,NO,Black-box,None,NO,None,Low,0,0,0,0,0,1,1
