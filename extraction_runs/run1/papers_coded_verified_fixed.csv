selection_reason,is_aml_paper,arxiv_id,found_in_artifacts,num_artifacts,paper_title,paper_authors,paper_pub_date,first_adoption_date,first_adoption_artifact,all_adoptions,adoption_lag_months,G1,G2,G3,G4,G5,G6,T1,T2,Q1
2+ artifacts,YES,1312.6199,"CleverHans, TextAttack",2,Intriguing properties of neural networks,Christian Szegedy; Wojciech Zaremba; Ilya Sutskever; Joan Bruna; Dumitru Erhan...,2013-12-21,2018-01-25,CleverHans,CleverHans:2018-01-25; TextAttack:2020-08-30,49.1,Attack,Evasion,Vision,ML,No,At-pub,White,Yes,No
2+ artifacts,YES,1412.6572,"CleverHans, IBM ART",2,Explaining and Harnessing Adversarial Examples,Ian J. Goodfellow; Jonathon Shlens; Christian Szegedy,2014-12-20,2016-09-19,CleverHans,CleverHans:2016-09-19; IBM ART:2017-06-07,21.0,Attack,Evasion,Vision,ML,Yes,At-pub,White,No,No
2+ artifacts,YES,1507.00677,"CleverHans, Foolbox, IBM ART",3,Distributional Smoothing with Virtual Adversarial Training,Takeru Miyato; Shin-ichi Maeda; Masanori Koyama; Ken Nakae; Shin Ishii,2015-07-02,2017-04-27,CleverHans,CleverHans:2017-04-27; IBM ART:2017-06-12; Foolbox:2019-10-17,21.8,Both,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1511.04599,"CleverHans, Foolbox, IBM ART",3,DeepFool: a simple and accurate method to fool deep neural networks,Seyed-Mohsen Moosavi-Dezfooli; Alhussein Fawzi; Pascal Frossard,2015-11-14,2017-05-30,IBM ART,IBM ART:2017-05-30; Foolbox:2017-06-07; CleverHans:2017-09-12,18.5,Attack,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1511.05122,"CleverHans, IBM ART",2,Adversarial Manipulation of Deep Representations,Sara Sabour; Yanshuai Cao; Fartash Faghri; David J. Fleet,2015-11-16,2017-06-08,CleverHans,CleverHans:2017-06-08; IBM ART:2020-04-10,18.7,Attack/Evaluation,Evasion,Vision,ML,No,Never,White,Yes,No
2+ artifacts,YES,1511.07528,"CleverHans, IBM ART",2,The Limitations of Deep Learning in Adversarial Settings,Nicolas Papernot; Patrick McDaniel; Somesh Jha; Matt Fredrikson; Z. Berkay Celik...,2015-11-24,2016-11-21,CleverHans,CleverHans:2016-11-21; IBM ART:2017-06-12,11.9,Attack/Defense/Evaluation,Evasion,Vision,Security,No,Never,White,Yes,No
2+ artifacts,YES,1607.02533,"CleverHans, Foolbox, IBM ART",3,Adversarial examples in the physical world,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-07-08,2017-02-01,CleverHans,CleverHans:2017-02-01; Foolbox:2018-06-26; IBM ART:2018-06-28,6.8,Attack/Evaluation,Evasion,Vision,ML,No,At-pub,White/Black,Yes,Yes
2+ artifacts,YES,1608.04644,"CleverHans, Foolbox, IBM ART",3,Towards Evaluating the Robustness of Neural Networks,Nicholas Carlini; David Wagner,2016-08-16,2017-06-05,CleverHans,CleverHans:2017-06-05; IBM ART:2017-08-14; Foolbox:2018-09-26,9.6,Attack/Evaluation,Evasion,Vision,Security,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1611.01236,"CleverHans, IBM ART",2,Adversarial Machine Learning at Scale,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-11-04,2017-03-23,CleverHans,CleverHans:2017-03-23; IBM ART:2017-06-07,4.6,Attack/Defense/Evaluation,Evasion,Vision,ML,No,Never,White/Black,Yes,No
2+ artifacts,YES,1705.07204,"CleverHans, IBM ART",2,Ensemble Adversarial Training: Attacks and Defenses,Florian Tramèr; Alexey Kurakin; Nicolas Papernot; Ian Goodfellow; Dan Boneh...,2017-05-19,2017-08-24,CleverHans,CleverHans:2017-08-24; IBM ART:2018-07-09,3.2,Attack/Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White/Black,Yes,No
2+ artifacts,YES,1706.06083,"AutoAttack, CleverHans, IBM ART, RobustBench",4,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksander Madry; Aleksandar Makelov; Ludwig Schmidt; Dimitris Tsipras; Adrian Vladu,2017-06-19,2017-09-22,CleverHans,CleverHans:2017-09-22; IBM ART:2018-09-26; AutoAttack:2020-03-17; RobustBench:2020-07-01,3.1,Attack/Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White/Black,Yes,No
2+ artifacts,YES,1709.04114,"CleverHans, IBM ART",2,EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples,Pin-Yu Chen; Yash Sharma; Huan Zhang; Jinfeng Yi; Cho-Jui Hsieh,2017-09-13,2017-09-28,CleverHans,CleverHans:2017-09-28; IBM ART:2018-12-18,0.5,Attack/Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White/Black,Yes,No
2+ artifacts,YES,1710.06081,"CleverHans, Foolbox, IBM ART",3,Boosting Adversarial Attacks with Momentum,Yinpeng Dong; Fangzhou Liao; Tianyu Pang; Hang Su; Jun Zhu...,2017-10-17,2017-12-22,CleverHans,CleverHans:2017-12-22; Foolbox:2018-06-26; IBM ART:2022-04-20,2.2,Attack/Evaluation,Evasion,Vision,ML,Yes,At-pub,White/Black,Yes,No
2+ artifacts,YES,1710.09412,"CleverHans, IBM ART",2,mixup: Beyond Empirical Risk Minimization,Hongyi Zhang; Moustapha Cisse; Yann N. Dauphin; David Lopez-Paz,2017-10-25,2018-10-03,CleverHans,CleverHans:2018-10-03; IBM ART:2022-10-19,11.3,Defense/Evaluation,Defense,Cross,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1712.02779,"Foolbox, IBM ART",2,Exploring the Landscape of Spatial Robustness,Logan Engstrom; Brandon Tran; Dimitris Tsipras; Ludwig Schmidt; Aleksander Madry,2017-12-07,2018-10-19,Foolbox,Foolbox:2018-10-19; IBM ART:2019-01-14,10.4,Attack/Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White/Black,Yes,No
2+ artifacts,YES,1712.04248,"Foolbox, IBM ART",2,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Wieland Brendel; Jonas Rauber; Matthias Bethge,2017-12-12,2017-12-13,Foolbox,Foolbox:2017-12-13; IBM ART:2019-04-01,0.0,Attack/Evaluation,Evasion,Vision,ML,Yes,At-pub,Black,No,Yes
2+ artifacts,YES,1712.09665,"CleverHans, IBM ART",2,Adversarial Patch,Tom B. Brown; Dandelion Mané; Aurko Roy; Martín Abadi; Justin Gilmer,2017-12-27,2018-02-05,CleverHans,CleverHans:2018-02-05; IBM ART:2019-02-13,1.3,Attack/Evaluation,Evasion,Vision,ML,No,Never,White/Black,Yes,Yes
2+ artifacts,YES,1801.01944,"CleverHans, IBM ART",2,Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,Nicholas Carlini; David Wagner,2018-01-05,2019-06-05,CleverHans,CleverHans:2019-06-05; IBM ART:2020-04-17,17.0,Attack/Evaluation,Evasion,Audio,Security,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1802.00420,"AutoAttack, CleverHans, IBM ART, RobustBench",4,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,Anish Athalye; Nicholas Carlini; David Wagner,2018-02-01,2018-10-07,CleverHans,CleverHans:2018-10-07; IBM ART:2019-04-19; RobustBench:2020-08-02; AutoAttack:2020-08-26,8.1,Attack/Evaluation,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1805.12152,"RobustBench, TextAttack",2,Robustness May Be at Odds with Accuracy,Dimitris Tsipras; Shibani Santurkar; Logan Engstrom; Alexander Turner; Aleksander Madry,2018-05-30,2020-08-02,RobustBench,RobustBench:2020-08-02; TextAttack:2020-08-30,26.1,Attack/Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1810.12715,"AutoAttack, IBM ART",2,On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models,Sven Gowal; Krishnamurthy Dvijotham; Robert Stanforth; Rudy Bunel; Chongli Qin...,2018-10-30,2020-03-25,AutoAttack,AutoAttack:2020-03-25; IBM ART:2022-08-22,16.8,Defense/Evaluation,Evasion,Vision,ML,Yes,At-pub,White,N/A,No
2+ artifacts,YES,1811.09600,"AutoAttack, Foolbox, RobustBench",3,Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses,Jérôme Rony; Luiz G. Hafemann; Luiz S. Oliveira; Ismail Ben Ayed; Robert Sabourin...,2018-11-23,2019-04-28,Foolbox,Foolbox:2019-04-28; AutoAttack:2020-08-04; RobustBench:2020-08-05,5.1,Attack/Defense,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1901.08573,"AutoAttack, RobustBench",2,Theoretically Principled Trade-off between Robustness and Accuracy,Hongyang Zhang; Yaodong Yu; Jiantao Jiao; Eric P. Xing; Laurent El Ghaoui...,2019-01-24,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,13.7,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1901.09960,"AutoAttack, RobustBench",2,Using Pre-Training Can Improve Model Robustness and Uncertainty,Dan Hendrycks; Kimin Lee; Mantas Mazeika,2019-01-28,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,13.6,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1902.02918,"IBM ART, RobustBench",2,Certified Adversarial Robustness via Randomized Smoothing,Jeremy M Cohen; Elan Rosenfeld; J. Zico Kolter,2019-02-08,2019-07-16,IBM ART,IBM ART:2019-07-16; RobustBench:2020-08-27,5.2,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1902.06705,"AutoAttack, IBM ART, RobustBench",3,On Evaluating Adversarial Robustness,Nicholas Carlini; Anish Athalye; Nicolas Papernot; Wieland Brendel; Jonas Rauber...,2019-02-18,2019-12-02,IBM ART,IBM ART:2019-12-02; RobustBench:2020-08-25; AutoAttack:2021-09-09,9.4,Evaluation,Evasion,Vision,arXiv-only,No,Never,White,Yes,No
2+ artifacts,YES,1904.00887,"AutoAttack, RobustBench",2,Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks,Aamir Mustafa; Salman Khan; Munawar Hayat; Roland Goecke; Jianbing Shen...,2019-04-01,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,11.5,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1904.02144,"CleverHans, Foolbox, IBM ART",3,HopSkipJumpAttack: A Query-Efficient Decision-Based Attack,Jianbo Chen; Michael I. Jordan; Martin J. Wainwright,2019-04-03,2019-04-11,CleverHans,CleverHans:2019-04-11; Foolbox:2019-04-23; IBM ART:2019-06-12,0.3,Attack,Evasion,Vision,arXiv-only,Yes,At-pub,Black,No,No
2+ artifacts,YES,1904.12843,"AutoAttack, RobustBench",2,Adversarial Training for Free!,Ali Shafahi; Mahyar Najibi; Amin Ghiasi; Zheng Xu; John Dickerson...,2019-04-29,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,10.6,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1904.13000,"CleverHans, Foolbox",2,Adversarial Training and Robustness for Multiple Perturbations,Florian Tramèr; Dan Boneh,2019-04-30,2019-05-01,CleverHans,CleverHans:2019-05-01; Foolbox:2019-10-17,0.0,Attack/Defense,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1905.00877,"AutoAttack, RobustBench",2,You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle,Dinghuai Zhang; Tianyuan Zhang; Yiping Lu; Zhanxing Zhu; Bin Dong,2019-05-02,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,10.5,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1905.05186,"AutoAttack, RobustBench",2,Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models,Mayank Singh; Abhishek Sinha; Nupur Kumari; Harshitha Machiraju; Balaji Krishnamurthy...,2019-05-13,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,10.2,Defense,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,1905.10510,"AutoAttack, RobustBench",2,Enhancing Adversarial Defense by k-Winners-Take-All,Chang Xiao; Peilin Zhong; Changxi Zheng,2019-05-25,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,9.8,Defense,Evasion,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1905.10626,"AutoAttack, RobustBench",2,Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,Tianyu Pang; Kun Xu; Yinpeng Dong; Chao Du; Ning Chen...,2019-05-25,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,9.8,Defense,N/A,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,1905.11911,"AutoAttack, RobustBench",2,Controlling Neural Level Sets,Matan Atzmon; Niv Haim; Lior Yariv; Ofer Israelov; Haggai Maron...,2019-05-28,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,9.7,Defense,N/A,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,1905.13725,"AutoAttack, RobustBench",2,Are Labels Required for Improving Adversarial Robustness?,Jonathan Uesato; Jean-Baptiste Alayrac; Po-Sen Huang; Robert Stanforth; Alhussein Fawzi...,2019-05-31,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,9.6,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1905.13736,"AutoAttack, RobustBench",2,Unlabeled Data Improves Adversarial Robustness,Yair Carmon; Aditi Raghunathan; Ludwig Schmidt; Percy Liang; John C. Duchi,2019-05-31,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,9.6,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1906.06316,"AutoAttack, RobustBench",2,Towards Stable and Efficient Training of Verifiably Robust Neural Networks,Huan Zhang; Hongge Chen; Chaowei Xiao; Sven Gowal; Robert Stanforth...,2019-06-14,2020-03-25,AutoAttack,AutoAttack:2020-03-25; RobustBench:2020-08-03,9.4,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,1907.01003,"Foolbox, IBM ART",2,"Accurate, reliable and fast robustness evaluation",Wieland Brendel; Jonas Rauber; Matthias Kümmerer; Ivan Ustyuzhaninov; Matthias Bethge,2019-07-01,2020-01-03,Foolbox,Foolbox:2020-01-03; IBM ART:2020-09-25,6.1,Attack,Evasion,Vision,ML,Yes,Never,White,Yes,No
2+ artifacts,YES,1907.02610,"AutoAttack, RobustBench",2,Adversarial Robustness through Local Linearization,Chongli Qin; James Martens; Sven Gowal; Dilip Krishnan; Krishnamurthy Dvijotham...,2019-07-04,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,8.4,Defense,N/A,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,1912.00049,"AutoAttack, IBM ART",2,Square Attack: a query-efficient black-box adversarial attack via random search,Maksym Andriushchenko; Francesco Croce; Nicolas Flammarion; Matthias Hein,2019-11-29,2020-02-22,AutoAttack,AutoAttack:2020-02-22; IBM ART:2020-04-12,2.8,Attack,Evasion,Vision,ML,Yes,At-pub,Black,No,No
2+ artifacts,YES,1912.10185,"AutoAttack, RobustBench",2,Jacobian Adversarially Regularized Networks for Robustness,Alvin Chan; Yi Tay; Yew Soon Ong; Jie Fu,2019-12-21,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,2.9,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2001.03994,"AutoAttack, RobustBench",2,Fast is better than free: Revisiting adversarial training,Eric Wong; Leslie Rice; J. Zico Kolter,2020-01-12,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,2.1,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2002.08347,"AutoAttack, RobustBench",2,On Adaptive Attacks to Adversarial Example Defenses,Florian Tramer; Nicholas Carlini; Wieland Brendel; Aleksander Madry,2020-02-19,2020-08-25,RobustBench,RobustBench:2020-08-25; AutoAttack:2021-09-09,6.2,Evaluation,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,2002.08619,"AutoAttack, RobustBench",2,Boosting Adversarial Training with Hypersphere Embedding,Tianyu Pang; Xiao Yang; Yinpeng Dong; Kun Xu; Jun Zhu...,2020-02-20,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,0.9,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2002.10319,"AutoAttack, RobustBench",2,Self-Adaptive Training: beyond Empirical Risk Minimization,Lang Huang; Chao Zhang; Hongyang Zhang,2020-02-24,2020-07-11,AutoAttack,AutoAttack:2020-07-11; RobustBench:2020-07-11,4.5,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2002.11242,"AutoAttack, RobustBench",2,Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,Jingfeng Zhang; Xilie Xu; Bo Han; Gang Niu; Lizhen Cui...,2020-02-26,2020-09-02,RobustBench,RobustBench:2020-09-02; AutoAttack:2020-09-03,6.2,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2002.11569,"AutoAttack, RobustBench",2,Overfitting in adversarially robust deep learning,Leslie Rice; Eric Wong; J. Zico Kolter,2020-02-26,2020-04-06,AutoAttack,AutoAttack:2020-04-06; RobustBench:2020-07-01,1.3,Defense,Evasion,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,2003.01690,"AutoAttack, IBM ART, RobustBench",3,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,Francesco Croce; Matthias Hein,2020-03-03,2020-03-17,AutoAttack,AutoAttack:2020-03-17; IBM ART:2020-04-12; RobustBench:2020-08-03,0.5,Evaluation,Evasion,Vision,ML,Yes,At-pub,White,Yes,No
2+ artifacts,YES,2003.04286,"AutoAttack, RobustBench",2,Manifold Regularization for Locally Stable Deep Neural Networks,Charles Jin; Martin Rinard,2020-03-09,2020-03-17,AutoAttack,AutoAttack:2020-03-17; RobustBench:2020-07-01,0.3,Defense,N/A,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,2003.09461,"AutoAttack, RobustBench",2,Adversarial Robustness on In- and Out-Distribution Improves Explainability,Maximilian Augustin; Alexander Meinke; Matthias Hein,2020-03-20,2020-08-04,AutoAttack,AutoAttack:2020-08-04; RobustBench:2020-08-05,4.5,Defense,N/A,Vision,ML,No,Never,N/A,N/A,No
2+ artifacts,YES,2003.12862,"AutoAttack, RobustBench",2,Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning,Tianlong Chen; Sijia Liu; Shiyu Chang; Yu Cheng; Lisa Amini...,2020-03-28,2020-07-01,RobustBench,RobustBench:2020-07-01; AutoAttack:2020-07-02,3.1,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2004.05884,"AutoAttack, RobustBench",2,Adversarial Weight Perturbation Helps Robust Generalization,Dongxian Wu; Shu-tao Xia; Yisen Wang,2020-04-13,2020-10-15,AutoAttack,AutoAttack:2020-10-15; RobustBench:2020-10-22,6.1,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2010.00467,"AutoAttack, RobustBench",2,Bag of Tricks for Adversarial Training,Tianyu Pang; Xiao Yang; Yinpeng Dong; Hang Su; Jun Zhu,2020-10-01,2020-10-17,AutoAttack,AutoAttack:2020-10-17; RobustBench:2021-02-16,0.5,Defense,N/A,Vision,ML,Yes,At-pub,N/A,N/A,No
2+ artifacts,YES,2010.01279,"AutoAttack, RobustBench",2,Do Wider Neural Networks Really Help Adversarial Robustness?,Boxi Wu; Jinghui Chen; Deng Cai; Xiaofei He; Quanquan Gu,2020-10-03,2020-10-06,AutoAttack,AutoAttack:2020-10-06; RobustBench:2021-02-16,0.1,Defense/Evaluation,Evasion,Vision,ML,No,Never,White,No,No
2+ artifacts,YES,2010.03593,"AutoAttack, RobustBench",2,Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples,Sven Gowal; Chongli Qin; Jonathan Uesato; Timothy Mann; Pushmeet Kohli,2020-10-07,2020-10-17,AutoAttack,AutoAttack:2020-10-17; RobustBench:2021-02-16,0.3,Defense/Evaluation,N/A,Vision,ML,Yes,At-pub,White,N/A,No
2+ artifacts,YES,2010.09670,"AutoAttack, RobustBench",2,RobustBench: a standardized adversarial robustness benchmark,Francesco Croce; Maksym Andriushchenko; Vikash Sehwag; Edoardo Debenedetti; Nicolas Flammarion...,2020-10-19,2020-10-20,RobustBench,RobustBench:2020-10-20; AutoAttack:2021-09-14,0.0,Defense/Evaluatio,N/A,Vision,ML,Yes,At-pub,White,N/A,No
2+ artifacts,YES,2011.11164,"AutoAttack, RobustBench",2,Learnable Boundary Guided Adversarial Training,Jiequan Cui; Shu Liu; Liwei Wang; Jiaya Jia,2020-11-23,2020-11-25,AutoAttack,AutoAttack:2020-11-25; RobustBench:2021-02-16,0.1,Defense/Evaluation,N/A,Vision,ML,Yes,At-pub,White,No,N/A
2+ artifacts,YES,2106.09947,"AutoAttack, IBM ART",2,Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples,Maura Pintor; Luca Demetrio; Angelo Sotgiu; Ambra Demontis; Nicholas Carlini...,2021-06-18,2021-09-14,AutoAttack,AutoAttack:2021-09-14; IBM ART:2021-12-08,2.9,Evaluation/Attack,Evasion,Vision,ML,Yes,At-pub,White,Yes,N/A
2+ artifacts,YES,2401.06373,"HarmBench, PyRIT",2,How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs,Yi Zeng; Hongpeng Lin; Jingwen Zhang; Diyi Yang; Ruoxi Jia...,2024-01-12,2024-02-27,HarmBench,HarmBench:2024-02-27; PyRIT:2024-06-25,1.5,Attack/Defense/Evaluation,Evasion,LLM,ML,Yes,At-pub,Black,Yes,Yes
2+ artifacts,YES,2402.04249,"HarmBench, PyRIT",2,HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal,Mantas Mazeika; Long Phan; Xuwang Yin; Andy Zou; Zifan Wang...,2024-02-06,2024-02-07,HarmBench,HarmBench:2024-02-07; PyRIT:2025-10-12,0.0,Attack/Defense/Evaluation,Evasion,LLM,ML,Yes,At-pub,White/Black,Yes,Yes
MITRE ATLAS (regulatory),YES,1802.03162,MITRE ATLAS,1,URLNet: Learning a URL Representation with Deep Learning for Malicious URL Detection,Hung Le; Quang Pham; Doyen Sahoo; Steven C. H. Hoi,2018-02-09,2021-03-16,MITRE ATLAS,MITRE ATLAS:2021-03-16,37.2,Defense/Evaluation,N/A,Malware,Security,Yes,At-pub,N/A,N/A,N/A
MITRE ATLAS (regulatory),YES,2004.15015,MITRE ATLAS,1,Imitation Attacks and Defenses for Black-box Machine Translation Systems,Eric Wallace; Mitchell Stern; Dawn Song,2020-04-30,2021-03-16,MITRE ATLAS,MITRE ATLAS:2021-03-16,10.5,Attack,N/A,NLP,arXiv-only,Yes,At-pub,N/A,N/A,No
MITRE ATLAS (regulatory),YES,2101.06896,MITRE ATLAS,1,DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection,Yuanchun Li; Jiayi Hua; Haoyu Wang; Chunyang Chen; Yunxin Liu,2021-01-18,2021-10-29,MITRE ATLAS,MITRE ATLAS:2021-10-29,9.3,Attack/Evaluation,Poisoning,Vision,Security,No,Never,Black,Yes,N/A
MITRE ATLAS (regulatory),YES,2103.03874,MITRE ATLAS,1,Measuring Mathematical Problem Solving With the MATH Dataset,Dan Hendrycks; Collin Burns; Saurav Kadavath; Akul Arora; Steven Basart...,2021-03-05,2023-03-01,MITRE ATLAS,MITRE ATLAS:2023-03-01,23.9,Evaluation,N/A,LLM,ML,Yes,At-pub,N/A,N/A,N/A
MITRE ATLAS (regulatory),YES,2110.14168,MITRE ATLAS,1,Training Verifiers to Solve Math Word Problems,Karl Cobbe; Vineet Kosaraju; Mohammad Bavarian; Mark Chen; Heewoo Jun...,2021-10-27,2023-03-01,MITRE ATLAS,MITRE ATLAS:2023-03-01,16.1,Defense,N/A,LLM,arXiv-only,Yes,At-pub,N/A,N/A,No
MITRE ATLAS (regulatory),YES,2203.09509,MITRE ATLAS,1,ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,Thomas Hartvigsen; Saadia Gabriel; Hamid Palangi; Maarten Sap; Dipankar Ray...,2022-03-17,2023-10-30,MITRE ATLAS,MITRE ATLAS:2023-10-30,19.4,Attack/Defense/Evalution,N/A,NLP,ML,Yes,At-pub,White/Black,Yes,No
MITRE ATLAS (regulatory),YES,2212.14315,MITRE ATLAS,1,"""Real Attackers Don't Compute Gradients"": Bridging the Gap Between Adversarial ML Research and Practice",Giovanni Apruzzese; Hyrum S. Anderson; Savino Dambra; David Freeman; Fabio Pierazzi...,2022-12-29,2025-09-29,MITRE ATLAS,MITRE ATLAS:2025-09-29,33.0,Evaluation,Evasion,Cross-domain,Security,Yes,At-pub,Black,Yes,Yes
MITRE ATLAS (regulatory),YES,2302.10149,MITRE ATLAS,1,Poisoning Web-Scale Training Datasets is Practical,Nicholas Carlini; Matthew Jagielski; Christopher A. Choquette-Choo; Daniel Paleka; Will Pearce...,2023-02-20,2024-10-01,MITRE ATLAS,MITRE ATLAS:2024-10-01,19.3,Attack,Poisoning,Cross-domain,Security,Yes,At-pub,Black,Yes,N/A
MITRE ATLAS (regulatory),YES,2403.02817,MITRE ATLAS,1,Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications,Stav Cohen; Ron Bitton; Ben Nassi,2024-03-05,2024-10-01,MITRE ATLAS,MITRE ATLAS:2024-10-01,6.9,Attack/Defense,Poisoning,LLM,Security,Yes,At-pub,Black,Yes,Yes
MITRE ATLAS (regulatory),YES,2406.11717,MITRE ATLAS,1,Refusal in Language Models Is Mediated by a Single Direction,Andy Arditi; Oscar Obeso; Aaquib Syed; Daniel Paleka; Nina Panickssery...,2024-06-17,2025-12-24,MITRE ATLAS,MITRE ATLAS:2025-12-24,18.2,Attack,Evasion,LLM,ML,Yes,At-pub,White,Yes,N/A
