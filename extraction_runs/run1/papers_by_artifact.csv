is_aml_paper,arxiv_id,found_in_artifacts,num_artifacts,paper_title,paper_authors,paper_pub_date,first_adoption_date,first_adoption_artifact,all_adoptions,adoption_lag_months,G1,G2,G3,G4,G5,G6,T1,T2,Q1
YES,1907.02044,AutoAttack,1,Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack,Francesco Croce; Matthias Hein,2019-07-03,2020-02-17,AutoAttack,AutoAttack:2020-02-17; AutoAttack:2020-02-17; AutoAttack:2020-02-17; AutoAttack:2020-02-17,7.5,,,,,,,,,
YES,2103.01208,AutoAttack,1,Mind the box: $l_1$-APGD for sparse adversarial attacks on image classifiers,Francesco Croce; Matthias Hein,2021-03-01,2020-02-17,AutoAttack,AutoAttack:2020-02-17,-12.4,,,,,,,,,
YES,1706.06083,"AutoAttack, CleverHans, IBM ART, RobustBench",4,Towards Deep Learning Models Resistant to Adversarial Attacks,Aleksander Madry; Aleksandar Makelov; Ludwig Schmidt; Dimitris Tsipras; Adrian Vladu,2017-06-19,2016-09-14,CleverHans,CleverHans:2017-09-26; CleverHans:2017-09-26; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2016-09-14; CleverHans:2017-09-26; IBM ART:2020-10-09; IBM ART:2020-02-19; IBM ART:2020-04-16; IBM ART:2018-09-26; IBM ART:2018-09-26; IBM ART:2018-09-26; IBM ART:2019-09-03; RobustBench:2020-07-03; AutoAttack:2020-02-17,-9.1,,,,,,,,,
YES,1802.00420,"AutoAttack, CleverHans, IBM ART, RobustBench",4,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,Anish Athalye; Nicholas Carlini; David Wagner,2018-02-01,2018-02-23,IBM ART,CleverHans:2018-10-08; CleverHans:2019-01-09; CleverHans:2019-04-10; IBM ART:2018-10-23; IBM ART:2018-03-20; IBM ART:2018-08-22; IBM ART:2018-02-27; IBM ART:2020-02-19; IBM ART:2018-02-23; RobustBench:2020-06-28; AutoAttack:2020-02-17,0.7,,,,,,,,,
YES,1811.09600,"AutoAttack, Foolbox, RobustBench",3,Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses,Jérôme Rony; Luiz G. Hafemann; Luiz S. Oliveira; Ismail Ben Ayed; Robert Sabourin...,2018-11-23,2020-02-07,Foolbox,Foolbox:2020-02-07; RobustBench:2020-06-28; RobustBench:2020-09-03; AutoAttack:2020-02-17,14.5,,,,,,,,,
YES,1810.12715,"AutoAttack, IBM ART",2,On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models,Sven Gowal; Krishnamurthy Dvijotham; Robert Stanforth; Rudy Bunel; Chongli Qin...,2018-10-30,2020-02-17,AutoAttack,IBM ART:2022-08-10; IBM ART:2022-08-10; AutoAttack:2020-02-17,15.6,,,,,,,,,
YES,1912.00049,"AutoAttack, IBM ART",2,Square Attack: a query-efficient black-box adversarial attack via random search,Maksym Andriushchenko; Francesco Croce; Nicolas Flammarion; Matthias Hein,2019-11-29,2019-11-08,IBM ART,IBM ART:2019-11-08; AutoAttack:2020-02-17; AutoAttack:2020-02-17,-0.7,,,,,,,,,
YES,2106.09947,"AutoAttack, IBM ART",2,Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples,Maura Pintor; Luca Demetrio; Angelo Sotgiu; Ambra Demontis; Nicholas Carlini...,2021-06-18,2021-08-31,AutoAttack,IBM ART:2021-11-12; AutoAttack:2021-08-31,2.4,,,,,,,,,
YES,1902.06705,"AutoAttack, IBM ART, RobustBench",3,On Evaluating Adversarial Robustness,Nicholas Carlini; Anish Athalye; Nicolas Papernot; Wieland Brendel; Jonas Rauber...,2019-02-18,2018-02-23,IBM ART,IBM ART:2018-08-01; IBM ART:2020-06-03; IBM ART:2018-10-23; IBM ART:2018-03-20; IBM ART:2018-02-27; IBM ART:2018-08-22; IBM ART:2020-04-30; IBM ART:2019-03-12; IBM ART:2018-02-27; IBM ART:2020-07-23; IBM ART:2018-03-20; IBM ART:2020-06-03; IBM ART:2018-03-20; IBM ART:2020-06-03; IBM ART:2018-02-27; IBM ART:2018-03-20; IBM ART:2022-09-14; IBM ART:2022-09-14; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2022-10-19; IBM ART:2022-10-19; IBM ART:2022-10-19; IBM ART:2020-02-19; IBM ART:2018-02-23; IBM ART:2019-11-08; IBM ART:2019-11-08; RobustBench:2020-06-28; AutoAttack:2021-08-31,-11.8,,,,,,,,,
YES,2003.01690,"AutoAttack, IBM ART, RobustBench",3,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,Francesco Croce; Matthias Hein,2020-03-03,2019-11-08,IBM ART,IBM ART:2019-11-08; IBM ART:2019-11-08; RobustBench:2020-06-28; AutoAttack:2021-03-02; AutoAttack:2021-08-31; AutoAttack:2020-02-17,-3.8,,,,,,,,,
YES,1901.08573,"AutoAttack, RobustBench",2,Theoretically Principled Trade-off between Robustness and Accuracy,Hongyang Zhang; Yaodong Yu; Jiantao Jiao; Eric P. Xing; Laurent El Ghaoui...,2019-01-24,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2020-02-17,12.8,,,,,,,,,
YES,1901.09960,"AutoAttack, RobustBench",2,Using Pre-Training Can Improve Model Robustness and Uncertainty,Dan Hendrycks; Kimin Lee; Mantas Mazeika,2019-01-28,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; RobustBench:2020-07-03; AutoAttack:2020-02-17,12.6,,,,,,,,,
YES,1904.00887,"AutoAttack, RobustBench",2,Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks,Aamir Mustafa; Salman Khan; Munawar Hayat; Roland Goecke; Jianbing Shen...,2019-04-01,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,10.6,,,,,,,,,
YES,1904.12843,"AutoAttack, RobustBench",2,Adversarial Training for Free!,Ali Shafahi; Mahyar Najibi; Amin Ghiasi; Zheng Xu; John Dickerson...,2019-04-29,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,9.7,,,,,,,,,
YES,1905.00877,"AutoAttack, RobustBench",2,You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle,Dinghuai Zhang; Tianyuan Zhang; Yiping Lu; Zhanxing Zhu; Bin Dong,2019-05-02,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2020-02-17,9.6,,,,,,,,,
YES,1905.05186,"AutoAttack, RobustBench",2,Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models,Mayank Singh; Abhishek Sinha; Nupur Kumari; Harshitha Machiraju; Balaji Krishnamurthy...,2019-05-13,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,9.2,,,,,,,,,
YES,1905.10510,"AutoAttack, RobustBench",2,Enhancing Adversarial Defense by k-Winners-Take-All,Chang Xiao; Peilin Zhong; Changxi Zheng,2019-05-25,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,8.8,,,,,,,,,
YES,1905.10626,"AutoAttack, RobustBench",2,Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness,Tianyu Pang; Kun Xu; Yinpeng Dong; Chao Du; Ning Chen...,2019-05-25,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,8.8,,,,,,,,,
YES,1905.11911,"AutoAttack, RobustBench",2,Controlling Neural Level Sets,Matan Atzmon; Niv Haim; Lior Yariv; Ofer Israelov; Haggai Maron...,2019-05-28,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,8.7,,,,,,,,,
YES,1905.13725,"AutoAttack, RobustBench",2,Are Labels Required for Improving Adversarial Robustness?,Jonathan Uesato; Jean-Baptiste Alayrac; Po-Sen Huang; Robert Stanforth; Alhussein Fawzi...,2019-05-31,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,8.6,,,,,,,,,
YES,1905.13736,"AutoAttack, RobustBench",2,Unlabeled Data Improves Adversarial Robustness,Yair Carmon; Aditi Raghunathan; Ludwig Schmidt; Percy Liang; John C. Duchi,2019-05-31,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2020-02-17,8.6,,,,,,,,,
YES,1906.06316,"AutoAttack, RobustBench",2,Towards Stable and Efficient Training of Verifiably Robust Neural Networks,Huan Zhang; Hongge Chen; Chaowei Xiao; Sven Gowal; Robert Stanforth...,2019-06-14,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2021-07-14; AutoAttack:2020-02-17,8.1,,,,,,,,,
YES,1907.02610,"AutoAttack, RobustBench",2,Adversarial Robustness through Local Linearization,Chongli Qin; James Martens; Sven Gowal; Dilip Krishnan; Krishnamurthy Dvijotham...,2019-07-04,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,7.5,,,,,,,,,
YES,1912.10185,"AutoAttack, RobustBench",2,Jacobian Adversarially Regularized Networks for Robustness,Alvin Chan; Yi Tay; Yew Soon Ong; Jie Fu,2019-12-21,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,1.9,,,,,,,,,
YES,2001.03994,"AutoAttack, RobustBench",2,Fast is better than free: Revisiting adversarial training,Eric Wong; Leslie Rice; J. Zico Kolter,2020-01-12,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; RobustBench:2020-07-03; AutoAttack:2020-02-17,1.2,,,,,,,,,
YES,2002.08347,"AutoAttack, RobustBench",2,On Adaptive Attacks to Adversarial Example Defenses,Florian Tramer; Nicholas Carlini; Wieland Brendel; Aleksander Madry,2020-02-19,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2021-08-31,4.3,,,,,,,,,
YES,2002.08619,"AutoAttack, RobustBench",2,Boosting Adversarial Training with Hypersphere Embedding,Tianyu Pang; Xiao Yang; Yinpeng Dong; Kun Xu; Jun Zhu...,2020-02-20,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2020-02-17,-0.1,,,,,,,,,
YES,2002.10319,"AutoAttack, RobustBench",2,Self-Adaptive Training: beyond Empirical Risk Minimization,Lang Huang; Chao Zhang; Hongyang Zhang,2020-02-24,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-11; AutoAttack:2020-02-17,-0.2,,,,,,,,,
YES,2002.11242,"AutoAttack, RobustBench",2,Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,Jingfeng Zhang; Xilie Xu; Bo Han; Gang Niu; Lizhen Cui...,2020-02-26,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-09-02; AutoAttack:2020-02-17,-0.3,,,,,,,,,
YES,2002.11569,"AutoAttack, RobustBench",2,Overfitting in adversarially robust deep learning,Leslie Rice; Eric Wong; J. Zico Kolter,2020-02-26,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; RobustBench:2020-07-03; RobustBench:2020-07-03; AutoAttack:2020-02-17,-0.3,,,,,,,,,
YES,2003.04286,"AutoAttack, RobustBench",2,Manifold Regularization for Locally Stable Deep Neural Networks,Charles Jin; Martin Rinard,2020-03-09,2020-02-17,AutoAttack,RobustBench:2020-07-03; AutoAttack:2020-02-17,-0.7,,,,,,,,,
YES,2003.09461,"AutoAttack, RobustBench",2,Adversarial Robustness on In- and Out-Distribution Improves Explainability,Maximilian Augustin; Alexander Meinke; Matthias Hein,2020-03-20,2020-02-17,AutoAttack,RobustBench:2021-01-14; RobustBench:2020-06-28; RobustBench:2020-09-03; RobustBench:2020-09-03; RobustBench:2020-09-03; AutoAttack:2020-02-17,-1.1,,,,,,,,,
YES,2003.12862,"AutoAttack, RobustBench",2,Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning,Tianlong Chen; Sijia Liu; Shiyu Chang; Yu Cheng; Lisa Amini...,2020-03-28,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-07-03; AutoAttack:2020-02-17,-1.3,,,,,,,,,
YES,2004.05884,"AutoAttack, RobustBench",2,Adversarial Weight Perturbation Helps Robust Generalization,Dongxian Wu; Shu-tao Xia; Yisen Wang,2020-04-13,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2020-10-22; RobustBench:2020-10-22; RobustBench:2020-10-22; RobustBench:2020-10-22; AutoAttack:2020-02-17,-1.8,,,,,,,,,
YES,2010.00467,"AutoAttack, RobustBench",2,Bag of Tricks for Adversarial Training,Tianyu Pang; Xiao Yang; Yinpeng Dong; Hang Su; Jun Zhu,2020-10-01,2020-02-17,AutoAttack,RobustBench:2021-02-16; AutoAttack:2020-02-17,-7.5,,,,,,,,,
YES,2010.01279,"AutoAttack, RobustBench",2,Do Wider Neural Networks Really Help Adversarial Robustness?,Boxi Wu; Jinghui Chen; Deng Cai; Xiaofei He; Quanquan Gu,2020-10-03,2020-02-17,AutoAttack,RobustBench:2021-02-16; AutoAttack:2020-02-17,-7.5,,,,,,,,,
YES,2010.03593,"AutoAttack, RobustBench",2,Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples,Sven Gowal; Chongli Qin; Jonathan Uesato; Timothy Mann; Pushmeet Kohli,2020-10-07,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; AutoAttack:2020-02-17,-7.7,,,,,,,,,
YES,2010.09670,"AutoAttack, RobustBench",2,RobustBench: a standardized adversarial robustness benchmark,Francesco Croce; Maksym Andriushchenko; Vikash Sehwag; Edoardo Debenedetti; Nicolas Flammarion...,2020-10-19,2020-06-28,RobustBench,RobustBench:2020-06-28; AutoAttack:2021-08-31,-3.7,,,,,,,,,
YES,2011.11164,"AutoAttack, RobustBench",2,Learnable Boundary Guided Adversarial Training,Jiequan Cui; Shu Liu; Liwei Wang; Jiaya Jia,2020-11-23,2020-02-17,AutoAttack,RobustBench:2020-06-28; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; RobustBench:2021-02-16; AutoAttack:2020-02-17,-9.2,,,,,,,,,
YES,1412.6558,CleverHans,1,Random Walk Initialization for Training Very Deep Feedforward Networks,David Sussillo; L. F. Abbott,2014-12-19,2018-08-24,CleverHans,CleverHans:2018-08-24,44.2,,,,,,,,,
YES,1511.06581,CleverHans,1,Dueling Network Architectures for Deep Reinforcement Learning,Ziyu Wang; Tom Schaul; Matteo Hessel; Hado van Hasselt; Marc Lanctot...,2015-11-20,2018-01-23,CleverHans,CleverHans:2018-01-23,26.1,,,,,,,,,
NO - Exclude,1512.03385,CleverHans,1,Deep Residual Learning for Image Recognition,Kaiming He; Xiangyu Zhang; Shaoqing Ren; Jian Sun,2015-12-10,2017-09-26,CleverHans,CleverHans:2017-09-26,21.6,,,,,,,,,
YES,1602.02697,CleverHans,1,Practical Black-Box Attacks against Machine Learning,Nicolas Papernot; Patrick McDaniel; Ian Goodfellow; Somesh Jha; Z. Berkay Celik...,2016-02-08,2016-09-14,CleverHans,CleverHans:2016-09-14; CleverHans:2017-02-04; CleverHans:2016-09-14,7.2,,,,,,,,,
YES,1602.07261,CleverHans,1,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",Christian Szegedy; Sergey Ioffe; Vincent Vanhoucke; Alex Alemi,2016-02-23,2017-08-23,CleverHans,CleverHans:2017-08-23,18.0,,,,,,,,,
YES,1603.05027,CleverHans,1,Identity Mappings in Deep Residual Networks,Kaiming He; Xiangyu Zhang; Shaoqing Ren; Jian Sun,2016-03-16,2017-09-26,CleverHans,CleverHans:2017-09-26,18.4,,,,,,,,,
YES,1605.07146,CleverHans,1,Wide Residual Networks,Sergey Zagoruyko; Nikos Komodakis,2016-05-23,2017-09-26,CleverHans,CleverHans:2017-09-26; CleverHans:2018-05-18,16.1,,,,,,,,,
YES,1610.00768,CleverHans,1,Technical Report on the CleverHans v2.1.0 Adversarial Examples Library,Nicolas Papernot; Fartash Faghri; Nicholas Carlini; Ian Goodfellow; Reuben Feinman...,2016-10-03,2016-09-14,CleverHans,CleverHans:2016-09-14; CleverHans:2016-09-14,-0.6,,,,,,,,,
YES,1703.06857,CleverHans,1,On the Limitation of Convolutional Neural Networks in Recognizing Negative Images,Hossein Hosseini; Baicen Xiao; Mayoore Jaiswal; Radha Poovendran,2017-03-20,2019-01-09,CleverHans,CleverHans:2019-01-09; CleverHans:2019-04-20,21.7,,,,,,,,,
YES,1706.10295,CleverHans,1,Noisy Networks for Exploration,Meire Fortunato; Mohammad Gheshlaghi Azar; Bilal Piot; Jacob Menick; Ian Osband...,2017-06-30,2018-01-23,CleverHans,CleverHans:2018-01-23,6.8,,,,,,,,,
YES,1712.09344,CleverHans,1,"Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger",Vahid Behzadan; Arslan Munir,2017-12-23,2018-01-23,CleverHans,CleverHans:2018-01-23,1.0,,,,,,,,,
YES,1802.05666,CleverHans,1,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks,Jonathan Uesato; Brendan O'Donoghue; Aaron van den Oord; Pushmeet Kohli,2018-02-15,2019-01-09,CleverHans,CleverHans:2019-01-09; CleverHans:2019-01-09; CleverHans:2019-07-11,10.8,,,,,,,,,
YES,1803.04765,CleverHans,1,"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning",Nicolas Papernot; Patrick McDaniel,2018-03-13,2019-01-24,CleverHans,CleverHans:2019-01-24,10.4,,,,,,,,,
YES,1803.08494,CleverHans,1,Group Normalization,Yuxin Wu; Kaiming He,2018-03-22,2018-08-24,CleverHans,CleverHans:2018-08-24,5.1,,,,,,,,,
YES,1804.00097,CleverHans,1,Adversarial Attacks and Defences Competition,Alexey Kurakin; Ian Goodfellow; Samy Bengio; Yinpeng Dong; Fangzhou Liao...,2018-03-31,2018-03-09,CleverHans,CleverHans:2018-03-09,-0.7,,,,,,,,,
YES,1811.03685,CleverHans,1,New CleverHans Feature: Better Adversarial Robustness Evaluations with Attack Bundling,Ian Goodfellow,2018-11-08,2018-10-08,CleverHans,CleverHans:2018-10-08,-1.0,,,,,,,,,
YES,1902.01889,CleverHans,1,Analyzing and Improving Representations with the Soft Nearest Neighbor Loss,Nicholas Frosst; Nicolas Papernot; Geoffrey Hinton,2019-02-05,2018-06-11,CleverHans,CleverHans:2018-06-11; CleverHans:2019-02-16; CleverHans:2019-02-16,-7.9,,,,,,,,,
YES,1902.08295,CleverHans,1,Lingvo: a Modular and Scalable Framework for Sequence-to-Sequence Modeling,Jonathan Shen; Patrick Nguyen; Yonghui Wu; Zhifeng Chen; Mia X. Chen...,2019-02-21,2019-06-05,CleverHans,CleverHans:2019-06-05,3.4,,,,,,,,,
YES,1904.13000,"CleverHans, Foolbox",2,Adversarial Training and Robustness for Multiple Perturbations,Florian Tramèr; Dan Boneh,2019-04-30,2019-04-20,CleverHans,CleverHans:2019-04-20; CleverHans:2021-03-18; Foolbox:2020-02-23,-0.3,,,,,,,,,
YES,1507.00677,"CleverHans, Foolbox, IBM ART",3,Distributional Smoothing with Virtual Adversarial Training,Takeru Miyato; Shin-ichi Maeda; Masanori Koyama; Ken Nakae; Shin Ishii,2015-07-02,2017-06-12,IBM ART,CleverHans:2019-01-09; IBM ART:2017-06-12; Foolbox:2020-02-07,23.4,,,,,,,,,
YES,1511.04599,"CleverHans, Foolbox, IBM ART",3,DeepFool: a simple and accurate method to fool deep neural networks,Seyed-Mohsen Moosavi-Dezfooli; Alhussein Fawzi; Pascal Frossard,2015-11-14,2017-06-01,IBM ART,CleverHans:2019-01-09; IBM ART:2017-06-08; IBM ART:2017-06-01; Foolbox:2020-01-14,18.6,,,,,,,,,
YES,1607.02533,"CleverHans, Foolbox, IBM ART",3,Adversarial examples in the physical world,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-07-08,2017-05-09,IBM ART,CleverHans:2018-07-23; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2018-12-26; IBM ART:2017-05-09; IBM ART:2018-06-28; Foolbox:2019-12-11,10.0,,,,,,,,,
YES,1608.04644,"CleverHans, Foolbox, IBM ART",3,Towards Evaluating the Robustness of Neural Networks,Nicholas Carlini; David Wagner,2016-08-16,2017-11-28,IBM ART,CleverHans:2019-01-09; CleverHans:2020-04-03; CleverHans:2020-01-02; IBM ART:2017-11-28; Foolbox:2019-10-30,15.4,,,,,,,,,
YES,1710.06081,"CleverHans, Foolbox, IBM ART",3,Boosting Adversarial Attacks with Momentum,Yinpeng Dong; Fangzhou Liao; Tianyu Pang; Hang Su; Jun Zhu...,2017-10-17,2018-06-28,IBM ART,CleverHans:2019-01-09; CleverHans:2019-10-04; IBM ART:2018-06-28; Foolbox:2023-11-09,8.3,,,,,,,,,
YES,1904.02144,"CleverHans, Foolbox, IBM ART",3,HopSkipJumpAttack: A Query-Efficient Decision-Based Attack,Jianbo Chen; Michael I. Jordan; Martin J. Wainwright,2019-04-03,2017-06-01,IBM ART,CleverHans:2019-04-11; CleverHans:2020-05-06; IBM ART:2017-06-01; Foolbox:2020-08-29,-22.0,,,,,,,,,
YES,1412.6572,"CleverHans, IBM ART",2,Explaining and Harnessing Adversarial Examples,Ian J. Goodfellow; Jonathon Shlens; Christian Szegedy,2014-12-20,2016-09-14,CleverHans,CleverHans:2018-07-23; CleverHans:2018-12-26; CleverHans:2016-09-14; CleverHans:2018-07-23; CleverHans:2016-09-14; CleverHans:2016-09-14; CleverHans:2019-01-23; CleverHans:2018-06-12; CleverHans:2018-12-26; CleverHans:2019-04-22; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2018-12-26; CleverHans:2019-06-27; CleverHans:2016-09-14; CleverHans:2016-09-14; CleverHans:2017-03-23; IBM ART:2017-06-07,20.8,,,,,,,,,
YES,1511.05122,"CleverHans, IBM ART",2,Adversarial Manipulation of Deep Representations,Sara Sabour; Yanshuai Cao; Fartash Faghri; David J. Fleet,2015-11-16,2019-01-09,CleverHans,CleverHans:2019-01-09; IBM ART:2021-05-26; IBM ART:2020-04-10; IBM ART:2021-05-26; IBM ART:2019-09-03,37.8,,,,,,,,,
YES,1511.07528,"CleverHans, IBM ART",2,The Limitations of Deep Learning in Adversarial Settings,Nicolas Papernot; Patrick McDaniel; Somesh Jha; Matt Fredrikson; Z. Berkay Celik...,2015-11-24,2016-09-14,CleverHans,CleverHans:2019-01-09; CleverHans:2016-11-18; CleverHans:2016-09-14; IBM ART:2017-06-12,9.7,,,,,,,,,
YES,1611.01236,"CleverHans, IBM ART",2,Adversarial Machine Learning at Scale,Alexey Kurakin; Ian Goodfellow; Samy Bengio,2016-11-04,2017-06-07,IBM ART,CleverHans:2018-07-23; CleverHans:2018-12-26; CleverHans:2019-04-20; CleverHans:2018-12-26; CleverHans:2019-10-04; CleverHans:2019-04-22; CleverHans:2018-12-26; CleverHans:2019-07-11; CleverHans:2018-12-26; CleverHans:2020-01-02; CleverHans:2018-12-26; CleverHans:2019-06-27; CleverHans:2017-06-21; IBM ART:2023-12-08; IBM ART:2019-11-08; IBM ART:2020-02-09; IBM ART:2019-11-08; IBM ART:2019-11-08; IBM ART:2017-11-28; IBM ART:2019-11-08; IBM ART:2017-06-07; IBM ART:2019-11-08; IBM ART:2020-04-16; IBM ART:2018-09-26; IBM ART:2018-09-26; IBM ART:2018-09-26,7.1,,,,,,,,,
YES,1705.07204,"CleverHans, IBM ART",2,Ensemble Adversarial Training: Attacks and Defenses,Florian Tramèr; Alexey Kurakin; Nicolas Papernot; Ian Goodfellow; Dan Boneh...,2017-05-19,2017-06-21,CleverHans,CleverHans:2017-06-21; IBM ART:2018-02-23,1.1,,,,,,,,,
YES,1709.04114,"CleverHans, IBM ART",2,EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples,Pin-Yu Chen; Yash Sharma; Huan Zhang; Jinfeng Yi; Cho-Jui Hsieh,2017-09-13,2017-11-28,IBM ART,CleverHans:2019-01-09; IBM ART:2017-11-28,2.5,,,,,,,,,
YES,1710.09412,"CleverHans, IBM ART",2,mixup: Beyond Empirical Risk Minimization,Hongyi Zhang; Moustapha Cisse; Yann N. Dauphin; David Lopez-Paz,2017-10-25,2018-06-11,CleverHans,CleverHans:2018-06-11; IBM ART:2022-10-19; IBM ART:2022-10-19; IBM ART:2022-10-19,7.5,,,,,,,,,
YES,1712.09665,"CleverHans, IBM ART",2,Adversarial Patch,Tom B. Brown; Dandelion Mané; Aurko Roy; Martín Abadi; Justin Gilmer,2017-12-27,2018-02-05,CleverHans,CleverHans:2018-02-05; IBM ART:2019-02-13; IBM ART:2019-05-02; IBM ART:2019-05-02; IBM ART:2019-05-02,1.3,,,,,,,,,
YES,1801.01944,"CleverHans, IBM ART",2,Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,Nicholas Carlini; David Wagner,2018-01-05,2019-03-12,IBM ART,CleverHans:2019-06-05; IBM ART:2019-03-12; IBM ART:2020-12-04; IBM ART:2020-09-04,14.2,,,,,,,,,
NO - Exclude,1412.6980,"CleverHans, PyRIT",2,Adam: A Method for Stochastic Optimization,Diederik P. Kingma; Jimmy Ba,2014-12-22,2019-01-09,CleverHans,CleverHans:2019-01-09; CleverHans:2019-01-09; PyRIT:2025-09-26,48.6,,,,,,,,,
YES,1312.6199,"CleverHans, TextAttack",2,Intriguing properties of neural networks,Christian Szegedy; Wojciech Zaremba; Ilya Sutskever; Joan Bruna; Dumitru Erhan...,2013-12-21,2019-01-09,CleverHans,CleverHans:2019-01-09; TextAttack:2020-08-30,60.6,,,,,,,,,
NO - Exclude,1506.02025,Foolbox,1,Spatial Transformer Networks,Max Jaderberg; Karen Simonyan; Andrew Zisserman; Koray Kavukcuoglu,2015-06-05,2020-03-30,Foolbox,Foolbox:2020-03-30,57.8,,,,,,,,,
YES,1707.04131,Foolbox,1,Foolbox: A Python toolbox to benchmark the robustness of machine learning models,Jonas Rauber; Wieland Brendel; Matthias Bethge,2017-07-13,2017-06-04,Foolbox,Foolbox:2017-06-04; Foolbox:2020-08-10,-1.3,,,,,,,,,
YES,1805.09190,Foolbox,1,Towards the first adversarially robust neural network model on MNIST,Lukas Schott; Jonas Rauber; Matthias Bethge; Wieland Brendel,2018-05-23,2018-01-19,Foolbox,Foolbox:2018-01-19,-4.1,,,,,,,,,
YES,1805.11090,Foolbox,1,GenAttack: Practical Black-box Attacks with Gradient-Free Optimization,Moustafa Alzantot; Yash Sharma; Supriyo Chakraborty; Huan Zhang; Cho-Jui Hsieh...,2018-05-28,2020-03-02,Foolbox,Foolbox:2020-03-02,21.2,,,,,,,,,
YES,2007.07677,Foolbox,1,Fast Differentiable Clipping-Aware Normalization and Rescaling,Jonas Rauber; Matthias Bethge,2020-07-15,2020-01-10,Foolbox,Foolbox:2020-01-10; Foolbox:2020-08-10,-6.1,,,,,,,,,
YES,2008.04175,Foolbox,1,"EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX, and NumPy",Jonas Rauber; Matthias Bethge; Wieland Brendel,2020-08-10,2020-08-10,Foolbox,Foolbox:2020-08-10,0.0,,,,,,,,,
YES,2102.12827,Foolbox,1,Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints,Maura Pintor; Fabio Roli; Wieland Brendel; Battista Biggio,2021-02-25,2021-06-04,Foolbox,Foolbox:2021-06-04,3.3,,,,,,,,,
YES,1712.02779,"Foolbox, IBM ART",2,Exploring the Landscape of Spatial Robustness,Logan Engstrom; Brandon Tran; Dimitris Tsipras; Ludwig Schmidt; Aleksander Madry,2017-12-07,2019-01-14,IBM ART,IBM ART:2019-01-14; Foolbox:2020-03-30,13.2,,,,,,,,,
YES,1712.04248,"Foolbox, IBM ART",2,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,Wieland Brendel; Jonas Rauber; Matthias Bethge,2017-12-12,2017-06-01,IBM ART,IBM ART:2017-06-01; Foolbox:2019-12-20,-6.4,,,,,,,,,
YES,1907.01003,"Foolbox, IBM ART",2,"Accurate, reliable and fast robustness evaluation",Wieland Brendel; Jonas Rauber; Matthias Kümmerer; Ivan Ustyuzhaninov; Matthias Bethge,2019-07-01,2020-01-03,Foolbox,IBM ART:2020-09-25; Foolbox:2020-01-03,6.1,,,,,,,,,
YES,2310.16944,HarmBench,1,Zephyr: Direct Distillation of LM Alignment,Lewis Tunstall; Edward Beeching; Nathan Lambert; Nazneen Rajani; Kashif Rasul...,2023-10-25,2024-02-27,HarmBench,HarmBench:2024-02-27,4.1,,,,,,,,,
YES,2401.06373,"HarmBench, PyRIT",2,How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs,Yi Zeng; Hongpeng Lin; Jingwen Zhang; Diyi Yang; Ruoxi Jia...,2024-01-12,2024-02-06,HarmBench,PyRIT:2024-03-19; PyRIT:2024-06-25; PyRIT:2024-06-25; PyRIT:2024-06-25; PyRIT:2024-06-25; PyRIT:2024-06-25; HarmBench:2024-02-06,0.8,,,,,,,,,
YES,2402.04249,"HarmBench, PyRIT",2,HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal,Mantas Mazeika; Long Phan; Xuwang Yin; Andy Zou; Zifan Wang...,2024-02-06,2024-02-02,HarmBench,PyRIT:2025-12-03; HarmBench:2024-02-02,-0.1,,,,,,,,,
YES,1206.6389,IBM ART,1,Poisoning Attacks against Support Vector Machines,Battista Biggio; Blaine Nelson; Pavel Laskov,2012-06-27,2019-09-06,IBM ART,IBM ART:2019-09-06,86.3,,,,,,,,,
YES,1506.01497,IBM ART,1,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,Shaoqing Ren; Kaiming He; Ross Girshick; Jian Sun,2015-06-04,2020-03-07,IBM ART,IBM ART:2020-03-07,57.1,,,,,,,,,
YES,1511.04508,IBM ART,1,Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks,Nicolas Papernot; Patrick McDaniel; Xi Wu; Somesh Jha; Ananthram Swami,2015-11-14,2020-02-20,IBM ART,IBM ART:2020-02-20,51.2,,,,,,,,,
YES,1512.02595,IBM ART,1,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,Dario Amodei; Rishita Anubhai; Eric Battenberg; Carl Case; Jared Casper...,2015-12-08,2020-03-07,IBM ART,IBM ART:2020-03-07,51.0,,,,,,,,,
YES,1605.07277,IBM ART,1,Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,Nicolas Papernot; Patrick McDaniel; Ian Goodfellow,2016-05-24,2019-05-30,IBM ART,IBM ART:2019-05-30; IBM ART:2019-07-01; IBM ART:2019-09-03,36.2,,,,,,,,,
YES,1608.00853,IBM ART,1,A study of the effect of JPG compression on adversarial images,Gintare Karolina Dziugaite; Zoubin Ghahramani; Daniel M. Roy,2016-08-02,2018-03-20,IBM ART,IBM ART:2018-03-20,19.5,,,,,,,,,
YES,1610.05820,IBM ART,1,Membership Inference Attacks against Machine Learning Models,Reza Shokri; Marco Stronati; Congzheng Song; Vitaly Shmatikov,2016-10-18,2021-08-23,IBM ART,IBM ART:2021-08-23,58.1,,,,,,,,,
YES,1610.08401,IBM ART,1,Universal adversarial perturbations,Seyed-Mohsen Moosavi-Dezfooli; Alhussein Fawzi; Omar Fawzi; Pascal Frossard,2016-10-26,2017-06-07,IBM ART,IBM ART:2017-06-07,7.4,,,,,,,,,
YES,1704.01155,IBM ART,1,Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,Weilin Xu; David Evans; Yanjun Qi,2017-04-04,2018-02-27,IBM ART,IBM ART:2018-02-27; IBM ART:2020-07-23; IBM ART:2018-03-20; IBM ART:2018-03-20,10.8,,,,,,,,,
YES,1705.02900,IBM ART,1,Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression,Nilaksh Das; Madhuri Shanbhogue; Shang-Tse Chen; Fred Hohman; Li Chen...,2017-05-08,2018-03-20,IBM ART,IBM ART:2018-03-20,10.4,,,,,,,,,
YES,1705.07263,IBM ART,1,Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods,Nicholas Carlini; David Wagner,2017-05-20,2018-05-02,IBM ART,IBM ART:2018-05-02,11.4,,,,,,,,,
YES,1706.05394,IBM ART,1,A Closer Look at Memorization in Deep Networks,Devansh Arpit; Stanisław Jastrzębski; Nicolas Ballas; David Krueger; Emmanuel Bengio...,2017-06-16,2017-06-08,IBM ART,IBM ART:2017-06-08,-0.3,,,,,,,,,
YES,1708.03999,IBM ART,1,ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models,Pin-Yu Chen; Huan Zhang; Yash Sharma; Jinfeng Yi; Cho-Jui Hsieh,2017-08-14,2019-02-16,IBM ART,IBM ART:2019-02-16,18.1,,,,,,,,,
YES,1708.04552,IBM ART,1,Improved Regularization of Convolutional Neural Networks with Cutout,Terrance DeVries; Graham W. Taylor,2017-08-15,2018-03-20,IBM ART,IBM ART:2018-03-20; IBM ART:2022-09-14; IBM ART:2022-09-14,7.1,,,,,,,,,
YES,1708.06733,IBM ART,1,BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain,Tianyu Gu; Brendan Dolan-Gavitt; Siddharth Garg,2017-08-22,2020-03-04,IBM ART,IBM ART:2020-03-04,30.4,,,,,,,,,
YES,1710.08864,IBM ART,1,One pixel attack for fooling deep neural networks,Jiawei Su; Danilo Vasconcellos Vargas; Sakurai Kouichi,2017-10-24,2020-02-09,IBM ART,IBM ART:2020-02-09; IBM ART:2020-02-09,27.5,,,,,,,,,
YES,1710.10766,IBM ART,1,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,Yang Song; Taesup Kim; Sebastian Nowozin; Stefano Ermon; Nate Kushman,2017-10-30,2018-02-27,IBM ART,IBM ART:2018-02-27,3.9,,,,,,,,,
YES,1712.07113,IBM ART,1,Query-Efficient Black-box Adversarial Examples (superceded),Andrew Ilyas; Logan Engstrom; Anish Athalye; Jessy Lin,2017-12-19,2019-01-24,IBM ART,IBM ART:2019-01-24,13.2,,,,,,,,,
YES,1712.09136,IBM ART,1,Towards Measuring Membership Privacy,Yunhui Long; Vincent Bindschaedler; Carl A. Gunter,2017-12-25,2021-01-05,IBM ART,IBM ART:2021-01-05,36.4,,,,,,,,,
YES,1801.10578,IBM ART,1,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,Tsui-Wei Weng; Huan Zhang; Pin-Yu Chen; Jinfeng Yi; Dong Su...,2018-01-31,2017-06-08,IBM ART,IBM ART:2017-06-08,-7.8,,,,,,,,,
YES,1803.09868,IBM ART,1,Bypassing Feature Squeezing by Increasing Adversary Strength,Yash Sharma; Pin-Yu Chen,2018-03-27,2018-02-27,IBM ART,IBM ART:2018-02-27; IBM ART:2020-07-23; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2022-09-14; IBM ART:2022-09-14; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2022-10-19; IBM ART:2022-10-19; IBM ART:2022-10-19,-0.9,,,,,,,,,
YES,1804.00792,IBM ART,1,Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks,Ali Shafahi; W. Ronny Huang; Mahyar Najibi; Octavian Suciu; Christoph Studer...,2018-04-03,2019-09-03,IBM ART,IBM ART:2020-04-23; IBM ART:2019-09-03,17.0,,,,,,,,,
YES,1804.02767,IBM ART,1,YOLOv3: An Incremental Improvement,Joseph Redmon; Ali Farhadi,2018-04-08,2020-03-07,IBM ART,IBM ART:2020-03-07,23.0,,,,,,,,,
YES,1806.00054,IBM ART,1,Defending Against Machine Learning Model Stealing Attacks Using Deceptive Perturbations,Taesung Lee; Benjamin Edwards; Ian Molloy; Dong Su,2018-05-31,2019-03-12,IBM ART,IBM ART:2019-03-12,9.4,,,,,,,,,
YES,1806.02299,IBM ART,1,DPatch: An Adversarial Patch Attack on Object Detectors,Xin Liu; Huanrui Yang; Ziwei Liu; Linghao Song; Hai Li...,2018-06-05,2020-04-02,IBM ART,IBM ART:2020-04-02; IBM ART:2020-11-17,21.9,,,,,,,,,
YES,1806.05476,IBM ART,1,Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data,Jacson Rodrigues Correia-Silva; Rodrigo F. Berriel; Claudine Badue; Alberto F. de Souza; Thiago Oliveira-Santos,2018-06-14,2017-06-01,IBM ART,IBM ART:2017-06-01,-12.4,,,,,,,,,
YES,1809.10875,IBM ART,1,Characterizing Audio Adversarial Examples Using Temporal Dependency,Zhuolin Yang; Bo Li; Pin-Yu Chen; Dawn Song,2018-09-28,2020-04-30,IBM ART,IBM ART:2020-04-30,19.1,,,,,,,,,
YES,1810.08280,IBM ART,1,Exploring Adversarial Examples in Malware Detection,Octavian Suciu; Scott E. Coull; Jeffrey Johns,2018-10-18,2021-04-07,IBM ART,IBM ART:2021-04-07,29.6,,,,,,,,,
YES,1811.03728,IBM ART,1,Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering,Bryant Chen; Wilka Carvalho; Nathalie Baracaldo; Heiko Ludwig; Benjamin Edwards...,2018-11-09,2018-08-01,IBM ART,IBM ART:2018-08-01,-3.3,,,,,,,,,
YES,1811.11875,IBM ART,1,Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers,Nathan Inkawhich; Matthew Inkawhich; Yiran Chen; Hai Li,2018-11-28,2020-03-29,IBM ART,IBM ART:2020-03-29,16.0,,,,,,,,,
YES,1812.02606,IBM ART,1,The Limitations of Model Uncertainty in Adversarial Settings,Kathrin Grosse; David Pfaff; Michael Thomas Smith; Michael Backes,2018-12-06,2019-07-31,IBM ART,IBM ART:2019-07-31; IBM ART:2019-09-03,7.8,,,,,,,,,
YES,1812.02766,IBM ART,1,Knockoff Nets: Stealing Functionality of Black-Box Models,Tribhuvanesh Orekondy; Bernt Schiele; Mario Fritz,2018-12-06,2017-11-28,IBM ART,IBM ART:2017-11-28,-12.3,,,,,,,,,
YES,1901.03583,IBM ART,1,Explaining Vulnerabilities of Deep Learning to Adversarial Malware Binaries,Luca Demetrio; Battista Biggio; Giovanni Lagorio; Fabio Roli; Alessandro Armando,2019-01-11,2021-04-07,IBM ART,IBM ART:2021-04-07,26.8,,,,,,,,,
YES,1902.06531,IBM ART,1,STRIP: A Defence Against Trojan Attacks on Deep Neural Networks,Yansong Gao; Chang Xu; Derui Wang; Shiping Chen; Damith C. Ranasinghe...,2019-02-18,2020-10-07,IBM ART,IBM ART:2020-10-07; IBM ART:2020-10-13,19.6,,,,,,,,,
YES,1902.07906,IBM ART,1,Wasserstein Adversarial Examples via Projected Sinkhorn Iterations,Eric Wong; Frank R. Schmidt; J. Zico Kolter,2019-02-21,2017-11-28,IBM ART,IBM ART:2017-11-28,-14.8,,,,,,,,,
YES,1903.10346,IBM ART,1,"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition",Yao Qin; Nicholas Carlini; Ian Goodfellow; Garrison Cottrell; Colin Raffel,2019-03-22,2018-09-26,IBM ART,IBM ART:2018-09-26,-5.8,,,,,,,,,
YES,1904.11042,IBM ART,1,Physical Adversarial Textures that Fool Visual Object Tracking,Rey Reza Wiyatno; Anqi Xu,2019-04-24,2021-10-07,IBM ART,IBM ART:2021-10-07,29.5,,,,,,,,,
YES,1905.04899,IBM ART,1,CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features,Sangdoo Yun; Dongyoon Han; Seong Joon Oh; Sanghyuk Chun; Junsuk Choe...,2019-05-13,2018-03-20,IBM ART,IBM ART:2018-03-20; IBM ART:2018-03-20; IBM ART:2018-03-20,-13.8,,,,,,,,,
YES,1905.07121,IBM ART,1,Simple Black-box Adversarial Attacks,Chuan Guo; Jacob R. Gardner; Yurong You; Andrew Gordon Wilson; Kilian Q. Weinberger,2019-05-17,2020-01-31,IBM ART,IBM ART:2020-01-31; IBM ART:2020-02-09,8.5,,,,,,,,,
YES,1905.13409,IBM ART,1,Bypassing Backdoor Detection Algorithms in Deep Learning,Te Juin Lester Tan; Reza Shokri,2019-05-31,2018-08-01,IBM ART,IBM ART:2018-08-01; IBM ART:2020-05-07; IBM ART:2020-08-17,-10.0,,,,,,,,,
YES,1906.03849,IBM ART,1,Robustness Verification of Tree-based Models,Hongge Chen; Huan Zhang; Si Si; Yang Li; Duane Boning...,2019-06-10,2019-08-09,IBM ART,IBM ART:2019-08-09,2.0,,,,,,,,,
YES,1906.04584,IBM ART,1,Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers,Hadi Salman; Greg Yang; Jerry Li; Pengchuan Zhang; Huan Zhang...,2019-06-09,2022-05-21,IBM ART,IBM ART:2022-05-21; IBM ART:2023-07-06,35.4,,,,,,,,,
YES,1906.06026,IBM ART,1,Adversarial Robustness Assessment: Why both $L_0$ and $L_\infty$ Attacks Are Necessary,Shashank Kotyan; Danilo Vasconcellos Vargas,2019-06-14,2020-02-09,IBM ART,IBM ART:2020-02-09; IBM ART:2020-02-09; IBM ART:2020-02-09,7.9,,,,,,,,,
YES,1906.11897,IBM ART,1,On Physical Adversarial Patches for Object Detection,Mark Lee; Zico Kolter,2019-06-20,2020-11-17,IBM ART,IBM ART:2020-11-17,17.0,,,,,,,,,
YES,1909.01838,IBM ART,1,High Accuracy and High Fidelity Extraction of Neural Networks,Matthew Jagielski; Nicholas Carlini; David Berthelot; Alex Kurakin; Nicolas Papernot,2019-09-03,2019-12-05,IBM ART,IBM ART:2019-12-05,3.1,,,,,,,,,
YES,1909.08723,IBM ART,1,Espresso: A Fast End-to-end Neural Speech Recognition Toolkit,Yiming Wang; Tongfei Chen; Hainan Xu; Shuoyang Ding; Hang Lv...,2019-09-18,2020-03-07,IBM ART,IBM ART:2020-03-07,5.6,,,,,,,,,
YES,1909.10773,IBM ART,1,Sign-OPT: A Query-Efficient Hard-label Adversarial Attack,Minhao Cheng; Simranjit Singh; Patrick Chen; Pin-Yu Chen; Sijia Liu...,2019-09-24,2022-06-04,IBM ART,IBM ART:2022-06-04,32.3,,,,,,,,,
YES,1910.00033,IBM ART,1,Hidden Trigger Backdoor Attacks,Aniruddha Saha; Akshayvarun Subramanya; Hamed Pirsiavash,2019-09-30,2022-01-14,IBM ART,IBM ART:2022-01-14; IBM ART:2022-01-14; IBM ART:2022-01-14,27.5,,,,,,,,,
YES,1911.03274,IBM ART,1,Imperceptible Adversarial Attacks on Tabular Data,Vincent Ballet; Xavier Renard; Jonathan Aigrain; Thibault Laugel; Pascal Frossard...,2019-11-08,2021-04-23,IBM ART,IBM ART:2021-04-23,17.5,,,,,,,,,
YES,1911.06502,IBM ART,1,Simple iterative method for generating targeted universal adversarial perturbations,Hokuto Hirano; Kazuhiro Takemoto,2019-11-15,2017-06-07,IBM ART,IBM ART:2017-06-07; IBM ART:2017-06-07,-29.3,,,,,,,,,
YES,2001.02378,IBM ART,1,MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius,Runtian Zhai; Chen Dan; Di He; Huan Zhang; Boqing Gong...,2020-01-08,2022-05-21,IBM ART,IBM ART:2022-05-21; IBM ART:2023-07-06,28.4,,,,,,,,,
YES,2002.05123,IBM ART,1,Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks,Roi Pony; Itay Naeh; Shie Mannor,2020-02-12,2021-05-13,IBM ART,IBM ART:2021-05-13,15.0,,,,,,,,,
YES,2002.07088,IBM ART,1,GRAPHITE: Generating Automatic Physical Examples for Machine-Learning Attacks on Computer Vision Systems,Ryan Feng; Neal Mangaokar; Jiefeng Chen; Earlence Fernandes; Somesh Jha...,2020-02-17,2022-06-28,IBM ART,IBM ART:2022-06-28; IBM ART:2022-06-28; IBM ART:2022-06-28,28.3,,,,,,,,,
YES,2002.10733,IBM ART,1,(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,Alexander Levine; Soheil Feizi,2020-02-25,2019-05-02,IBM ART,IBM ART:2022-05-21; IBM ART:2022-05-18; IBM ART:2019-05-02; IBM ART:2022-05-18,-9.8,,,,,,,,,
YES,2003.06468,IBM ART,1,GeoDA: a geometric framework for black-box adversarial attacks,Ali Rahmati; Seyed-Mohsen Moosavi-Dezfooli; Pascal Frossard; Huaiyu Dai,2020-03-13,2021-03-27,IBM ART,IBM ART:2021-03-27,12.5,,,,,,,,,
YES,2003.08937,IBM ART,1,Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates,Amin Ghiasi; Ali Shafahi; Tom Goldstein,2020-03-19,2020-05-09,IBM ART,IBM ART:2020-05-09,1.7,,,,,,,,,
YES,2005.00191,IBM ART,1,Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved Transferability,Hojjat Aghakhani; Dongyu Meng; Yu-Xiang Wang; Christopher Kruegel; Giovanni Vigna,2020-05-01,2021-03-10,IBM ART,IBM ART:2021-03-10,10.3,,,,,,,,,
YES,2005.12872,IBM ART,1,End-to-End Object Detection with Transformers,Nicolas Carion; Francisco Massa; Gabriel Synnaeve; Nicolas Usunier; Alexander Kirillov...,2020-05-26,2023-03-15,IBM ART,IBM ART:2023-03-15; IBM ART:2023-06-28,33.6,,,,,,,,,
YES,2006.14768,IBM ART,1,Deep Partition Aggregation: Provable Defense against General Poisoning Attacks,Alexander Levine; Soheil Feizi,2020-06-26,2021-11-08,IBM ART,IBM ART:2021-11-08,16.4,,,,,,,,,
YES,2007.14321,IBM ART,1,Label-Only Membership Inference Attacks,Christopher A. Choquette-Choo; Florian Tramer; Nicholas Carlini; Nicolas Papernot,2020-07-28,2020-02-18,IBM ART,IBM ART:2020-02-18; IBM ART:2020-11-07,-5.3,,,,,,,,,
YES,2007.15528,IBM ART,1,Membership Leakage in Label-Only Exposures,Zheng Li; Yang Zhang,2020-07-30,2020-11-07,IBM ART,IBM ART:2020-11-07,3.3,,,,,,,,,
YES,2008.07125,IBM ART,1,Adversarial EXEmples: A Survey and Experimental Evaluation of Practical Attacks on Machine Learning for Windows Malware Detection,Luca Demetrio; Scott E. Coull; Battista Biggio; Giovanni Lagorio; Alessandro Armando...,2020-08-17,2021-04-07,IBM ART,IBM ART:2021-04-07,7.7,,,,,,,,,
YES,2009.02276,IBM ART,1,Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching,Jonas Geiping; Liam Fowl; W. Ronny Huang; Wojciech Czaja; Gavin Taylor...,2020-09-04,2021-12-07,IBM ART,IBM ART:2021-12-07,15.1,,,,,,,,,
YES,2103.02079,IBM ART,1,DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations,Eitan Borgnia; Jonas Geiping; Valeriia Cherepanova; Liam Fowl; Arjun Gupta...,2021-03-02,2022-12-07,IBM ART,IBM ART:2022-12-07,21.2,,,,,,,,,
YES,2103.06504,IBM ART,1,Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a Blink,Ranjie Duan; Xiaofeng Mao; A. K. Qin; Yun Yang; Yuefeng Chen...,2021-03-11,2021-11-10,IBM ART,IBM ART:2021-11-10; IBM ART:2021-11-10; IBM ART:2021-11-10,8.0,,,,,,,,,
YES,2106.08970,IBM ART,1,Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,Hossein Souri; Liam Fowl; Rama Chellappa; Micah Goldblum; Tom Goldstein,2021-06-16,2019-09-03,IBM ART,IBM ART:2022-06-06; IBM ART:2019-09-03,-21.4,,,,,,,,,
YES,2108.01644,IBM ART,1,The Devil is in the GAN: Backdoor Attacks and Defenses in Deep Generative Models,Ambrish Rawat; Killian Levacher; Mathieu Sinn,2021-08-03,2021-11-12,IBM ART,IBM ART:2021-12-08; IBM ART:2021-12-08; IBM ART:2021-11-12; IBM ART:2021-12-08,3.3,,,,,,,,,
YES,2110.07719,IBM ART,1,Certified Patch Robustness via Smoothed Vision Transformers,Hadi Salman; Saachi Jain; Eric Wong; Aleksander Mądry,2021-10-11,2019-05-02,IBM ART,IBM ART:2022-05-18; IBM ART:2019-05-02; IBM ART:2023-04-19,-29.3,,,,,,,,,
YES,2111.09277,IBM ART,1,SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness,Jongheon Jeong; Sejun Park; Minkyu Kim; Heung-Chang Lee; Doguk Kim...,2021-11-17,2023-07-06,IBM ART,IBM ART:2023-07-06,19.6,,,,,,,,,
YES,2112.02230,IBM ART,1,SHAPr: An Efficient and Versatile Membership Privacy Risk Metric for Machine Learning,Vasisht Duddu; Sebastian Szyller; N. Asokan,2021-12-04,2021-01-05,IBM ART,IBM ART:2021-01-05,-10.9,,,,,,,,,
YES,2112.03570,IBM ART,1,Membership Inference Attacks From First Principles,Nicholas Carlini; Steve Chien; Milad Nasr; Shuang Song; Andreas Terzis...,2021-12-07,2022-05-12,IBM ART,IBM ART:2022-05-12,5.1,,,,,,,,,
YES,2202.01811,IBM ART,1,ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding Attacks via Patch-agnostic Masking,Chong Xiang; Alexander Valtchanov; Saeed Mahloujifar; Prateek Mittal,2022-02-03,2020-02-18,IBM ART,IBM ART:2020-02-18; IBM ART:2023-07-05,-23.5,,,,,,,,,
YES,2202.04235,IBM ART,1,Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations,Lei Hsiung; Yun-Yun Tsai; Pin-Yu Chen; Tsung-Yi Ho,2022-02-09,2019-09-03,IBM ART,IBM ART:2023-09-14; IBM ART:2019-09-03,-29.2,,,,,,,,,
YES,2205.14497,IBM ART,1,BadDet: Backdoor Attacks on Object Detection,Shih-Han Chan; Yinpeng Dong; Jun Zhu; Xiaolu Zhang; Jun Zhou,2022-05-28,2023-02-23,IBM ART,IBM ART:2023-02-23; IBM ART:2023-02-23; IBM ART:2023-02-23; IBM ART:2023-02-23,8.9,,,,,,,,,
YES,2206.09628,IBM ART,1,Diversified Adversarial Attacks based on Conjugate Gradient Method,Keiichiro Yamamura; Haruki Sato; Nariaki Tateiwa; Nozomi Hata; Toru Mitsutake...,2022-06-20,2019-11-08,IBM ART,IBM ART:2019-11-08,-31.4,,,,,,,,,
YES,2304.05370,IBM ART,1,Overload: Latency Attacks on Object Detection for Edge Devices,Erh-Chung Chen; Pin-Yu Chen; I-Hsin Chung; Che-rung Lee,2023-04-11,2023-11-28,IBM ART,IBM ART:2024-04-28; IBM ART:2023-11-28,7.6,,,,,,,,,
YES,2404.15881,IBM ART,1,Steal Now and Attack Later: Evaluating Robustness of Object Detection against Black-box Adversarial Attacks,Erh-Chung Chen; Pin-Yu Chen; I-Hsin Chung; Che-Rung Lee,2024-04-24,2024-04-28,IBM ART,IBM ART:2024-04-28,0.1,,,,,,,,,
YES,2408.03972,IBM ART,1,Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks,Keiichiro Yamamura; Issa Oe; Hiroki Ishikura; Katsuki Fujisawa,2024-08-07,2019-11-08,IBM ART,IBM ART:2019-11-08,-57.0,,,,,,,,,
YES,1902.02918,"IBM ART, RobustBench",2,Certified Adversarial Robustness via Randomized Smoothing,Jeremy M Cohen; Elan Rosenfeld; J. Zico Kolter,2019-02-08,2019-07-16,IBM ART,IBM ART:2019-07-16; IBM ART:2020-11-24; IBM ART:2020-05-08; IBM ART:2020-05-08; RobustBench:2020-06-28,5.2,,,,,,,,,
YES,1802.03162,MITRE ATLAS,1,URLNet: Learning a URL Representation with Deep Learning for Malicious URL Detection,Hung Le; Quang Pham; Doyen Sahoo; Steven C. H. Hoi,2018-02-09,2021-03-16,MITRE ATLAS,MITRE ATLAS:2021-03-16,37.2,,,,,,,,,
YES,2004.15015,MITRE ATLAS,1,Imitation Attacks and Defenses for Black-box Machine Translation Systems,Eric Wallace; Mitchell Stern; Dawn Song,2020-04-30,2021-03-16,MITRE ATLAS,MITRE ATLAS:2021-03-16,10.5,,,,,,,,,
YES,2101.06896,MITRE ATLAS,1,DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection,Yuanchun Li; Jiayi Hua; Haoyu Wang; Chunyang Chen; Yunxin Liu,2021-01-18,2021-10-29,MITRE ATLAS,MITRE ATLAS:2021-10-29,9.3,,,,,,,,,
YES,2103.03874,MITRE ATLAS,1,Measuring Mathematical Problem Solving With the MATH Dataset,Dan Hendrycks; Collin Burns; Saurav Kadavath; Akul Arora; Steven Basart...,2021-03-05,2023-03-01,MITRE ATLAS,MITRE ATLAS:2023-03-01,23.9,,,,,,,,,
YES,2110.14168,MITRE ATLAS,1,Training Verifiers to Solve Math Word Problems,Karl Cobbe; Vineet Kosaraju; Mohammad Bavarian; Mark Chen; Heewoo Jun...,2021-10-27,2023-03-01,MITRE ATLAS,MITRE ATLAS:2023-03-01,16.1,,,,,,,,,
YES,2203.09509,MITRE ATLAS,1,ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,Thomas Hartvigsen; Saadia Gabriel; Hamid Palangi; Maarten Sap; Dipankar Ray...,2022-03-17,2023-10-30,MITRE ATLAS,MITRE ATLAS:2023-10-30,19.4,,,,,,,,,
YES,2212.14315,MITRE ATLAS,1,"""Real Attackers Don't Compute Gradients"": Bridging the Gap Between Adversarial ML Research and Practice",Giovanni Apruzzese; Hyrum S. Anderson; Savino Dambra; David Freeman; Fabio Pierazzi...,2022-12-29,2025-09-29,MITRE ATLAS,MITRE ATLAS:2025-09-29,33.0,,,,,,,,,
YES,2302.10149,MITRE ATLAS,1,Poisoning Web-Scale Training Datasets is Practical,Nicholas Carlini; Matthew Jagielski; Christopher A. Choquette-Choo; Daniel Paleka; Will Pearce...,2023-02-20,2024-10-01,MITRE ATLAS,MITRE ATLAS:2024-10-01,19.3,,,,,,,,,
YES,2403.02817,MITRE ATLAS,1,Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications,Stav Cohen; Ron Bitton; Ben Nassi,2024-03-05,2024-10-01,MITRE ATLAS,MITRE ATLAS:2024-10-01,6.9,,,,,,,,,
YES,2406.11717,MITRE ATLAS,1,Refusal in Language Models Is Mediated by a Single Direction,Andy Arditi; Oscar Obeso; Aaquib Syed; Daniel Paleka; Nina Panickssery...,2024-06-17,2025-12-24,MITRE ATLAS,MITRE ATLAS:2025-12-24,18.2,,,,,,,,,
YES,2307.02483,PyRIT,1,Jailbroken: How Does LLM Safety Training Fail?,Alexander Wei; Nika Haghtalab; Jacob Steinhardt,2023-07-05,2024-05-28,PyRIT,PyRIT:2024-05-28; PyRIT:2024-05-28; PyRIT:2024-05-28; PyRIT:2024-05-28,10.8,,,,,,,,,
YES,2307.15043,PyRIT,1,Universal and Transferable Adversarial Attacks on Aligned Language Models,Andy Zou; Zifan Wang; Nicholas Carlini; Milad Nasr; J. Zico Kolter...,2023-07-27,2024-10-09,PyRIT,PyRIT:2024-10-09; PyRIT:2024-10-09,14.5,,,,,,,,,
YES,2308.03825,PyRIT,1,"""Do Anything Now"": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",Xinyue Shen; Zeyuan Chen; Michael Backes; Yun Shen; Yang Zhang,2023-08-07,2025-12-03,PyRIT,PyRIT:2025-12-03,27.9,,,,,,,,,
YES,2308.06463,PyRIT,1,GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher,Youliang Yuan; Wenxiang Jiao; Wenxuan Wang; Jen-tse Huang; Pinjia He...,2023-08-12,2024-06-10,PyRIT,PyRIT:2024-06-10,10.0,,,,,,,,,
YES,2308.13387,PyRIT,1,Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs,Yuxia Wang; Haonan Li; Xudong Han; Preslav Nakov; Timothy Baldwin,2023-08-25,2025-12-03,PyRIT,PyRIT:2025-12-03,27.3,,,,,,,,,
YES,2309.10253,PyRIT,1,GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts,Jiahao Yu; Xingwei Lin; Zheng Yu; Xinyu Xing,2023-09-19,2024-03-19,PyRIT,PyRIT:2025-07-23; PyRIT:2024-03-19; PyRIT:2024-09-20; PyRIT:2024-06-21; PyRIT:2024-09-30; PyRIT:2024-09-30; PyRIT:2024-06-21; PyRIT:2024-09-30,6.0,,,,,,,,,
YES,2311.08268,PyRIT,1,A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily,Peng Ding; Jun Kuang; Dan Ma; Xuezhi Cao; Yunsen Xian...,2023-11-14,2024-05-28,PyRIT,PyRIT:2024-05-28; PyRIT:2024-05-28; PyRIT:2024-05-28,6.4,,,,,,,,,
YES,2312.02119,PyRIT,1,Tree of Attacks: Jailbreaking Black-Box LLMs Automatically,Anay Mehrotra; Manolis Zampetakis; Paul Kassianik; Blaine Nelson; Hyrum Anderson...,2023-12-04,2024-07-26,PyRIT,PyRIT:2025-07-02; PyRIT:2025-08-22; PyRIT:2024-08-05; PyRIT:2024-08-05; PyRIT:2024-07-26,7.7,,,,,,,,,
YES,2401.15817,PyRIT,1,Transparency Attacks: How Imperceptible Image Layers Can Fool AI Perception,Forrest McKee; David Noever,2024-01-29,2025-09-26,PyRIT,PyRIT:2025-09-26; PyRIT:2025-12-29,19.9,,,,,,,,,
YES,2402.16717,PyRIT,1,CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models,Huijie Lv; Xiao Wang; Yuansen Zhang; Caishuang Huang; Shihan Dou...,2024-02-26,2024-06-21,PyRIT,PyRIT:2024-06-21; PyRIT:2024-06-21,3.8,,,,,,,,,
NO - Exclude,2403.12025,PyRIT,1,A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models,Stephen R. Pfohl; Heather Cole-Lewis; Rory Sayres; Darlene Neal; Mercy Asiedu...,2024-03-18,2025-12-03,PyRIT,PyRIT:2025-12-03,20.5,,,,,,,,,
YES,2404.01318,PyRIT,1,JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models,Patrick Chao; Edoardo Debenedetti; Alexander Robey; Maksym Andriushchenko; Francesco Croce...,2024-03-28,2025-12-03,PyRIT,PyRIT:2025-12-03,20.2,,,,,,,,,
YES,2406.14598,PyRIT,1,SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal,Tinghao Xie; Xiangyu Qi; Yi Zeng; Yangsibo Huang; Udari Madhushani Sehwag...,2024-06-20,2025-12-03,PyRIT,PyRIT:2025-12-03,17.4,,,,,,,,,
YES,2406.15513,PyRIT,1,PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference,Jiaming Ji; Donghai Hong; Borong Zhang; Boyuan Chen; Juntao Dai...,2024-06-20,2025-12-03,PyRIT,PyRIT:2025-12-03,17.4,,,,,,,,,
NO - Exclude,2406.18682,PyRIT,1,The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm, Aakanksha; Arash Ahmadian; Beyza Ermis; Seraphina Goldfarb-Tarrant; Julia Kreutzer...,2024-06-26,2025-12-03,PyRIT,PyRIT:2025-12-03,17.2,,,,,,,,,
YES,2407.11969,PyRIT,1,Does Refusal Training in LLMs Generalize to the Past Tense?,Maksym Andriushchenko; Nicolas Flammarion,2024-07-16,2024-07-08,PyRIT,PyRIT:2024-07-08,-0.3,,,,,,,,,
YES,2409.11445,PyRIT,1,Jailbreaking Large Language Models with Symbolic Mathematics,Emet Bethany; Mazal Bethany; Juan Arturo Nolazco Flores; Sumit Kumar Jha; Peyman Najafirad,2024-09-17,2024-10-23,PyRIT,PyRIT:2024-10-23,1.2,,,,,,,,,
YES,2410.02828,PyRIT,1,PyRIT: A Framework for Security Risk Identification and Red Teaming in Generative AI System,Gary D. Lopez Munoz; Amanda J. Minnich; Roman Lutz; Richard Lundeen; Raja Sekhar Rao Dheekonda...,2024-10-01,2023-12-12,PyRIT,PyRIT:2023-12-12,-9.7,,,,,,,,,
NO - Exclude,2501.01151,PyRIT,1,Characteristic oscillations in frequency-resolved heat dissipation of linear time-delayed Langevin systems: Approach from the violation of the fluctuation-response relation,Xin Wang; Ruicheng Bao; Naruo Ohga,2025-01-02,2026-01-14,PyRIT,PyRIT:2026-01-14,12.4,,,,,,,,,
YES,2503.13081,PyRIT,1,A Framework to Assess Multilingual Vulnerabilities of LLMs,Likai Tang; Niruth Bogahawatta; Yasod Ginige; Jiarui Xu; Shixuan Sun...,2025-03-17,2025-12-03,PyRIT,PyRIT:2025-12-03,8.6,,,,,,,,,
NO - Exclude,2505.21605,PyRIT,1,SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge,Fengqing Jiang; Fengbo Ma; Zhangchen Xu; Yuetai Li; Bhaskar Ramasubramanian...,2025-05-27,2025-12-03,PyRIT,PyRIT:2025-12-03,6.2,,,,,,,,,
NO - Exclude,1611.05431,RobustBench,1,Aggregated Residual Transformations for Deep Neural Networks,Saining Xie; Ross Girshick; Piotr Dollár; Zhuowen Tu; Kaiming He,2016-11-16,2021-02-12,RobustBench,RobustBench:2021-02-12,50.9,,,,,,,,,
YES,1811.03194,RobustBench,1,AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning,Florian Tramèr; Pascal Dupré; Gili Rusak; Giancarlo Pellegrino; Dan Boneh,2018-11-08,2020-06-28,RobustBench,RobustBench:2020-06-28,19.6,,,,,,,,,
YES,1811.12231,RobustBench,1,ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness,Robert Geirhos; Patricia Rubisch; Claudio Michaelis; Matthias Bethge; Felix A. Wichmann...,2018-11-29,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-08-28; RobustBench:2021-08-28; RobustBench:2021-08-28,19.0,,,,,,,,,
YES,1902.08722,RobustBench,1,A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks,Hadi Salman; Greg Yang; Huan Zhang; Cho-Jui Hsieh; Pengchuan Zhang,2019-02-23,2020-06-28,RobustBench,RobustBench:2020-06-28,16.1,,,,,,,,,
YES,1905.01034,RobustBench,1,Transfer of Adversarial Robustness Between Perturbation Types,Daniel Kang; Yi Sun; Tom Brown; Dan Hendrycks; Jacob Steinhardt,2019-05-03,2020-06-28,RobustBench,RobustBench:2020-06-28,13.9,,,,,,,,,
YES,1906.00945,RobustBench,1,Adversarial Robustness as a Prior for Learned Representations,Logan Engstrom; Andrew Ilyas; Shibani Santurkar; Dimitris Tsipras; Brandon Tran...,2019-06-03,2020-06-28,RobustBench,RobustBench:2020-06-28,12.8,,,,,,,,,
YES,1906.07153,RobustBench,1,Adversarial attacks on Copyright Detection Systems,Parsa Saadatpanah; Ali Shafahi; Tom Goldstein,2019-06-17,2020-06-28,RobustBench,RobustBench:2020-06-28,12.4,,,,,,,,,
YES,1906.08988,RobustBench,1,A Fourier Perspective on Model Robustness in Computer Vision,Dong Yin; Raphael Gontijo Lopes; Jonathon Shlens; Ekin D. Cubuk; Justin Gilmer,2019-06-21,2020-06-28,RobustBench,RobustBench:2020-06-28,12.3,,,,,,,,,
YES,1909.11764,RobustBench,1,FreeLB: Enhanced Adversarial Training for Natural Language Understanding,Chen Zhu; Yu Cheng; Zhe Gan; Siqi Sun; Tom Goldstein...,2019-09-25,2020-06-28,RobustBench,RobustBench:2020-06-28,9.1,,,,,,,,,
YES,1910.08640,RobustBench,1,Are Perceptually-Aligned Gradients a General Property of Robust Classifiers?,Simran Kaur; Jeremy Cohen; Zachary C. Lipton,2019-10-18,2020-06-28,RobustBench,RobustBench:2020-06-28,8.3,,,,,,,,,
YES,1911.09665,RobustBench,1,Adversarial Examples Improve Image Recognition,Cihang Xie; Mingxing Tan; Boqing Gong; Jiang Wang; Alan Yuille...,2019-11-21,2020-06-28,RobustBench,RobustBench:2020-06-28,7.2,,,,,,,,,
YES,1912.02781,RobustBench,1,AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty,Dan Hendrycks; Norman Mu; Ekin D. Cubuk; Barret Zoph; Justin Gilmer...,2019-12-05,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-02-12; RobustBench:2021-02-12; RobustBench:2021-02-12; RobustBench:2021-02-12; RobustBench:2021-02-12,6.8,,,,,,,,,
YES,2002.10509,RobustBench,1,HYDRA: Pruning Adversarially Robust Neural Networks,Vikash Sehwag; Shiqi Wang; Prateek Mittal; Suman Jana,2020-02-24,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2020-07-03,4.1,,,,,,,,,
YES,2003.09347,RobustBench,1,SAT: Improving Adversarial Training via Curriculum-Based Loss Smoothing,Chawin Sitawarin; Supriyo Chakraborty; David Wagner,2020-03-18,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-02-16; RobustBench:2021-02-16,3.4,,,,,,,,,
YES,2004.10934,RobustBench,1,YOLOv4: Optimal Speed and Accuracy of Object Detection,Alexey Bochkovskiy; Chien-Yao Wang; Hong-Yuan Mark Liao,2020-04-23,2020-06-28,RobustBench,RobustBench:2020-06-28,2.2,,,,,,,,,
YES,2006.07682,RobustBench,1,Rethinking Clustering for Robustness,Motasem Alfarra; Juan C. Pérez; Adel Bibi; Ali Thabet; Pablo Arbeláez...,2020-06-13,2020-08-02,RobustBench,RobustBench:2020-08-02,1.6,,,,,,,,,
YES,2006.16241,RobustBench,1,The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization,Dan Hendrycks; Steven Basart; Norman Mu; Saurav Kadavath; Frank Wang...,2020-06-29,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-08-28,-0.0,,,,,,,,,
YES,2007.02617,RobustBench,1,Understanding and Improving Fast Adversarial Training,Maksym Andriushchenko; Nicolas Flammarion,2020-07-06,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-05-13,-0.3,,,,,,,,,
YES,2007.05869,RobustBench,1,Adversarially-Trained Deep Nets Transfer Better: Illustration on Image Classification,Francisco Utrera; Evan Kravitz; N. Benjamin Erichson; Rajiv Khanna; Michael W. Mahoney,2020-07-11,2020-06-28,RobustBench,RobustBench:2020-06-28,-0.4,,,,,,,,,
YES,2007.08489,RobustBench,1,Do Adversarially Robust ImageNet Models Transfer Better?,Hadi Salman; Andrew Ilyas; Logan Engstrom; Ashish Kapoor; Aleksander Madry,2020-07-16,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-08-26; RobustBench:2021-08-26; RobustBench:2021-08-26; RobustBench:2021-08-26,-0.6,,,,,,,,,
YES,2008.03364,RobustBench,1,Improving the Speed and Quality of GAN by Adversarial Training,Jiachen Zhong; Xuanqing Liu; Cho-Jui Hsieh,2020-08-07,2020-06-28,RobustBench,RobustBench:2020-06-28,-1.3,,,,,,,,,
YES,2009.04131,RobustBench,1,SoK: Certified Robustness for Deep Neural Networks,Linyi Li; Tao Xie; Bo Li,2020-09-09,2020-06-28,RobustBench,RobustBench:2020-06-28,-2.4,,,,,,,,,
YES,2010.01278,RobustBench,1,Efficient Robust Training via Backward Smoothing,Jinghui Chen; Yu Cheng; Zhe Gan; Quanquan Gu; Jingjing Liu,2020-10-03,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-02-16; RobustBench:2021-02-16,-3.2,,,,,,,,,
YES,2010.01736,RobustBench,1,Geometry-aware Instance-reweighted Adversarial Training,Jingfeng Zhang; Jianing Zhu; Gang Niu; Bo Han; Masashi Sugiyama...,2020-10-05,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-05-04,-3.3,,,,,,,,,
YES,2011.03083,RobustBench,1,A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs,Souvik Kundu; Mahdi Nazemi; Peter A. Beerel; Massoud Pedram,2020-11-03,2021-03-30,RobustBench,RobustBench:2021-03-30,4.8,,,,,,,,,
YES,2103.01946,RobustBench,1,Fixing Data Augmentation to Improve Adversarial Robustness,Sylvestre-Alvise Rebuffi; Sven Gowal; Dan A. Calian; Florian Stimberg; Olivia Wiles...,2021-03-02,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14; RobustBench:2021-05-14,-8.1,,,,,,,,,
YES,2103.02325,RobustBench,1,On the effectiveness of adversarial training against common corruptions,Klim Kireev; Maksym Andriushchenko; Nicolas Flammarion,2021-03-03,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-03-07; RobustBench:2021-03-07; RobustBench:2021-03-07; RobustBench:2021-03-07; RobustBench:2021-03-07,-8.1,,,,,,,,,
YES,2103.14030,RobustBench,1,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,Ze Liu; Yutong Lin; Yue Cao; Han Hu; Yixuan Wei...,2021-03-25,2024-11-05,RobustBench,RobustBench:2025-02-02; RobustBench:2024-11-05,43.4,,,,,,,,,
YES,2104.01086,RobustBench,1,Defending Against Image Corruptions Through Adversarial Augmentations,Dan A. Calian; Florian Stimberg; Olivia Wiles; Sylvestre-Alvise Rebuffi; Andras Gyorgy...,2021-04-02,2021-04-14,RobustBench,RobustBench:2021-04-14,0.4,,,,,,,,,
YES,2104.09425,RobustBench,1,Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?,Vikash Sehwag; Saeed Mahloujifar; Tinashe Handina; Sihui Dai; Chong Xiang...,2021-04-19,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-03-15; RobustBench:2022-03-15; RobustBench:2021-04-22; RobustBench:2021-04-22; RobustBench:2021-04-22; RobustBench:2021-04-22,-9.7,,,,,,,,,
YES,2106.02078,RobustBench,1,Improving Neural Network Robustness via Persistency of Excitation,Kaustubh Sridhar; Oleg Sokolsky; Insup Lee; James Weimer,2021-06-03,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-06-18; RobustBench:2021-06-18,-11.2,,,,,,,,,
YES,2106.09129,RobustBench,1,A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness,James Diffenderfer; Brian R. Bartoldson; Shreya Chaganti; Jize Zhang; Bhavya Kailkhura,2021-06-16,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20; RobustBench:2021-10-20,-11.6,,,,,,,,,
YES,2110.03825,RobustBench,1,Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks,Hanxun Huang; Yisen Wang; Sarah Monazam Erfani; Quanquan Gu; James Bailey...,2021-10-07,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-10-19; RobustBench:2021-10-19,-15.3,,,,,,,,,
YES,2110.05626,RobustBench,1,Parameterizing Activation Functions for Adversarial Robustness,Sihui Dai; Saeed Mahloujifar; Prateek Mittal,2021-10-11,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-10-29,-15.4,,,,,,,,,
YES,2110.09468,RobustBench,1,Improving Robustness using Generated Data,Sven Gowal; Sylvestre-Alvise Rebuffi; Olivia Wiles; Florian Stimberg; Dan Andrei Calian...,2021-10-18,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-10-19; RobustBench:2021-10-19; RobustBench:2021-10-19,-15.7,,,,,,,,,
YES,2110.12976,RobustBench,1,Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks,Qiyu Kang; Yang Song; Qinxu Ding; Wee Peng Tay,2021-10-25,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-02-14,-15.9,,,,,,,,,
YES,2111.02331,RobustBench,1,LTD: Low Temperature Distillation for Gradient Masking-free Adversarial Training,Erh-Chung Chen; Che-Rung Lee,2021-11-03,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-11-10; RobustBench:2021-11-10; RobustBench:2021-11-10,-16.2,,,,,,,,,
NO - Exclude,2111.14725,RobustBench,1,Searching the Search Space of Vision Transformer,Minghao Chen; Kan Wu; Bolin Ni; Houwen Peng; Bei Liu...,2021-11-29,2024-11-05,RobustBench,RobustBench:2024-11-05,35.2,,,,,,,,,
YES,2112.13547,RobustBench,1,PRIME: A few primitives can boost robustness to common corruptions,Apostolos Modas; Rahul Rade; Guillermo Ortiz-Jiménez; Seyed-Mohsen Moosavi-Dezfooli; Pascal Frossard,2021-12-27,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-01-13; RobustBench:2022-01-13,-18.0,,,,,,,,,
YES,2202.01263,RobustBench,1,NoisyMix: Boosting Model Robustness to Common Corruptions,N. Benjamin Erichson; Soon Hoe Lim; Winnie Xu; Francisco Utrera; Ziang Cao...,2022-02-02,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-02-22; RobustBench:2022-02-22; RobustBench:2022-02-22; RobustBench:2022-02-22,-19.2,,,,,,,,,
YES,2202.10103,RobustBench,1,Robustness and Accuracy Could Be Reconcilable by (Proper) Definition,Tianyu Pang; Min Lin; Xiao Yang; Jun Zhu; Shuicheng Yan,2022-02-21,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-03-15; RobustBench:2022-03-15; RobustBench:2022-03-15; RobustBench:2022-03-15,-19.8,,,,,,,,,
YES,2203.06616,RobustBench,1,LAS-AT: Adversarial Training with Learnable Attack Strategy,Xiaojun Jia; Yong Zhang; Baoyuan Wu; Ke Ma; Jue Wang...,2022-03-13,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-04-04; RobustBench:2022-04-04; RobustBench:2022-04-04; RobustBench:2022-04-04,-20.5,,,,,,,,,
YES,2204.12143,RobustBench,1,Deeper Insights into the Robustness of ViTs towards Common Corruptions,Rui Tian; Zuxuan Wu; Qi Dai; Han Hu; Yu-Gang Jiang,2022-04-26,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-04-10; RobustBench:2023-04-10,-21.9,,,,,,,,,
YES,2209.07399,RobustBench,1,A Light Recipe to Train Robust Vision Transformers,Edoardo Debenedetti; Vikash Sehwag; Prateek Mittal,2022-09-15,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27; RobustBench:2022-09-27,-26.6,,,,,,,,,
YES,2210.07540,RobustBench,1,When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture,Yichuan Mo; Dongxian Wu; Yifei Wang; Yiwen Guo; Yisen Wang,2022-10-14,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2024-06-25; RobustBench:2024-06-25,-27.5,,,,,,,,,
YES,2210.09852,RobustBench,1,Scaling Adversarial Training to Large Perturbation Bounds,Sravanti Addepalli; Samyak Jain; Gaurang Sriramanan; R. Venkatesh Babu,2022-10-18,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2021-10-29; RobustBench:2021-10-29; RobustBench:2021-10-29; RobustBench:2021-10-29; RobustBench:2021-10-29; RobustBench:2021-10-29; RobustBench:2021-10-29,-27.7,,,,,,,,,
YES,2210.15318,RobustBench,1,Efficient and Effective Augmentation Strategy for Adversarial Training,Sravanti Addepalli; Samyak Jain; R. Venkatesh Babu,2022-10-27,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2022-06-07; RobustBench:2022-06-07; RobustBench:2022-06-07; RobustBench:2022-06-07; RobustBench:2022-06-07; RobustBench:2022-06-07,-28.0,,,,,,,,,
YES,2212.11005,RobustBench,1,Revisiting Residual Networks for Adversarial Robustness: An Architectural Perspective,Shihua Huang; Zhichao Lu; Kalyanmoy Deb; Vishnu Naresh Boddeti,2022-12-21,2020-06-28,RobustBench,RobustBench:2023-02-08; RobustBench:2020-06-28; RobustBench:2023-02-08,-29.8,,,,,,,,,
YES,2301.12554,RobustBench,1,Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing,Yatong Bai; Brendon G. Anderson; Aerin Kim; Somayeh Sojoudi,2023-01-29,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-05-18; RobustBench:2023-05-18; RobustBench:2023-05-18,-31.0,,,,,,,,,
YES,2302.03015,RobustBench,1,Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness,Yuancheng Xu; Yanchao Sun; Micah Goldblum; Tom Goldstein; Furong Huang,2023-02-06,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-04-24,-31.3,,,,,,,,,
YES,2302.04638,RobustBench,1,Better Diffusion Models Further Improve Adversarial Training,Zekai Wang; Tianyu Pang; Chao Du; Min Lin; Weiwei Liu...,2023-02-09,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-02-27; RobustBench:2023-02-27; RobustBench:2023-02-27; RobustBench:2023-02-27; RobustBench:2023-02-27; RobustBench:2023-02-27,-31.4,,,,,,,,,
YES,2302.14301,RobustBench,1,A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking,Chang Liu; Yinpeng Dong; Wenzhao Xiang; Xiao Yang; Hang Su...,2023-02-28,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16,-32.0,,,,,,,,,
YES,2303.01870,RobustBench,1,"Revisiting Adversarial Training for ImageNet: Architectures, Training and Generalization across Threat Models",Naman D Singh; Francesco Croce; Matthias Hein,2023-03-03,2020-06-28,RobustBench,RobustBench:2023-03-15; RobustBench:2020-06-28; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16; RobustBench:2023-03-16,-32.1,,,,,,,,,
YES,2305.13948,RobustBench,1,Decoupled Kullback-Leibler Divergence Loss,Jiequan Cui; Zhuotao Tian; Zhisheng Zhong; Xiaojuan Qi; Bei Yu...,2023-05-23,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-06-04; RobustBench:2023-06-04; RobustBench:2023-06-04; RobustBench:2023-06-04; RobustBench:2023-06-04,-34.8,,,,,,,,,
YES,2308.16258,RobustBench,1,Robust Principles: Architectural Design Principles for Adversarially Robust CNNs,ShengYun Peng; Weilin Xu; Cory Cornelius; Matthew Hull; Kevin Li...,2023-08-30,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2023-09-07; RobustBench:2023-09-07,-38.0,,,,,,,,,
YES,2312.04960,RobustBench,1,MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness,Xiaoyun Xu; Shujian Yu; Zhuoran Liu; Stjepan Picek,2023-12-08,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2025-02-02; RobustBench:2025-02-02,-41.3,,,,,,,,,
YES,2402.02263,RobustBench,1,MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers,Yatong Bai; Mo Zhou; Vishal M. Patel; Somayeh Sojoudi,2024-02-03,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2024-03-17; RobustBench:2024-03-17; RobustBench:2024-03-17,-43.2,,,,,,,,,
YES,2404.09349,RobustBench,1,Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies,Brian R. Bartoldson; James Diffenderfer; Konstantinos Parasyris; Bhavya Kailkhura,2024-04-14,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2024-06-25; RobustBench:2024-06-25,-45.5,,,,,,,,,
YES,2406.05927,RobustBench,1,MeanSparse: Post-Training Robustness Enhancement Through Mean-Centered Feature Sparsification,Sajjad Amini; Mohammadreza Teymoorianfard; Shiqing Ma; Amir Houmansadr,2024-06-09,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2024-06-25; RobustBench:2024-06-25; RobustBench:2024-06-25; RobustBench:2024-06-25; RobustBench:2024-06-25; RobustBench:2024-06-25,-47.4,,,,,,,,,
YES,2409.20139,RobustBench,1,Characterizing Model Robustness via Natural Input Gradients,Adrián Rodríguez-Muñoz; Tongzhou Wang; Antonio Torralba,2024-09-30,2020-06-28,RobustBench,RobustBench:2020-06-28; RobustBench:2024-12-20; RobustBench:2024-12-20,-51.1,,,,,,,,,
YES,1805.12152,"RobustBench, TextAttack",2,Robustness May Be at Odds with Accuracy,Dimitris Tsipras; Shibani Santurkar; Logan Engstrom; Alexander Turner; Aleksander Madry,2018-05-30,2020-06-28,RobustBench,TextAttack:2020-08-30; RobustBench:2020-06-28,25.0,,,,,,,,,
YES,1603.00892,TextAttack,1,Counter-fitting Word Vectors to Linguistic Constraints,Nikola Mrkšić; Diarmuid Ó Séaghdha; Blaise Thomson; Milica Gašić; Lina Rojas-Barahona...,2016-03-02,2019-10-31,TextAttack,TextAttack:2019-10-31,44.0,,,,,,,,,
YES,1705.02364,TextAttack,1,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,Alexis Conneau; Douwe Kiela; Holger Schwenk; Loic Barrault; Antoine Bordes,2017-05-05,2019-10-11,TextAttack,TextAttack:2019-10-11,29.2,,,,,,,,,
YES,1712.06751,TextAttack,1,HotFlip: White-Box Adversarial Examples for Text Classification,Javid Ebrahimi; Anyi Rao; Daniel Lowd; Dejing Dou,2017-12-19,2019-10-11,TextAttack,TextAttack:2020-05-15; TextAttack:2019-11-10; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,21.7,,,,,,,,,
YES,1801.04354,TextAttack,1,Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers,Ji Gao; Jack Lanchantin; Mary Lou Soffa; Yanjun Qi,2018-01-13,2019-10-11,TextAttack,TextAttack:2020-02-19; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,20.9,,,,,,,,,
YES,1803.01128,TextAttack,1,Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples,Minhao Cheng; Jinfeng Yi; Pin-Yu Chen; Huan Zhang; Cho-Jui Hsieh,2018-03-03,2019-10-11,TextAttack,TextAttack:2020-04-26; TextAttack:2020-04-26; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,19.3,,,,,,,,,
YES,1804.07781,TextAttack,1,Pathologies of Neural Models Make Interpretations Difficult,Shi Feng; Eric Wallace; Alvin Grissom; Mohit Iyyer; Pedro Rodriguez...,2018-04-20,2019-10-11,TextAttack,TextAttack:2020-06-03; TextAttack:2020-06-30; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,17.7,,,,,,,,,
YES,1804.07998,TextAttack,1,Generating Natural Language Adversarial Examples,Moustafa Alzantot; Yash Sharma; Ahmed Elgohary; Bo-Jhang Ho; Mani Srivastava...,2018-04-21,2019-10-11,TextAttack,TextAttack:2019-10-28; TextAttack:2019-11-10; TextAttack:2020-07-25; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,17.7,,,,,,,,,
YES,1805.06087,TextAttack,1,Learning to Write with Cooperative Discriminators,Ari Holtzman; Jan Buys; Maxwell Forbes; Antoine Bosselut; David Golub...,2018-05-16,2020-06-27,TextAttack,TextAttack:2020-06-27,25.4,,,,,,,,,
YES,1812.05271,TextAttack,1,TextBugger: Generating Adversarial Text Against Real-world Applications,Jinfeng Li; Shouling Ji; Tianyu Du; Bo Li; Ting Wang,2018-12-13,2019-10-11,TextAttack,TextAttack:2020-06-03; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,9.9,,,,,,,,,
YES,1901.11196,TextAttack,1,EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks,Jason Wei; Kai Zou,2019-01-31,2020-05-07,TextAttack,TextAttack:2020-05-07,15.2,,,,,,,,,
YES,1904.09675,TextAttack,1,BERTScore: Evaluating Text Generation with BERT,Tianyi Zhang; Varsha Kishore; Felix Wu; Kilian Q. Weinberger; Yoav Artzi,2019-04-21,2020-06-22,TextAttack,TextAttack:2020-06-22,14.1,,,,,,,,,
YES,1905.11268,TextAttack,1,Combating Adversarial Misspellings with Robust Word Recognition,Danish Pruthi; Bhuwan Dhingra; Zachary C. Lipton,2019-05-27,2019-10-11,TextAttack,TextAttack:2020-07-06; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,4.5,,,,,,,,,
YES,1907.11932,TextAttack,1,Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment,Di Jin; Zhijing Jin; Joey Tianyi Zhou; Peter Szolovits,2019-07-27,2019-10-11,TextAttack,TextAttack:2019-12-01; TextAttack:2019-11-10; TextAttack:2019-10-28; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14; TextAttack:2021-05-02,2.5,,,,,,,,,
YES,1909.00986,TextAttack,1,Certified Robustness to Adversarial Word Substitutions,Robin Jia; Aditi Raghunathan; Kerem Göksel; Percy Liang,2019-09-03,2019-10-11,TextAttack,TextAttack:2020-06-28; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,1.2,,,,,,,,,
YES,1909.02560,TextAttack,1,Robustness to Modification with Shared Words in Paraphrase Identification,Zhouxing Shi; Minlie Huang,2019-09-05,2020-06-19,TextAttack,TextAttack:2020-06-19,9.5,,,,,,,,,
YES,1909.06723,TextAttack,1,Natural Language Adversarial Defense through Synonym Encoding,Xiaosen Wang; Hao Jin; Yichen Yang; Kun He,2019-09-15,2019-10-11,TextAttack,TextAttack:2019-11-10; TextAttack:2019-10-24; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,0.9,,,,,,,,,
YES,2004.01970,TextAttack,1,BAE: BERT-based Adversarial Examples for Text Classification,Siddhant Garg; Goutham Ramakrishnan,2020-04-04,2019-10-11,TextAttack,TextAttack:2020-06-19; TextAttack:2020-06-28; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,-5.8,,,,,,,,,
YES,2004.09984,TextAttack,1,BERT-ATTACK: Adversarial Attack Against BERT Using BERT,Linyang Li; Ruotian Ma; Qipeng Guo; Xiangyang Xue; Xipeng Qiu,2020-04-21,2019-10-11,TextAttack,TextAttack:2020-06-19; TextAttack:2020-06-28; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,-6.3,,,,,,,,,
YES,2004.14174,TextAttack,1,Reevaluating Adversarial Examples in Natural Language,John X. Morris; Eli Lifland; Jack Lanchantin; Yangfeng Ji; Yanjun Qi,2020-04-25,2019-10-11,TextAttack,TextAttack:2019-10-11; TextAttack:2020-10-05; TextAttack:2020-12-15,-6.5,,,,,,,,,
YES,2005.04118,TextAttack,1,Beyond Accuracy: Behavioral Testing of NLP models with CheckList,Marco Tulio Ribeiro; Tongshuang Wu; Carlos Guestrin; Sameer Singh,2020-05-08,2019-10-11,TextAttack,TextAttack:2020-05-07; TextAttack:2020-09-01; TextAttack:2020-09-01; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,-6.9,,,,,,,,,
YES,2005.05909,TextAttack,1,"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP",John X. Morris; Eli Lifland; Jin Yong Yoo; Jake Grigsby; Di Jin...,2020-04-29,2019-10-11,TextAttack,TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2020-11-14; TextAttack:2020-11-17; TextAttack:2020-10-05; TextAttack:2020-10-04,-6.6,,,,,,,,,
YES,2009.06368,TextAttack,1,Searching for a Search Method: Benchmarking Search Algorithms for Generating NLP Adversarial Examples,Jin Yong Yoo; John X. Morris; Eli Lifland; Yanjun Qi,2020-09-09,2019-10-11,TextAttack,TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2020-11-14; TextAttack:2020-11-17; TextAttack:2020-10-05; TextAttack:2020-11-10; TextAttack:2021-05-02,-11.0,,,,,,,,,
YES,2009.07502,TextAttack,1,Contextualized Perturbation for Textual Adversarial Attack,Dianqi Li; Yizhe Zhang; Hao Peng; Liqun Chen; Chris Brockett...,2020-09-16,2019-10-11,TextAttack,TextAttack:2020-05-07; TextAttack:2020-10-26; TextAttack:2020-06-19; TextAttack:2020-10-26; TextAttack:2020-10-17; TextAttack:2019-10-11; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14; TextAttack:2020-12-19,-11.2,,,,,,,,,
YES,2010.01724,TextAttack,1,TextAttack: Lessons learned in designing Python frameworks for NLP,John X. Morris; Jin Yong Yoo; Yanjun Qi,2020-10-05,2020-10-05,TextAttack,TextAttack:2020-10-05,0.0,,,,,,,,,
YES,2106.09898,TextAttack,1,Bad Characters: Imperceptible NLP Attacks,Nicholas Boucher; Ilia Shumailov; Ross Anderson; Nicolas Papernot,2021-06-18,2019-10-11,TextAttack,TextAttack:2019-11-05; TextAttack:2025-01-15; TextAttack:2025-01-15; TextAttack:2025-01-15; TextAttack:2025-04-17; TextAttack:2019-10-11; TextAttack:2021-06-17; TextAttack:2020-11-14,-20.2,,,,,,,,,
YES,2109.00544,TextAttack,1,Towards Improving Adversarial Training of NLP Models,Jin Yong Yoo; Yanjun Qi,2021-09-01,2019-10-11,TextAttack,TextAttack:2021-09-11; TextAttack:2019-10-11; TextAttack:2020-10-05; TextAttack:2021-11-11,-22.7,,,,,,,,,
YES,2306.04874,TextAttack,1,Expanding Scope: Adapting English Adversarial Attacks to Chinese,Hanyu Liu; Chengyuan Cai; Yanjun Qi,2023-06-08,2020-10-05,TextAttack,TextAttack:2020-10-05,-32.1,,,,,,,,,
