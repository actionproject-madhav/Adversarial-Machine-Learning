\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{csvsimple}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{setspace}
\usepackage{enumitem}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Line spacing
\onehalfspacing

% Title
\title{\textbf{Bridging the Gap Between Theory and Practice in Adversarial Machine Learning: A Systematic Cross-Venue Analysis of 454 Papers (2022--2025)}}

\author{
  Madhav Khanal\\
  Rollins College\\
  \texttt{mkhanal@rollins.edu}
  \and
  JJ Jasser\\
  Rollins College\\
  \texttt{jjasser@rollins.edu}
}

\date{}

\begin{document}

\maketitle

%==============================================================================
% ABSTRACT
%==============================================================================
\begin{abstract}
Machine learning systems are increasingly deployed in security-critical applications, yet a fundamental disconnect persists between academic adversarial machine learning research and real-world deployment needs. This literature review synthesizes findings from 454 papers published across four top-tier security conferences---ACM CCS, IEEE S\&P, NDSS, and USENIX Security---spanning 2022 to 2025. Following the framework established by Apruzzese et al.'s influential critique ``Real Attackers Don't Compute Gradients,'' we systematically evaluate how well the research community has addressed the theory-practice gap.

Our quantitative analysis reveals persistent and concerning patterns: 94.7\% of papers do not test on real deployed systems, 67.8\% require gradient access that real attackers lack, 80.4\% assume unrealistic query budgets, and 63.2\% rely on white-box threat models rarely available in practice. Through thematic synthesis across venues, we identify five critical disconnects that prevent research translation: unrealistic threat models, gradient dependency assumptions, absence of real-world validation, severe domain bias toward image data, and systematic neglect of economic and human factors. Perhaps most troublingly, our temporal analysis shows these gaps have not narrowed meaningfully from 2022 to 2025 despite explicit calls for change.

\textbf{Keywords:} adversarial machine learning, theory-practice gap, security research, systematic review, threat modeling
\end{abstract}

\newpage
\tableofcontents
\newpage

%==============================================================================
% 1. INTRODUCTION
%==============================================================================
\section{Introduction}

Machine learning has transformed how we build software systems. From facial recognition at airports to fraud detection in banking, from autonomous vehicles navigating city streets to content moderation on social media platforms, ML models now make decisions that affect millions of people daily. However, these systems are vulnerable to adversarial attacks---carefully crafted inputs designed to cause models to fail in ways their designers never anticipated.

The field of adversarial machine learning (AML) emerged to study these vulnerabilities and develop defenses against them. Over the past decade, researchers have demonstrated impressive attacks: adding imperceptible noise to images that causes classifiers to misidentify them, poisoning training data to implant hidden backdoors, extracting private information about training data through careful queries, and more. In response, the community has proposed numerous defenses claiming to make models robust against such attacks.

Yet there is a fundamental problem: \textbf{the assumptions underlying most academic research do not match the realities of deployed systems.}

In 2022, Apruzzese and colleagues published a landmark analysis titled ``Real Attackers Don't Compute Gradients''~\citep{apruzzese2022real}, documenting a significant gap between academic AML research and practical security needs. Their central observation was simple but devastating: while academic attacks typically assume adversaries can compute gradients through target models (requiring knowledge of model architecture and parameters), real attackers almost never have such access. Real attackers exploit simpler vulnerabilities---they don't need sophisticated mathematical optimization when social engineering or basic input manipulation suffices.

This literature review asks: \textit{four years later, has the research community addressed these concerns?}

To answer this question, we systematically analyzed 454 adversarial ML papers published from 2022 through 2025 at four premier security venues: ACM CCS (118 papers), IEEE S\&P (79 papers), NDSS (49 papers), and USENIX Security (208 papers). We evaluated each paper across multiple dimensions capturing practical relevance: threat model realism, computational requirements, validation methodology, and consideration of deployment constraints.

Our findings are sobering. The theory-practice gap has not narrowed. If anything, certain metrics have worsened. The research community continues to optimize for publication metrics---novelty, theoretical rigor, impressive attack success rates---rather than for actual deployment viability. This review documents the extent of the problem, analyzes its root causes through thematic synthesis across venues, and offers concrete recommendations for researchers, venues, industry practitioners, and funding agencies.

%==============================================================================
% 2. BACKGROUND
%==============================================================================
\section{Background: Understanding Adversarial Machine Learning}

Before diving into our analysis, readers unfamiliar with adversarial machine learning may benefit from understanding its core concepts and why practical deployment differs so dramatically from laboratory research.

\subsection{What Makes Machine Learning Vulnerable?}

Modern machine learning models, particularly deep neural networks, learn to recognize patterns by processing millions of examples during training. A model trained to classify images, for instance, learns to associate certain pixel patterns with labels like ``cat'' or ``dog.'' However, these models don't ``understand'' images the way humans do---they simply learn statistical correlations between pixel values and labels.

This fundamental difference creates vulnerabilities. Researchers discovered that adding carefully calculated noise to an image---noise so subtle that humans cannot perceive it---can cause a model to completely misclassify the image with high confidence. A photograph of a panda, with imperceptible perturbations, might be classified as a gibbon. A stop sign, with a few strategically placed stickers, might be classified as a speed limit sign by an autonomous vehicle.

\subsection{Types of Adversarial Attacks}

Adversarial attacks generally fall into three categories based on their goals:

\textbf{Evasion attacks} manipulate inputs at test time to cause misclassification. The attacker modifies an input (an image, a malware sample, a network packet) so that the model makes an incorrect prediction. These attacks target the inference phase and are the most commonly studied.

\textbf{Poisoning attacks} corrupt the training process itself. By injecting malicious examples into training data, attackers can cause models to learn incorrect behaviors or implant ``backdoors''---hidden triggers that cause specific misbehaviors when activated. For example, a poisoned model might correctly classify most images but consistently misclassify any image containing a specific pattern.

\textbf{Privacy attacks} extract sensitive information. Membership inference attacks determine whether specific individuals were in the training data. Model extraction attacks steal the model's functionality by querying it repeatedly. Data reconstruction attacks attempt to recover actual training examples.

\subsection{Threat Models: What Does the Attacker Know?}

A ``threat model'' specifies what capabilities and knowledge an adversary possesses. This is where academic research most dramatically diverges from reality.

\textbf{White-box access} means the attacker has complete knowledge of the model: its architecture, its parameters (weights), and often its training data. With white-box access, attackers can compute gradients---mathematical derivatives that indicate exactly how to modify an input to change the model's output. Most academic attacks assume white-box access because it makes attack optimization straightforward.

\textbf{Black-box access} means the attacker can only query the model and observe its outputs. This mirrors real-world scenarios where models are deployed as web services or embedded in applications. The attacker cannot see inside the model---they can only submit inputs and receive predictions.

\textbf{Gray-box access} falls between these extremes. The attacker might know the model architecture but not its specific parameters, or might have access to a similar training dataset.

The critical insight from Apruzzese et al. is that \textbf{real-world attackers almost never have white-box access}~\citep{apruzzese2022real}. Production models are protected by extensive security controls. Yet 63.2\% of papers in our dataset assume white-box access---a fundamentally unrealistic starting point.

\subsection{Why the Gap Matters}

One might argue that academic research should push boundaries, studying worst-case scenarios even if they seem impractical. There is merit to this view---understanding what is theoretically possible helps us prepare for future threats. However, the current state of the field goes beyond conservative threat modeling into systematic irrelevance.

When 94.7\% of papers never test on real systems, we cannot know whether proposed attacks actually work in practice or whether proposed defenses actually protect deployed applications. When attacks require thousands of queries to a model, but real systems have rate limiting and anomaly detection, the attacks may be completely impractical. When defenses impose 10--100$\times$ computational overhead, no production system will deploy them.

The consequence is a research field that has become largely self-referential: papers cite other papers, attacks beat defenses that were never deployed, and defenses claim robustness against attacks that were never practical. Meanwhile, actual deployed ML systems face threats that the research community rarely studies.

%==============================================================================
% 3. METHODOLOGY
%==============================================================================
\section{Methodology}

\subsection{Data Collection}

We systematically reviewed all papers with adversarial ML focus published at four top-tier security venues from 2022 through 2025. These venues were selected because they represent the primary publication outlets for security-focused ML research and have historically shaped the field's direction.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig01_dataset_overview.png}
    \caption{Dataset overview showing the distribution of 454 papers across four security conferences (ACM CCS, IEEE S\&P, NDSS, USENIX Security) from 2022--2025.}
    \label{fig:dataset}
\end{figure}

Our dataset comprises 454 papers: ACM CCS contributed 118 papers (26.0\%), IEEE S\&P contributed 79 papers (17.4\%), NDSS contributed 49 papers (10.8\%), and USENIX Security contributed 208 papers (45.8\%). The temporal distribution shows 89 papers from 2022, 136 from 2023, 198 from 2024, and 31 from 2025 (partial year at time of analysis).

\subsection{Coding Framework}

Each paper was evaluated across multiple dimensions designed to capture practical relevance:

\begin{itemize}[noitemsep]
    \item \textbf{Research Focus (G1):} Whether the paper primarily proposes attacks (60\%), defenses (39\%), or both (2\%).
    \item \textbf{Attack Type (G2):} Classification as evasion (48\%), poisoning (20\%), privacy (23\%), or multiple types (9\%).
    \item \textbf{Data Domain (G4):} The input modality---images (65\%), text (11\%), audio (7\%), malware (6\%), or other (12\%).
    \item \textbf{Threat Model (T1):} Assumed adversary access---white-box (63.2\%), black-box (34.1\%), or gray-box (2.6\%).
    \item \textbf{Gradient Requirements (Q1):} Whether the approach requires gradient access.
    \item \textbf{Query Budget (Q2):} High ($>$1000 queries), low, or none.
    \item \textbf{Real System Testing (G7):} Whether validation occurred on deployed systems.
    \item \textbf{Code Release (G6):} Whether code was released publicly.
\end{itemize}

\subsection{Gap Score Framework}

To quantify the theory-practice gap, we developed a 6-point ``Gap Score'' summing binary indicators of impractical assumptions:

\begin{enumerate}[noitemsep]
    \item Requires white-box access (vs. black/gray-box)
    \item Requires gradient computation
    \item Assumes high query budget ($>$1000 queries)
    \item Requires high computation (GPU-level resources)
    \item No testing on real deployed systems
    \item No consideration of economic factors
\end{enumerate}

Higher scores indicate greater distance from practical deployment. A paper scoring 0 would use realistic threat models, require minimal resources, test on production systems, and consider economic constraints. A paper scoring 6 would represent a purely academic exercise unlikely to inform real-world security.

%==============================================================================
% 4. QUANTITATIVE FINDINGS
%==============================================================================
\section{Quantitative Findings: The State of the Gap}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig02_theory_practice_gap.png}
    \caption{Overview of the theory-practice gap showing the percentage of papers exhibiting each problematic assumption: no real-world testing (94.7\%), high query budget (80.4\%), gradient dependency (67.8\%), white-box access (63.2\%), and no code release (10.4\%).}
    \label{fig:gap_overview}
\end{figure}


Our analysis reveals a research field persistently disconnected from deployment realities. Figure~\ref{fig:gap_overview} summarizes the key gap indicators across all 454 papers.

\subsection{The Real-World Testing Crisis}

The single most striking finding is the near-complete absence of real-world validation: \textbf{only 5.3\% of papers (24 of 454) test on actual deployed systems}. The remaining 94.7\% evaluate exclusively on research benchmarks, simulated environments, or research prototypes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig05_real_world_testing.png}
    \caption{The stark real-world testing gap: only 5.3\% of papers validate on actual deployed systems.}
    \label{fig:real_world}
\end{figure}


This matters because deployment introduces constraints completely absent from controlled experiments. Real systems use proprietary model formats and encryption. They integrate ML components into complex security pipelines where multiple components interact. They face hardware constraints, latency requirements, and regulatory compliance obligations. A defense that works perfectly in a research setting may be entirely impractical when these factors are considered.

Research from USENIX Security particularly highlights this disconnect. \citet{nayan2024sok} conducted a systematic review of on-device ML model extraction attacks, finding that many proposed academic attacks ``prove difficult to reproduce, fail to perform effectively on production models, or introduce unacceptable computation and energy costs.'' Similarly, \citet{layton2024sok} demonstrated that deepfake detection research uses inappropriate metrics and unrealistic dataset distributions, leading to ``overestimation of detector efficacy and creating difficulties for transitioning these tools into practice.''

The few papers that do test on real systems often reveal surprising gaps between laboratory and field performance. \citet{duan2022perception} validated perception-aware attacks against YouTube's copyright detection system---one of the rare examples of testing against actual commercial infrastructure. Their work demonstrated that attacks optimized in simulation required significant adaptation to succeed in practice.

\subsection{The Gradient Dependency Problem}

Apruzzese et al.'s critique centered on the observation that ``real attackers don't compute gradients.'' Our analysis confirms this concern persists: \textbf{67.8\% of papers require gradient access}, despite this capability being unavailable against most production systems.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig04_gradient_dependency.png}
    \caption{Gradient dependency analysis showing no meaningful improvement over time (68.2\% in 2022 to 65.9\% in 2025) and variation by attack type.}
    \label{fig:gradient}
\end{figure}

Perhaps more concerning, temporal analysis reveals no meaningful improvement. Gradient dependency has remained essentially flat: 68.2\% in 2022, 69.1\% in 2023, 66.8\% in 2024, and 65.9\% in 2025. The research community has not shifted toward gradient-free approaches despite explicit calls to do so.

USENIX research has pioneered gradient-free approaches in specific domains. The Universal Robustness Evaluation Toolkit (URET) from \citet{eykholt2023uret} addresses this gap by ``formulating adversarial generation as a graph exploration problem, seeking sequences of domain-specific, functionality-preserving transformations rather than relying on differentiable feature spaces.'' This framework enables studying systems utilizing inputs like malware binaries or tabular data ``where semantic and functional correctness must be maintained during perturbation.''

Similarly, practical LLM jailbreak attacks demonstrate that effective attacks need not be gradient-based. \citet{liu2024jailbreaking} and \citet{yu2024jailbreak} showed that jailbreaking large language models ``can be highly effective even when executed by inexperienced users via strategically crafted natural language prompts, emphasizing the potency of low-cost, accessible black-box attacks over complex gradient optimization.''

\subsection{Unrealistic Threat Model Assumptions}

White-box access remains the dominant assumption: \textbf{63.2\% of papers assume adversaries have complete knowledge of model architecture and parameters}. Only 34.1\% consider black-box scenarios matching real deployment conditions, and a mere 2.6\% examine gray-box settings.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig03_threat_model.png}
    \caption{Distribution of threat model assumptions across all papers, showing dominance of unrealistic white-box assumptions.}
    \label{fig:threat_model}
\end{figure}


This assumption fundamentally contradicts industrial reality. As \citet{grosse2024practical} document in their USENIX paper on practical threat models, ``academic studies often operate under assumptions of overly generous attacker access---such as extensive access to internal models, parameters, or training data---that do not reflect the stringent security controls present in real-world corporate environments.''

The foundational USENIX meta-analysis by \citet{arp2022dos} exposed these ``widespread methodological pitfalls in security research, including reliance on `lab-only evaluation' and deployment of `inappropriate threat models' that fail to account for adaptive adversaries.'' Three years later, the field has not substantively responded to this critique.

\subsection{Query Budget Assumptions}

Even papers claiming black-box threat models often make unrealistic assumptions about query access. \textbf{80.4\% of papers assume high query budgets ($>$1000 queries)}---impractical when commercial APIs implement rate limiting, repeated queries trigger fraud detection systems, and real-time constraints prevent iterative optimization.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig06_query_budget.png}
    \caption{Query budget assumptions showing 80.4\% of papers assume high query budgets that are impractical in real deployments.}
    \label{fig:query}
\end{figure}


Some recent work has begun addressing query efficiency. HARDBEAT from \citet{tao2023hardbeat} generates ``high-success-rate triggers needing knowledge only of the final predicted label (hard-label) and minimal queries, addressing restrictions often imposed by proprietary commercial services.'' Similarly, BounceAttack from \citet{wan2024bounceattack} demonstrates query-efficient decision-based attacks. However, these remain exceptions rather than the norm.

\subsection{Domain Bias: The Image Obsession}

Adversarial ML research exhibits severe domain bias: \textbf{65\% of papers focus exclusively on image data}. Text receives 11\% attention, audio 7\%, malware 6\%, with all other domains combined representing just 12\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig08_data_domains.png}
    \caption{Data domain distribution revealing severe image-centric bias in adversarial ML research.}
    \label{fig:domains}
\end{figure}

This creates dangerous blind spots. Financial systems process tabular data where adversarial perturbations cannot be measured by pixel distances. As \citet{kireev2023cost} observe for fraud detection, ``the meaningful constraint is not visual imperceptibility but rather the quantifiable financial cost or utility an adversary must expend.'' $L_p$ norms are meaningless for tabular financial data---what matters is whether fraudulent transactions remain economically viable.

\subsection{The Code Release Paradox}

One dimension shows positive results: \textbf{89.6\% of papers release their code}. This represents laudable commitment to reproducibility and significantly exceeds code release rates in many other fields.

However, this creates a new problem: code designed for research datasets often cannot transfer to production environments without substantial re-engineering. High code release rates may create an illusion of deployability that does not survive contact with production constraints.

\subsection{Gap Score Distribution}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig12_gap_score.png}
    \caption{Distribution of Gap Scores showing the typical paper (mean 3.17/6) makes roughly half of the measured impractical assumptions.}
    \label{fig:gap_score}
\end{figure}


The mean Gap Score across all 454 papers is \textbf{3.17 out of 6}, indicating the typical paper makes roughly half of the impractical assumptions we measured. The distribution peaks at scores of 3--4, with very few papers (approximately 10.5\%) achieving scores of 0--1 that would indicate deployment readiness.

Conference-level analysis reveals minimal variation: ACM CCS averages 3.04, NDSS 3.12, IEEE S\&P 3.18, and USENIX 3.25. No venue has established itself as more practice-focused than others---the theory-practice gap is an endemic problem across the entire security research community.

%==============================================================================
% 5. THEMATIC FINDINGS
%==============================================================================
\section{Thematic Findings: Understanding the Gap}

Beyond quantitative metrics, thematic analysis across venues reveals deeper structural problems in how adversarial ML research is conducted and evaluated.

\subsection{The Utility-Robustness Trade-off}

Perhaps the most significant barrier to deployment is the conflict between security guarantees and system performance. Research from USENIX Security (2022--2025) particularly illuminates this tension.

\citet{xiang2022patchcleanser} found that defensive proposals achieving certifiable robustness against adversarial patches frequently ``yielded poor clean classification accuracy, which inherently `discourages the real-world deployment' of these defenses.'' This pattern persisted through subsequent years. By 2024, \citet{xiang2024patchcure} documented that certifiably robust defenses in computer vision require ``10 to 100 times more inference-time computation than undefended models, rendering them computationally prohibitive for practical use.''

The problem extends beyond vision systems. \citet{ahmed2022keyword} found that defenses against malicious activations in voice assistants ``typically harm the natural accuracy---an unacceptable proposition for commercial systems.'' Similarly, widely used privacy-preserving techniques like DP-SGD ``compromise model utility significantly to achieve privacy guarantees''~\citep{liu2022mldoctor, tang2022membership}.

Some recent work shows promise in resolving this fundamental conflict. PatchCleanser introduced a double-masking approach compatible with any image classifier, achieving high certified robustness while preserving state-of-the-art clean accuracy~\citep{xiang2022patchcleanser}. MIST offers a pathway toward robust security without performance penalties by strategically limiting overfitting only to the most membership-vulnerable training instances~\citep{li2024mist}. CAMP training demonstrated that provable adversarial robustness in deep reinforcement learning need not sacrifice certified expected return---crucial for safety-critical robotics applications~\citep{wang2025camp}.

\subsection{Inappropriate Evaluation Metrics}

Research across venues reveals systematic problems with how attacks and defenses are evaluated.

\subsubsection{The $L_p$ Norm Problem}

Standard evaluation measures adversarial perturbation size using $L_p$ norms---mathematical measures of distance between original and perturbed inputs. However, as \citet{carlini2022membership} document, ``conventional distance metrics like $L_p$ norms---measuring pixel-level differences---do not reliably predict whether humans perceive adversarial perturbations as anomalous.''

This disconnect was empirically demonstrated by the Avara framework~\citep{ma2024avara}, which used VR environments and eye-tracking to study whether drivers notice adversarial traffic signs. They found that $L_p$ norms ``fail to predict'' whether human drivers notice adversarial perturbations: ``An attack deemed `imperceptible' by mathematical standards may be immediately obvious to a driver,'' while attacks violating $L_p$ constraints might go unnoticed in realistic driving conditions.

\subsubsection{Average-Case vs. Worst-Case Privacy}

Privacy attacks are evaluated using fundamentally inappropriate metrics. \citet{carlini2022membership} observe that ``privacy is fundamentally a worst-case concern: a defense succeeds only if it protects all individuals, not just the majority.'' Yet membership inference attacks are typically evaluated using average-case metrics (overall accuracy, AUC) that mask severe privacy leakage for specific individuals.

\subsection{Physical Deployment Constraints}

A fundamental limitation of conventional AML research lies in its focus on digital adversarial examples that fail to account for the complex physical conditions governing real-world perception systems.

\subsubsection{From Digital to Physical Attacks}

Digital perturbations optimized in simulation frequently fail when deployed physically due to environmental factors: distance and viewing angle variations, illumination changes, sensor noise, and compression artifacts. NDSS research has particularly emphasized this gap.

\citet{jia2022physical} developed robust physical adversarial example pipelines tested extensively against production autonomous vehicles running YOLO v5 traffic sign recognition. Their work required accounting for real-road conditions that simulation ignores.

Physical attack research at USENIX has expanded beyond vision systems. \citet{liu2023xadv} designed physically realizable 3D adversarial objects capable of deceiving X-ray prohibited item detection, requiring optimization for shape rather than color or texture and accounting for complex object overlap in luggage. \citet{cao2023lidar} demonstrated Physical Removal Attacks using focused laser spoofing to selectively remove LiDAR point cloud data on autonomous vehicles. The ``Tubes Among Us'' research~\citep{ahmed2023tubes} demonstrated analog adversarial attacks where human adversaries manipulate voice signals using simple tubes to bypass speaker recognition---``effectively bypassing established digital artifact detection methods.''

By 2025, physical attack research embraced increasingly practical scenarios. ``Shadow Hack''~\citep{kobayashi2025shadow} exploits LiDAR weaknesses using ordinary non-reflective materials placed on roads---requiring no specialized equipment. ATKSCOPES~\citep{zhang2025atkscopes} demonstrates rapid evasion against real-world perceptual hashing algorithms by dynamically adapting to victim systems.

\subsubsection{System Integration Vulnerabilities}

Research increasingly recognizes that integrating ML models into complex systems introduces vulnerabilities that isolated model analysis misses. \citet{debenedetti2024privacy} reveal that system-level components such as training data filters or output monitoring ``introduce critical privacy side channels easily exploitable by adaptive adversaries, often invalidating provable differential privacy guarantees.''

\citet{nasr2025magika} demonstrated this through the ``weakest-link'' problem: exploiting Google's Magika file-type classifier compromises Gmail's entire malware detection pipeline---even if other components are robust. A single non-robust component can compromise an entire security pipeline.

Models trained in high-level frameworks are compiled into optimized executables for deployment, but as \citet{chen2023obsan} document, ``security mechanisms integrated solely at the framework level fail once models are compiled.'' Defenses must be embedded within the DL compiler pipeline to persist through deployment---a requirement absent from most academic work.

\subsection{Attack Evolution Toward Practicality}

Despite methodological concerns about unrealistic assumptions, research has progressively shifted toward practical attack vectors.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig07_attack_types.png}
    \caption{Attack type distribution showing evasion attacks (48\%) dominate, with trends over time.}
    \label{fig:attack_types}
\end{figure}


Early practical attacks (2022) demonstrated physically realizable approaches like the ``frustum attack,'' which leverages environmental context to compromise automotive sensor fusion in black-box settings~\citep{hallyburton2022frustum}.

By 2023--2024, attacks increasingly capitalized on simplicity and accessibility. The effectiveness of jailbreaking LLMs through natural language prompts---even by inexperienced users---emphasized the potency of low-cost black-box attacks over complex gradient optimization.

The 2025 landscape shows attacks prioritizing stealth and persistence. MergeBackdoor~\citep{wang2025mergebackdoor} reveals supply chain threats where seemingly benign upstream models pass security checks but activate malicious backdoors upon merging with other components. Persistent backdoor strategies from \citet{guo2025persistent} target stable neuronal components, ensuring exploits survive continuous parameter updates in continual learning systems.

\subsection{Defense Evolution Toward Specialization}

Defensive research has evolved from generic solutions toward specialized, interpretable, and context-aware mechanisms.

Blacklight~\citep{li2022blacklight} successfully detected and mitigated nearly all black-box query-based attacks against MLaaS by leveraging the fact that iterative optimization inevitably produces highly similar queries---providing effective defense against persistent attackers that bypass account-based security measures.

Recent defenses demonstrate increased sophistication. JBShield~\citep{zhang2025jbshield} moves beyond heuristics for LLM protection by using the Linear Representation Hypothesis to identify and manipulate ``toxic'' and ``jailbreak'' concepts within hidden states. SafeSpeech~\citep{zhang2025safespeech} proactively poisons voice data during training to make synthesized audio unusable---achieving robustness surpassing inference-only defenses against voice cloning. DeBackdoor~\citep{popovic2025debackdoor} addresses realistic deployment constraints by providing backdoor detection effective under black-box access, data scarcity, and pre-deployment inspection limitations.

\subsection{Economic and Human Factor Blind Spots}

Academic research systematically ignores the economic and human dimensions of adversarial ML.

\subsubsection{The Economics of Attacks}

ACM CCS research has highlighted how commercial ML services create powerful financial incentives for IP theft that render many protective mechanisms inadequate. \citet{cong2022sslguard} document that stealing pre-trained encoders costs far less than training from scratch. \citet{lu2024neural} show that Neural Dehydration can remove watermarks using less than 2\% of training data. The fundamental economic asymmetry---model extraction attacks cost orders of magnitude less than defenses or the assets they protect---remains largely unaddressed.

\subsubsection{Organizational Barriers}

Beyond technical challenges, qualitative research reveals significant organizational barriers preventing industry adoption. \citet{mink2023barriers} found that ``machine learning practitioners often lack institutional motivation and usable resources to understand and mitigate adversarial threats, frequently assuming security and machine learning are entirely disconnected fields.''

This organizational detachment results in low prioritization of adversarial evaluations before deployment and poor visibility into monitoring for active attacks. Defenses remain unimplemented due to ``isolation between ML and security teams or because competing business priorities outweigh the cost and time needed for robust implementation.''

%==============================================================================
% 6. TEMPORAL TRENDS
%==============================================================================
\section{Temporal Trends: Is the Gap Narrowing?}

A critical question motivates this review: has the research community responded to calls for greater practical relevance? Our temporal analysis provides a clear answer: \textbf{no, the gap has not meaningfully narrowed}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig11_yearly_trends.png}
    \caption{Temporal trends showing the theory-practice gap has not narrowed from 2022--2025, with some metrics worsening.}
    \label{fig:trends}
\end{figure}


\subsection{Metrics That Have Not Improved}

\textbf{Real-world testing} remains at approximately 5\% across all years. Despite explicit calls for deployment validation, the research community has not shifted toward testing on production systems.

\textbf{Gradient dependency} has remained essentially flat at 67--69\%. There has been no meaningful movement toward gradient-free approaches.

\textbf{White-box assumptions} show no reduction (63\% in 2025 vs. 64\% in 2022). Threat model realism has not improved.

\textbf{Domain bias} persists with image data dominating 65\% of papers throughout the study period.

\textbf{Economic analysis} remains below 11\% in all years.

\subsection{Metrics Showing Marginal Improvement}

Query efficiency shows modest progress, with high-budget assumptions declining from 80.4\% to approximately 76\% by 2025. Some researchers have begun developing query-efficient attacks, though these remain minority approaches.

Zero-knowledge attacks have gained recognition, with growing acknowledgment that adversaries often lack full system knowledge. However, this has not translated into substantial shifts in threat modeling practices.

\subsection{Emerging Threat Categories}

The 2024--2025 period has seen rapid growth in LLM security research, creating urgent new gaps. Jailbreak attacks evolve faster than RLHF defenses can adapt~\citep{shen2024llm}. Prompt injection against commercial LLM services poses immediate practical threats. Adversarial training---the standard defense approach---proves too computationally costly for broad deployment.

%==============================================================================
% 7. CROSS-VENUE ANALYSIS
%==============================================================================
\section{Cross-Venue Analysis: Conference-Specific Contributions}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig10_conference_comparison.png}
    \caption{Conference comparison heatmap showing all venues share similar gap patterns.}
    \label{fig:heatmap}
\end{figure}


While all venues share the fundamental theory-practice gap, each has developed distinctive emphases that coanalysingy illuminate different facets of the problem.

\subsection{ACM CCS: Economics and System Integration}

ACM CCS research uniquely emphasizes business logic, usability constraints, and intellectual property protection. emphasisesbutions include demonstrating how economic incentives fundamentally shape the threat landscape~\citep{cong2022sslguard, lu2024neural}, documenting modellingonnect between mathematical metrics and human perception~\citep{ma2024avara}, analyzing system-level integration vulnerabilities~\citep{nasr2025magika}, and revealing architectural constraints in emerging deployment patterns.

\subsection{IEEE S\&P: Efficiency and Formal Guarantees}

IEEE S\&P research emphasizes computational efficiency, privacy-utility trade-offs, and certemphasisesscalability. The venue has advanced understanding of inappropriate threat modeling and resource assumptions~\citep{carlini2022membershipanalysingished privacy as a worst-case rather than average-case property, documented accuracy-privacy trade-offs~\citep{rezaei2023accuracy}, and highlighted scalability challenges preventing certified robustness deployment~\citep{li2023sok}.

\subsection{NDSS: Physemphasisesraints and Operational Realities}

NDSS research emphasizes system-level constraints, distributed training challengerigourd physical deployment realities. Contributions include documenting the gap betweanalysedal perturbations and physical deployment~\citep{jia2022physical}, developing appropriate metrics for non-image domains~\citep{kireev2023cost}, analyzing distributed training heterogeneity challenges~\citep{rieger2022deepsight}, and studying adversarial loops where defenses create exploitable side channels.

\subsection{USENIX Security: Real-World Validation and Domain Diversity}

USENIX Security research emphasizes testing on deployed systems and domain-specific constraints. The venue has documented tensions between theoretical rigor and deployment constraints~\citep{xiang2022patchcleanser, xiang2024patchcure}, analyzed trade-offs academia ignores (computational cost, regulatory compliance, usability)~\citep{ahmed2022keyword}, studied adversarial evolution when defenses meet adaptive attackers in production, and examined domain-specific requirements ignored by image-focused research~\citep{eykholt2023uret}.

\subsection{Attack versus Defense Papers}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{fig09_attack_vs_defense.png}
    \caption{Comparison of practicality metrics between attack-focused and defense-focused papers.}
    \label{fig:atk_def}
\end{figure}

Our analysis reveals that defense papers are slightly more practical than attack papers on average. Defense papers show 6\% real-system testing versus 5\% for attacks, 41\% gradient-free approaches versus 27\%, and 38\% black-box focus versus 31\%. However, both categories remain far from deployment readiness.

%==============================================================================
% 8. RECOMMENDATIONS
%==============================================================================
\section{Recommendations}

Bridging the theory-practice gap requires coordinated action across the research ecosystem.

\subsection{For Researchers}

\subsubsection{Immediate Actions}

\textbf{Test on real systems.} Partner with industry to evaluate against production deployments. Even limited real-world testing reveals constraints invisible in laboratory settings.

\textbf{Adopt realistic threat models.} Default to black-box access. When white-box assumptions are necessary, justify them explicitly and acknowledge limitations.

\textbf{Diversify domains.} Expand beyond image classification to tabular data, graphs, time-series, and multimodal systems where practical deployment is occurring.

\textbf{Analyze economics.} Quantify attack costs, defender resources, and ROI trade-offs. Security decisions are ultimately economic decisions.

\textbf{Conduct human-in-the-loop evaluation.} Test perceptibility against actual humans rather than relying solely on mathematical metrics.

\subsubsection{Methodological Improvements}

Evaluate privacy using true-positive rate at low false-positive rates, not average accuracy or AUC. For non-image domains, define domain-appropriate perturbation constraints. Report query budgets realistically based on what commercial APIs actually allow. Measure computational requirements in practical units like wall-clock time and dollar cost.

\subsection{For Venues and Program Committees}

\textbf{Require real-world validation.} At minimum, require authors to justify why real-system testing is infeasible if omitted.

\textbf{Create artifact badges for deployability.} Recognize work tested on production systems with explicit recognition.

\textbf{Develop an adversarial realism checklist.} Require papers to explicitly address threat model realism, query budget constraints, gradient requirements, domain-appropriate metrics, economic considerations, and adaptive defense testing.

\textbf{Encourage negative results.} Papers showing that attacks fail under realistic constraints provide valuable information that positive-result publication bias suppresses.

\subsection{For Industry Practitioners}

\textbf{Assume academic attacks overestimate threat severity.} Adjust risk assessments for deployment realities rather than accepting laboratory success rates.

\textbf{Assume academic defenses underestimate deployment costs.} Budget for substantial re-engineering before research prototypes become production-ready.

\textbf{Prioritize defenses against realistic threats:} black-box attacks rather than gradient-based ones, low query budget scenarios, economically motivated adversaries, and domain-specific constraints.

\textbf{Contribute data.} Anonymized logs of real attack attempts would ground academic research in deployment reality.

\subsection{For Funding Agencies}

Fund industry-academic partnerships with required real-world validation components. Support long-term deployment studies rather than just paper publication. Incentivize replication studies that validate academic claims against production systems. Create red team / blue team competitions with realistic constraints.

%==============================================================================
% 9. LIMITATIONS
%==============================================================================
\section{Limitations and Threats to Validity}

\subsection{Scope Limitations}

This review focuses on four security venues and may not capture patterns at ML conferences (NeurIPS, ICML, ICLR) where different norms may apply. Publication bias likely suppresses negative results---attacks that fail under realistic constraints or defenses that prove impractical are less likely to be published. Our 2022--2025 window may not capture longer-term trends.

\subsection{Coding Limitations}

The Gap Score reduces complex trade-offs to binary decisions, potentially oversimplifying nuanced situations. Manual coding introduces subjectivity, particularly for papers straddling categories. The definition of ``real system testing'' may vary---some papers test on emulated production environments that share some but not all deployment constraints.

\subsection{Generalizability}

Security venues may actually be more practice-focused than average computer science venues given their traditional emphasis on real-world threats. Our findings may therefore underestimate the theory-practice gap in the broader ML community.

%==============================================================================
% 10. CONCLUSION
%==============================================================================
\section{Conclusion}

Four years and 454 papers after ``Real Attackers Don't Compute Gradients,'' the adversarial machine learning research community has made insufficient progress toward practical relevance.

The core problem is structural: academic research optimizes for publication metrics---novelty, theoretical rigor, impressive attack success rates---rather than deployment viability. Incentive structures reward papers that advance the state of the art against previous papers rather than papers that translate to deployed defenses.

The quantitative evidence is stark:
\begin{itemize}[noitemsep]
    \item 94.7\% of papers never test on real systems
    \item 67.8\% require gradients that real attackers lack
    \item 80.4\% assume query budgets that real systems don't allow
    \item 63.2\% assume white-box access that real deployments don't provide
\end{itemize}

The qualitative evidence is equally concerning. $L_p$ norms don't predict human perception. Certified robustness doesn't scale to production models. Defenses ignore economic costs and usability constraints. Evaluation uses average-case metrics for worst-case properties.

The path forward requires structural changes. Venues must incentivize real-world validation. Researchers must default to realistic threat models. Industry must contribute deployment data. Funding must reward practical impact over novelty.

The gap between theory and practice in adversarial ML is not narrowing organically. Only deliberate, community-wide effort---changing publication incentives, evaluation standards, and collaboration models---can bridge it. The security of increasingly pervasive ML systems depends on the research community's willingness to prioritize practical impact over academic metrics.

%==============================================================================
% REFERENCES
%==============================================================================
\newpage
\bibliographystyle{unsrtnat}
\bibliography{ref}

%==============================================================================
% APPENDIX
%==============================================================================
\newpage
\appendix
\section{Complete Paper Analysis Dataset}

The complete analysis of all 454 papers is available in the supplementary CSV file: 
\texttt{all\_conferences\_analysis\_results\_2022\_2025.csv}

The dataset includes the following columns for each paper:
\begin{itemize}[noitemsep]
    \item Year, Conference, Filename, Title, Authors
    \item G1 (Focus), G2 (Attack Type), G3 (ML Type), G4 (Data Domain)
    \item G5 (Economics), G6 (Code Release), G7 (Real System Testing)
    \item T1 (Threat Model), T2 (Training Data Access)
    \item Q1 (Gradient Requirements), Q2 (Query Budget), Q3 (Computation)
    \item Gap indicator flags and Traditional Score
\end{itemize}

% Insert CSV table here
\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}
    \hline
        Year & Conference & Filename & Title & Authors & G1 & G2 & G3 & G4 & G5 & G6 & G7 & T1 & T2 & Q1 & Q2 & Q3 & Flag\_Grad & Flag\_HighQ & Flag\_WB & Flag\_NoEcon & Flag\_NoCode & Flag\_NoReal & Traditional\_Score & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559335.pdf & Identifying a Training-Set Attackâ€™s Target Using Renormalized Influence Estimation Zayd Hammoudeh University of Oregon Eugene, Oregon, USA zayd@cs.uor & Using Renormalized Influence Estimation Zayd Hammoudeh University of Oregon Eugene, Oregon, USA zayd@cs.uoregon.eduDaniel Lowd & def & Poisoning & DL & Images & YES & YES & NO & Gray-box & Full & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559350.pdf & Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception Rui Duan University of South Florida Tampa, FL, USA ruidu & Reverse-Engineering Human Perception Rui Duan University of South Florida Tampa, FL, USA ruiduan@usf.eduZhe Qu & atk & Evasion & DL & Audio & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559355.pdf & SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders Tianshuo Cong Institute for Advanced Study, BNRist, Tsinghua Univers & Tianshuo Cong Institute for Advanced Study, BNRist, Tsinghua UniversityXinlei He CISPA Helmholtz Center for Information SecurityYang Zhang & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559358.pdf & Finding MNEMON: Reviving Memories of Node Embeddings Yun Shenâˆ— NetAppYufei Han InriaZhikun Zhang CISPA Helmholtz Center for Information Security Min C & CISPA Helmholtz Center for Information SecurityGianluca Stringhini Boston University ABSTRACT Previous security research efforts orbiting around graphs have & atk & Privacy & DL & Other & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559359.pdf & Auditing Membership Leakages of Multi-Exit Networks Zheng Li CISPA Helmholtz Center for Information SecurityYiyong Liu CISPA Helmholtz Center for Info & CISPA Helmholtz Center for Information SecurityYiyong Liu CISPA Helmholtz Center for Information SecurityXinlei He CISPA Helmholtz Center for Information Security & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559388.pdf & Understanding Real-world Threats to Deep Learning Models in Android Apps Zizhuang Deng SKLOIS, IIE, CASâ€  School of Cyber Security, UCASâ€¡ Beijing, Chin & School of Cyber Security, UCASâ€¡ Beijing, China dengzizhuang@iie.ac.cnKai Chen & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559390.pdf & Physical Hijacking Attacks against Object Trackers Raymond Muller Purdue University mullerr@purdue.eduYanmao Man University of Arizona yman@arizona.ed & Physical Hijacking Attacks against Object Trackers Raymond Muller Purdue University mullerr@purdue.eduYanmao Man University of Arizona & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3559392.pdf & ""Is your explanation stable?"": A Robustness Evaluation Framework for Feature Attribution Yuyou Ganâˆ— Zhejiang University ganyuyou@zju.edu.cnYuhao Maoâˆ—  & Framework for Feature Attribution Yuyou Ganâˆ— Zhejiang University ganyuyou@zju.edu.cnYuhao Maoâˆ— Zhejiang University, ETH ZÃ¼rich & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560554.pdf & Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets Florian TramÃ¨râˆ—â€  ETH ZÃ¼richReza Shokri National University of SingaporeAyrton S & Florian TramÃ¨râˆ—â€  ETH ZÃ¼richReza Shokri National University of SingaporeAyrton San Joaquin Yale-NUS College Hoang Le & atk & Poisoning & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560557.pdf & Eluding Secure Aggregation in Federated Learning via Model Inconsistency Dario Pasquini dario.pasquini@epfl.ch SPRING Lab, EPFL Lausanne, SwitzerlandD & via Model Inconsistency Dario Pasquini dario.pasquini@epfl.ch SPRING Lab, EPFL Lausanne, SwitzerlandDanilo Francati & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560561.pdf & Post-breach Recovery:Protectionagainst White-box Advers arial ExamplesforLeaked DNN Models Shawn Shan shawnshan@cs.uchicago.edu University ofChicago C & ExamplesforLeaked DNN Models Shawn Shan shawnshan@cs.uchicago.edu University ofChicago Chicago,USAWenxinDing & def & Evasion & DL & Images & YES & YES & NO & White-box & Partial & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560566.pdf & Harnessing Perceptual Adversarial Patches for Crowd Counting Shunchang Liuâˆ— Beihang University Beijing, China liusc@buaa.edu.cnJiakai Wangâˆ— Zhongguanc & Harnessing Perceptual Adversarial Patches for Crowd Counting Shunchang Liuâˆ— Beihang University Beijing, China liusc@buaa.edu.cnJiakai Wangâˆ— & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560573.pdf & Feature Inference Attack on Shapley Values Xinjian Luo National University of Singapore xinjluo@comp.nus.edu.sgYangfan Jiang National University of Si & Feature Inference Attack on Shapley Values Xinjian Luo National University of Singapore xinjluo@comp.nus.edu.sgYangfan Jiang National University of Singapore & atk & Privacy & DL & Other & YES & NO & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 0 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560581.pdf & QuerySnout: Automating the Discovery of Attribute Inference Attacks against Query-Based Systems Ana-Maria CreÅ£uâˆ— Imperial College London London, Unite & Imperial College London London, United Kingdom a.cretu@imperial .ac.ukFlorimond Houssiauâˆ— The Alan Turing Institute London, United Kingdom & atk & Privacy & Both & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560586.pdf & StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning Yupei Liu Duke University yupei.liu@duke.eduJinyuan Jia Duke University jinyu & Learning Yupei Liu Duke University yupei.liu@duke.eduJinyuan Jia Duke University & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560599.pdf & Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots Wai Man Si CISPA Helmholtz Center for Information SecurityMichael Backes & CISPA Helmholtz Center for Information SecurityJeremy Blackburn Binghamton University Emiliano De Cristofaro University College LondonGianluca Stringhini & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560611.pdf & E FFeL: Ensuring Integrity For Federated Learning Amrita Roy Chowdhuryâˆ— University of Wisconsin-MadisonChuan Guo Meta AISomesh Jhaâ€  University of Wisc & Amrita Roy Chowdhuryâˆ— University of Wisconsin-MadisonChuan Guo Meta AISomesh Jhaâ€  & def & Poisoning & DL & Images & YES & NO & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560615.pdf & Phishing URL Detection: A Network-based Approach Robust to Evasion Taeri Kimâˆ— Hanyang University Seoul, Korea taerik@hanyang.ac.krNoseong Parkâˆ— Yonsei & A Network-based Approach Robust to Evasion Taeri Kimâˆ— Hanyang University Seoul, Korea taerik@hanyang.ac.krNoseong Parkâˆ— & def & Evasion & Both & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560619.pdf & On the Privacy Risks of Cell-Based NAS Architectures Hai Huang CISPA Helmholtz Center for Information SecurityZhikun Zhang CISPA Helmholtz Center for & CISPA Helmholtz Center for Information SecurityQi Li Tsinghua University \& Zhongguancun LabYang Zhang CISPA Helmholtz Center for & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560621.pdf & Adversarial Correctness and Privacy for Probabilistic Data Structures Mia FiliÄ‡ ETH ZÃ¼rich ZÃ¼rich, Switzerland mia.filic@inf.ethz.chKenneth G. Paterso & ETH ZÃ¼rich ZÃ¼rich, Switzerland mia.filic@inf.ethz.chKenneth G. Paterson ETH ZÃ¼rich ZÃ¼rich, Switzerland & def & Privacy & Both & Other & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560660.pdf & SpecPatch: Human-in-the-Loop Adversarial Audio Spectrogram Patch Attack on Speech Recognition Hanqing Guo SEIT Lab Michigan State University East Lans & Hanqing Guo SEIT Lab Michigan State University East Lansing, MI, USA guohanqi@msu.eduYuanda Wang & atk & Evasion & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560662.pdf & Group Property Inference Attacks Against Graph Neural Networks Xiuling Wang Stevens Institute of Technology Hoboken, NJ, USA xwang193@stevens.eduWendy & Stevens Institute of Technology Hoboken, NJ, USA xwang193@stevens.eduWendy Hui Wang Stevens Institute of Technology Hoboken, NJ, USA & atk & Privacy & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560663.pdf & Are Attribute Inference Attacks Just Imputation? Bargav Jayaraman University of Virginia Charlottesville, VA, USA bj4nq@virginia.eduDavid Evans Univer & Are Attribute Inference Attacks Just Imputation? Bargav Jayaraman University of Virginia Charlottesville, VA, USA bj4nq@virginia.eduDavid Evans & atk & Privacy & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560671.pdf & When Evil Calls: Targeted Adversarial Voice over IP Network Han Liu Washington University in St. Louis St. Louis, USA h.liu1@wustl.eduZhiyuan Yu Washi & When Evil Calls: Targeted Adversarial Voice over IP Network Han Liu Washington University in St. Louis St. Louis, USA h.liu1@wustl.eduZhiyuan Yu & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 0 & 0 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560675.pdf & Enhanced Membership Inference Attacks against Machine Learning Models Jiayuan Ye National University of Singapore (NUS) jiayuan@comp.nus.edu.sgAadyaa & Learning Models Jiayuan Ye National University of Singapore (NUS) jiayuan@comp.nus.edu.sgAadyaa Maddi & atk & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560678.pdf & LoneNeuron: A Highly-Effective Feature-Domain Neural Trojan Using Invisible and Polymorphic Watermarks Zeyan Liu Department of EECS and Institute of I & Using Invisible and Polymorphic Watermarks Zeyan Liu Department of EECS and Institute of Information Sciences The University of Kansas, Lawrence, KS, USA zyliu@ku.eduFengjun Li & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560683.pdf & Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models Jiawei Liu Wuhan University laujames2017@whu.edu.cnYangyang Kang Ali & Neural Ranking Models Jiawei Liu Wuhan University laujames2017@whu.edu.cnYangyang Kang Alibaba Group, China & atk & Evasion & DL & Text & YES & YES & NO & Black-box & Partial & YES & High & High & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560684.pdf & Membership Inference Attacks by Exploiting Loss Trajectory Yiyong Liu CISPA Helmholtz Center for Information SecurityZhengyu Zhao CISPA Helmholtz Cent & CISPA Helmholtz Center for Information SecurityZhengyu Zhao CISPA Helmholtz Center for Information Security Michael Backes CISPA Helmholtz Center for & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560694.pdf & Membership Inference Attacks and Generalization: A Causal Perspective Teodora Baluta National University of Singapore Singapore teobaluta@comp.nus.edu & A Causal Perspective Teodora Baluta National University of Singapore Singapore teobaluta@comp.nus.edu.sgShiqi Shen & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & ACM & 3548606.3560705.pdf & LPGNet: Link Private Graph Networks for Node Classification Aashish Kolluri aashish7@comp.nus.edu.sg National University of Singapore School of Comput & LPGNet: Link Private Graph Networks for Node Classification Aashish Kolluri aashish7@comp.nus.edu.sg National University of Singapore School of Computing & def & Privacy & DL & Other & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600a346.pdf & BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning Jinyuan Jiaâˆ—Yupei Liuâˆ—Neil Zhenqiang Gong Duke University \{jinyuan.ji & Encoders in Self-Supervised Learning Jinyuan Jiaâˆ—Yupei Liuâˆ—Neil Zhenqiang Gong Duke University \{jinyuan.jia, yupei.liu, neil.gong }@duke.edu Abstract â€”Self-supervised learning in computer vision aims  & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600a415.pdf & Universal 3-Dimensional Perturbations for Black-Box Attacks on Video Recognition Systems Shangyu Xie1, Han Wang1, Yu Kong2, Yuan Hong1 1Illinois Insti & 1Illinois Institute of Technology, Chicago, IL 60616 2Rochester Institute of Technology, Rochester, NY 14623 Email:fsxie14, hwang185g@hawk.iit.edu, yu.kong@rit.edu, yuan.hong@iit.edu Abstract â€”Widely  & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600a522.pdf & LINKTELLER : Recovering Private Edges from Graph Neural Networks via Inï¬‚uence Analysis Fan Wu1Yunhui Long1Ce Zhang2Bo Li1 1University of Illinois at U & Graph Neural Networks via Inï¬‚uence Analysis Fan Wu1Yunhui Long1Ce Zhang2Bo Li1 1University of Illinois at Urbana-Champaign2ETH Z Â¨urich ffanw6,ylong4,lbo g@illinois.edu ce.zhang@inf.ethz.ch Abstract â€” & atk & Privacy & DL & Other & YES & YES & NO & Black-box & Full & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600a773.pdf & Bad â€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œâ€Œ & Imperceptible NLP Attacks Nicholas Boucher University of Cambridge Computer Science \& Technology nicholas.boucher@cl.cam.ac.ukIlia Shumailov & atk & Evasion & DL & Text & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600a980.pdf & Asleep at the Keyboard? Assessing the Security of GitHub Copilotâ€™s Code Contributions Hammond Pearce Department of ECE New York University Brooklyn, N & Security of GitHub Copilotâ€™s Code Contributions Hammond Pearce Department of ECE New York University Brooklyn, NY , USA & def & ~ & DL & Other & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b013.pdf & Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models Jialuo Chenâˆ—, Jingyi Wangâˆ—/Letter, Tinglan Pengâˆ—, Y oucheng Sunâ€ , Pe & Jialuo Chenâˆ—, Jingyi Wangâˆ—/Letter, Tinglan Pengâˆ—, Y oucheng Sunâ€ , Peng Chengâˆ—, Shouling Jiâˆ—, Xingjun Maâ€¡,B oL iÂ§and Dawn SongÂ¶ âˆ—Zhejiang University,â€ University of Manchester,â€¡Fudan University,Â§UIUC,Â¶U & def & ~ & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b031.pdf & Model Stealing Attacks Against Inductive Graph Neural Networks Yun Shen1Xinlei He2Yufei Han3Yang Zhang2 1Norton Research Group2CISPA Helmholtz Cente & Yun Shen1Xinlei He2Yufei Han3Yang Zhang2 1Norton Research Group2CISPA Helmholtz Center for Information Security3INRIA Abstract â€”Many real-world data come in the form of graphs. Graph neural networks & atk & Evasion & DL & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b117.pdf & Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning Virat Shejwalkarâˆ—, Amir Houmansadrâˆ—, Peter Kair & Production Federated Learning Virat Shejwalkarâˆ—, Amir Houmansadrâˆ—, Peter Kairouzâ€ , Daniel Ramageâ€  âˆ—University of Massachusetts Amherstâ€ Google Research âˆ—\{vshejwalkar, amir }@cs.umass.edu,â€ \{kairouz, dra & atk & Poisoning & DL & Images & YES & NO & NO & White-box & Partial & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b135.pdf & Sphinx: Enabling Privacy-Preserving Online Learning over the Cloud Han Tian1Chaoliang Zeng1Zhenghang Ren1Di Chai1;2Junxue Zhang1;2Kai Chen1Qiang Yang1 & Sphinx: Enabling Privacy-Preserving Online Learning over the Cloud Han Tian1Chaoliang Zeng1Zhenghang Ren1Di Chai1;2Junxue Zhang1;2Kai Chen1Qiang Yang1 1Hong Kong University of Science and Technology2C & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b165.pdf & Transcending T RANSCEND : Revisiting Malware Classiï¬cation in the Presence of Concept Drift Federico Barberoyk, Feargus Pendleburyzx\{, Fabio Pierazz & Classiï¬cation in the Presence of Concept Drift Federico Barberoyk, Feargus Pendleburyzx\{, Fabio Pierazziy, Lorenzo Cavallaro\{ yKingâ€™s College London,zRoyal Holloway, University of London,xThe Alan T & def & ~ & Both & Malware & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b344.pdf & Model Orthogonalization: Class Distance Hardening in Neural Networks for Better Security Guanhong Tao, Yingqi Liu, Guangyu Shen, Qiuling Xu, Shengwei  & in Neural Networks for Better Security Guanhong Tao, Yingqi Liu, Guangyu Shen, Qiuling Xu, Shengwei An, Zhuo Zhang, Xiangyu Zhang Department of Computer Science, Purdue University Email: \{taog, liu175 & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b519.pdf & Membership Inference Attacks From First Principles Nicholas Carlini1Steve Chien1Milad Nasr1;2Shuang Song1Andreas Terzis1Florian Tram `er1 1Google Res & Membership Inference Attacks From First Principles Nicholas Carlini1Steve Chien1Milad Nasr1;2Shuang Song1Andreas Terzis1Florian Tram `er1 1Google Research2University of Massachusetts Amherst Abstract & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b526.pdf & IRShield: A Countermeasure Against Adversarial Physical-Layer Wireless Sensing Paul Staat, Simon Mulzery, Stefan Rothy, Veelasha Moonsamyy, Markus He & Markus Heinrichsz, Rainer Kronbergerz, Aydin Sezginy, Christof Paar Max Planck Institute for Security and Privacy, Bochum, Germany yRuhr University Bochum, Bochum, Germany zTH K Â¨oln â€“ University of & def & Privacy & Both & Other & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b532.pdf & Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures Eugene Bagdasaryan Cornell Tech eugene@cs.cornell.eduVitaly Shmatikov C & Eugene Bagdasaryan Cornell Tech eugene@cs.cornell.eduVitaly Shmatikov Cornell Tech shmat@cs.cornell.edu & atk & Poisoning & DL & Text & YES & YES & NO & Black-box & ~ & YES & High & High & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b542.pdf & â€œAdversarial Examplesâ€ for Proof-of-Learning Rui Zhangâ€ , Jian Liuâ€ âˆ—, Yuan Ding, Zhibo Wang, Qingbiao Wu, and Kui Ren Zhejiang University Email: \{zhang & â€œAdversarial Examplesâ€ for Proof-of-Learning Rui Zhangâ€ , Jian Liuâ€ âˆ—, Yuan Ding, Zhibo Wang, Qingbiao Wu, and Kui Ren Zhejiang University Email: \{zhangrui98, liujian2411, dy1ant, zhibowang, qbwu, kuire & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b547.pdf & Are We There Yet? Timing and Floating-Point Attacks on Differential Privacy Systems Jiankai Jin, Eleanor McMurtryyz, Benjamin I. P. Rubinstein, Olga & Attacks on Differential Privacy Systems Jiankai Jin, Eleanor McMurtryyz, Benjamin I. P. Rubinstein, Olga Ohrimenko School of Computing and Information Systems, The University of Melbourne yDepartm & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b551.pdf & DeepSteal: Advanced Model Extractions Leveraging Efï¬cient Weight Stealing in Memories Adnan Siraj Rakin*1, Md Haï¬zul Islam Chowdhuryy*2, Fan Yao2, and & Weight Stealing in Memories Adnan Siraj Rakin*1, Md Haï¬zul Islam Chowdhuryy*2, Fan Yao2, and Deliang Fan1 1School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ 2 & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b552.pdf & SoK: Authentication in Augmented and Virtual Reality Sophie Stephensony, Bijeeta Palz, Stephen Fany, Earlence Fernandesy, Yuhang Zhaoy, Rahul Chatterj & SoK: Authentication in Augmented and Virtual Reality Sophie Stephensony, Bijeeta Palz, Stephen Fany, Earlence Fernandesy, Yuhang Zhaoy, Rahul Chatterjeey yUniversity of Wisconsinâ€”Madison, zCornell Uni & def & ~ & Both & Other & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b556.pdf & Reconstructing Training Data with Informed Adversaries Borja Balle* DeepMindGiovanni Cherubin*â€  Microsoft ResearchJamie Hayes* DeepMind Abstract â€”Give & Borja Balle* DeepMindGiovanni Cherubin*â€  Microsoft ResearchJamie Hayes* DeepMind Abstract â€”Given access to a machine learning model, can an adversary reconstruct the modelâ€™s training data? This work & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b561.pdf & PICCOLO : Exposing Complex Backdoors in NLP Transformer Models Yingqi Liu1*, Guangyu Shen1*, Guanhong Tao1, Shengwei An1, Shiqing Ma2, Xiangyu Zhang1  & Transformer Models Yingqi Liu1*, Guangyu Shen1*, Guanhong Tao1, Shengwei An1, Shiqing Ma2, Xiangyu Zhang1 Purdue University1, Rutgers University2, \{liu1751, shen447, taog, an93 }@purdue.edu ,sm2283@cs & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b569.pdf & Property Inference from Poisoning Saeed Mahloujifar Princeton University sfar@princeton.eduEsha Ghosh Microsoft Research esha.ghosh@microsoft.comMelis & Property Inference from Poisoning Saeed Mahloujifar Princeton University sfar@princeton.eduEsha Ghosh Microsoft Research & atk & Poisoning & DL & Images & YES & YES & NO & Black-box & Full & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & IEEE & 131600b576.pdf & Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings Yuhao Maoy, Chong Fu, Saizhuo Wang, Shouling Ji()), Xuh & Yuhao Maoy, Chong Fu, Saizhuo Wang, Shouling Ji()), Xuhong Zhangz()), Zhenguang Liu, Jun Zhoux, Alex X. Liux, Raheem Beyah\{, Ting Wangk Zhejiang University,yETH Z Â¨urich,zZhejiang University N & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-130-paper.pdf & Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Trafï¬c Sign Recognition Systems Wei Jia School of Cyber Science & School of Cyber Science and Engineering Huazhong Univ. of Sci. \& Tech. jiaw@hust.edu.cnZhaojun Lu* School of Cyber Science and Engineering Huazhong Univ. of Sci. \& Tech. & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-156-paper.pdf & DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-R & Federated Learning Through Deep Model Inspection Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi Technical University of Darmstadt, Germany fphillip.rieger, ducthien.nguyen, mar & def & Poisoning & DL & Text & YES & NO & NO & White-box & ~ & NO & Low & Low & 0 & 0 & 1 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-19-paper.pdf & Property Inference Attacks Against GANs Junhao Zhouâ€ âˆ—, Yufei Chenâ€ âˆ—, Chao Shenâ€ Â§, Yang Zhangâ€¡Â§ â€ Faculty of Electronic and Information Engineering, Xiâ€™ & Property Inference Attacks Against GANs Junhao Zhouâ€ âˆ—, Yufei Chenâ€ âˆ—, Chao Shenâ€ Â§, Yang Zhangâ€¡Â§ â€ Faculty of Electronic and Information Engineering, Xiâ€™an Jiaotong University â€¡CISPA Helmholtz Center for & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Full & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-200-paper.pdf & RamBoAttack: A Robust Query Efï¬cient Deep Neural Network Decision Exploit Viet Quoc V o The University of Adelaide viet.vo@adelaide.edu.auEhsan Abbasn & RamBoAttack: A Robust Query Efï¬cient Deep Neural Network Decision Exploit Viet Quoc V o The University of Adelaide viet.vo@adelaide.edu.auEhsan Abbasnejad The University of Adelaide & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-335-paper.pdf & MIRROR: Model Inversion for Deep Learning Network with High Fidelity Shengwei Anâ€ , Guanhong Taoâ€ , Qiuling Xuâ€ , Yingqi Liuâ€ , Guangyu Shenâ€ , Yuan Yaoâ€¡,  & Shengwei Anâ€ , Guanhong Taoâ€ , Qiuling Xuâ€ , Yingqi Liuâ€ , Guangyu Shenâ€ , Yuan Yaoâ€¡, Jingwei Xuâ€¡, Xiangyu Zhangâ€  â€ Department of Computer Science, Purdue University, USA â€¡State Key Laboratory for Novel Sof & atk & Privacy & DL & Images & YES & YES & YES & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-54-paper.pdf & Local and Central Differential Privacy for Robustness and Privacy in Federated Learning Mohammad Naseri University College London (UCL) mohammad.naser & Robustness and Privacy in Federated Learning Mohammad Naseri University College London (UCL) mohammad.naseri.19@ucl.ac.ukJamie Hayesâˆ— DeepMind & both & Poisoning & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & NDS & 2022-64-paper.pdf & Get a Model! Model Hijacking Attack Against Machine Learning Models Ahmed Salem Michael Backes Yang Zhang CISPA Helmholtz Center for Information Secur & Ahmed Salem Michael Backes Yang Zhang CISPA Helmholtz Center for Information Security fahmed.salem, director, zhang g@cispa.de Abstract â€”Machine learning (ML) has established itself as a cornerstone f & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & 2108.09135v2.pdf & PatchCleanser: Certiï¬ably Robust Defense against Adversarial Patches for Any Image Classiï¬er Chong Xiang Princeton UniversitySaeed Mahloujifar Princet & for Any Image Classiï¬er Chong Xiang Princeton UniversitySaeed Mahloujifar Princeton UniversityPrateek Mittal Princeton University & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-ahmed.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Towards More Robust Keyword Spotting  for Voice Assistants Shimaa Ahmed, University of Wisconsin-Madison; Ilia Shumailov,   University of Cambridge; Nicolas Papernot, University of & def & Privacy & DL & Audio & YES & YES & YES & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-arp.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & Daniel Arp, Technische UniversitÃ¤t Berlin; Erwin Quiring, Technische UniversitÃ¤t  Braunschweig; Feargus Pendlebury, Kingâ€™s College London and Royal Holloway,  University of London and The Alan Turing  & def & ~ & Both & Malware & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-blue.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & Vocal Tract Reconstruction Logan Blue, Kevin Warren, Hadi Abdullah, Cassidy Gibson, Luis Vargas,  Jessica Oâ€™Dell, Kevin Butler, and Patrick Traynor, University of Florida https://www.usenix.org/confer & def & Evasion & DL & Audio & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-chen-yufei.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Teacher Model Fingerprinting Attacks   Against Transfer Learning Yufei Chen, Xiâ€™an Jiaotong University \& City University of Hong Kong; Chao Shen,  Xiâ€™an Jiaotong University; Cong W & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-cohen.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & 31st USENIX Security Symposium is  sponsored by USENIX.Attacks on Deidentificationâ€™s Defenses Aloni Cohen, University of Chicago https://www.usenix.org/conference/usenixsecurity22/presentation/cohen & atk & Privacy & Both & Other & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-fu-chong.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Label Inference Attacks   Against Vertical Federated Learning Chong Fu, Zhejiang University; Xuhong Zhang and Shouling Ji,   Binjiang Institute of Zhejiang University; Jinyin Chen, & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-fu-qi.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & Iterative Adversarial Attacks Qi-An Fu, Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center,  THBI Lab, BNRist Center, Tsinghua University, Beijing, China; Yinpeng Dong, De & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-hallyburton.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Security Analysis of Camera-LiDAR Fusion Against  Black-Box Attacks on Autonomous Vehicles R. Spencer Hallyburton and Yupei Liu, Duke University; Yulong Cao and   Z. Morley Mao, Un & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-jain.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access to the Proceedings of the  31st USENIX Security Symposium is  sponsored by USENIX.Adversarial Detection Avoidance Attacks:  Evaluatin & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-li-changjiang.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Seeing is Living? Rethinking the Security of  Facial Liveness Verification in the Deepfake Era Changjiang Li, Pennsylvania State University and Zhejiang University;   Li Wang, Shan & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-li-huiying.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Blacklight: Scalable Defense for Neural Networks  against Query-Based Black-Box Attacks Huiying Li, Shawn Shan, and Emily Wenger, University of Chicago; Jiayun Zhang,   Fudan Unive & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-liu-hongbin.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.PoisonedEncoder: Poisoning the Unlabeled   Pre-training Data in Contrastive Learning Hongbin Liu, Jinyuan Jia, and Neil Zhenqiang Gong, Duke University https://www.usenix.org/confe & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-liu-yugeng.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access to the Proceedings of the  31st USENIX Security Symposium is  sponsored by USENIX.ML-D octor : Holistic Risk Assessment of Inference  & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-nguyen.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & 31st USENIX Security Symposium is  sponsored by USENIX.FLAME: Taming Backdoors in Federated Learning Thien Duc Nguyen and Phillip Rieger, Technical University of Darmstadt;   Huili Chen, University of & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-pan-exploring.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Exploring the Security Boundary of Data  Reconstruction via Neuron Exclusivity Analysis Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, and Min Yang, Fudan University https://www.use & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-pan-hidden.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Hidden Trigger Backdoor Attack on NLP Models   via Linguistic Style Manipulation Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, and Min Yang, Fudan University https://www.usenix.o & atk & Poisoning & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-pang-ren.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & 31st USENIX Security Symposium is  sponsored by USENIX.On the Security Risks of AutoML Ren Pang and Zhaohan Xi, Pennsylvania State University; Shouling Ji,   Zhejiang University; Xiapu Luo, Hong Kong  & atk & Multiple & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-shan.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & Attacks in Neural Networks Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng,   and Ben Y. Zhao, University of Chicago https://www.usenix.org/conference/usenixsecurity22/presentation/shan & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-tang.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Mitigating Membership Inference Attacks by   Self-Distillation Through a Novel Ensemble Architecture Xinyu Tang, Saeed Mahloujifar, and Liwei Song, Princeton University;   Virat Sh & def & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-vaishnavi.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Transferring Adversarial Robustness Through  Robust Representation Matching Pratik Vaishnavi, Stony Brook University; Kevin Eykholt, IBM;   Amir Rahmati, Stony Brook University htt & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-xiang.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.PatchCleanser: Certifiably Robust Defense against  Adversarial Patches for Any Image Classifier Chong Xiang, Saeed Mahloujifar, and Prateek Mittal, Princeton University https://www & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-yan.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & sponsored by USENIX.Rolling Colors: Adversarial Laser Exploits  against Traffic Light Recognition Chen Yan, Zhejiang University; Zhijian Xu, Zhejiang University and   The Chinese University of Hong Ko & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-yuan-xiaoyong.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access to the Proceedings of the  31st USENIX Security Symposium is  sponsored by USENIX.Membership Inference Attacks and   Defenses in Neur & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-zhang-zhikun.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access to the Proceedings of the  31st USENIX Security Symposium is  sponsored by USENIX.Inference Attacks Against Graph Neural Networks Zhi & atk & Privacy & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22-zhou-ce.pdf & This paper is included in the Proceedings of the  31st USENIX Security Symposium. August 10â€“12, 2022 â€¢ Boston, MA, USA 978-1-939133-31-1 Open access t & Estimation based Obstacle Avoidance in  Autonomous Systems Ce Zhou, Qiben Yan, and Yan Shi, Michigan State University;   Lichao Sun, Lehigh University https://www.usenix.org/conference/usenixsecurity2 & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22fall\_mehnaz.pdf & Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classiï¬cation Models Shagufta Mehnaz1, Sayanton V . Dibbo1 & Novel Model Inversion Attribute Inference Attacks on Classiï¬cation Models Shagufta Mehnaz1, Sayanton V . Dibbo1, Ehsanul Kabir1, Ninghui Li2, and Elisa Bertino2 1Department of Computer Science, Dartmo & atk & Privacy & Both & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22summer\_arp.pdf & Dos and Don'ts of Machine Learning in Computer Security Daniel Arp, Erwin Quiringâ€ , Feargus Pendleburyâ€¡ Â§, Alexander Warneckeâ€ , Fabio Pierazziâ€¡, Chri & Technische UniversitÃ¤t Berlin â€ Technische UniversitÃ¤t Braunschweig â€¡Kingâ€™s College London ,kUniversity College London Â§Royal Holloway, University of London and The Alan Turing Institute Â¶KASTEL Secur & def & ~ & Both & Malware & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22summer\_hua.pdf & Increasing Adversarial Uncertainty to Scale Private Similarity Testing Yiqing Hua1;2, Armin Namavari1;2, Kaishuo Cheng2, Mor Naaman1;2, Thomas Ristenp & Increasing Adversarial Uncertainty to Scale Private Similarity Testing Yiqing Hua1;2, Armin Namavari1;2, Kaishuo Cheng2, Mor Naaman1;2, Thomas Ristenpart1;2 1Cornell Tech2Cornell University Abstract S & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2022 & USENIX & sec22summer\_zhang-zhikun.pdf & Inference Attacks Against Graph Neural Networks Zhikun Zhang1Min Chen1*Michael Backes1Yun Shen2Yang Zhang1 1CISPA Helmholtz Center for Information Se & 1CISPA Helmholtz Center for Information Security 2Norton Research Group Abstract Graph is an important data representation ubiquitously ex- isting in the real world. However, analyzing the graph data  & atk & Privacy & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616588.pdf & DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models Zeyang Sha CISPA Helmholtz Center for Information Secur & CISPA Helmholtz Center for Information Security SaarbrÃ¼cken, Germany zeyang.sha@cispa.deZheng Li CISPA Helmholtz Center for Information Security SaarbrÃ¼cken, Germany & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616593.pdf & DPMLBench: Holistic Evaluation of Differentially Private Machine Learning Chengkun Weiâˆ— Zhejiang University Hangzhou, China weichengkun@zju.edu.cnMing & Machine Learning Chengkun Weiâˆ— Zhejiang University Hangzhou, China weichengkun@zju.edu.cnMinghu Zhaoâˆ— & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616617.pdf & Narcissus : A Practical Clean-Label Backdoor Attack with Limited Information Yi Zengâˆ— Virginia Tech Blacksburg, VA, USA yizeng@vt.eduMinzhou Panâˆ— Virg & Virginia Tech Blacksburg, VA, USA yizeng@vt.eduMinzhou Panâˆ— Virginia Tech Blacksburg, VA, USA & atk & Poisoning & DL & Images & YES & YES & NO & Gray-box & Partial & YES & Low & Low & 1 & 0 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616634.pdf & Privacy Leakage via Speech-induced Vibrations on Room Objects through Remote Sensing based on Phased-MIMO Cong Shi Rutgers University cs1421@scarletma & through Remote Sensing based on Phased-MIMO Cong Shi Rutgers University cs1421@scarletmail. rutgers.eduTianfang Zhang & atk & Privacy & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616652.pdf & Stealing the Decoding Algorithms of Language Models Ali Naseh University of Massachusetts Amherst Amherst, Massachusetts, USA anaseh@cs.umass.eduKalpe & Stealing the Decoding Algorithms of Language Models Ali Naseh University of Massachusetts Amherst Amherst, Massachusetts, USA anaseh@cs.umass.eduKalpesh Krishna & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616653.pdf & Stolen Risks of Models with Security Properties Yue Qin Indiana University Bloomington Bloomington, Indiana, USA qinyue@iu.eduZhuoqun Fu Tsinghua Univ & Stolen Risks of Models with Security Properties Yue Qin Indiana University Bloomington Bloomington, Indiana, USA qinyue@iu.eduZhuoqun Fu & both & Multiple & DL & Other & YES & YES & NO & Black-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3616679.pdf & Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models Yiting Qu CISPA Helmholtz Center for Information Secu & Information Security SaarbrÃ¼cken, Germany yiting.qu@cispa.deXinyue Shen CISPA Helmholtz Center for Information Security & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623082.pdf & MDTD: A Multi-Domain Trojan Detector for Deep Neural Networks Arezoo Rajabi University of Washington Seattle, USA rajabia@uw.eduSurudhi Asokraj Univer & Deep Neural Networks Arezoo Rajabi University of Washington Seattle, USA rajabia@uw.eduSurudhi Asokraj & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623093.pdf & Unforgeability in Stochastic Gradient Descent Teodora Balutaâˆ— National University of Singapore Singapore teobaluta@comp.nus.edu.sgIvica NikoliÄ‡âˆ— Natio & Unforgeability in Stochastic Gradient Descent Teodora Balutaâˆ— National University of Singapore Singapore teobaluta@comp.nus.edu.sgIvica NikoliÄ‡âˆ— & def & ~ & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623100.pdf & Verifiable Learning for Robust Tree Ensembles Stefano Calzavara UniversitÃ  Caâ€™ Foscari Venezia stefano.calzavara@unive.itLorenzo Cazzaro UniversitÃ  Ca & Stefano Calzavara UniversitÃ  Caâ€™ Foscari Venezia stefano.calzavara@unive.itLorenzo Cazzaro UniversitÃ  Caâ€™ Foscari Venezia lorenzo.cazzaro@unive.it & def & Evasion & Traditional & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623114.pdf & Turning Privacy-preserving Mechanisms against Federated Learning Marco Arazzi University of Pavia Pavia, Italy marco.arazzi01@universitadipavia.itMaur & Learning Marco Arazzi University of Pavia Pavia, Italy marco.arazzi01@universitadipavia.itMauro Conti & atk & Poisoning & DL & Other & YES & YES & NO & Gray-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623116.pdf & Stateful Defenses for Machine Learning Models Are Not Yet Secure Against Black-box Attacks Ryan Fengâ€  rtfeng@umich.edu University of Michigan Ann Arbo & Secure Against Black-box Attacks Ryan Fengâ€  rtfeng@umich.edu University of Michigan Ann Arbor, Michigan, USAAshish Hoodaâ€  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623117.pdf & Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting Ping He Zhejiang University gnip@zju.edu.cnYifan & Detection under Zero Knowledge Setting Ping He Zhejiang University gnip@zju.edu.cnYifan Xia Zhejiang University & atk & Evasion & DL & Malware & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623120.pdf & Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks Zongjie Li Hong Kong University of Science and Tech & Code Generation APIs via Watermarks Zongjie Li Hong Kong University of Science and Technology Hong Kong, China zligo@cse.ust.hkChaozheng Wang & def & ~ & DL & Other & YES & YES & NO & Gray-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623134.pdf & martFL: Enabling Utility-Driven Data Marketplace with a Robust and Verifiable Federated Learning Architecture Qi Li Tsinghua University \& Zhongguancun & and Verifiable Federated Learning Architecture Qi Li Tsinghua University \& Zhongguancun Laboratory li-q20@mails.tsinghua.edu.cnZhuotao Liuâˆ— Tsinghua University \& Zhongguancun Laboratory & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623173.pdf & Devil in Disguise: Breaching Graph Neural Networks Privacy through Infiltration Lingshuo Meng Zhejiang University emeng@zju.edu.cnYijie Bai Zhejiang U & through Infiltration Lingshuo Meng Zhejiang University emeng@zju.edu.cnYijie Bai Zhejiang University & atk & Privacy & DL & Other & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623175.pdf & Large Language Models for Code: Security Hardening and Adversarial Testing Jingxuan He ETH Zurich, Switzerland jingxuan.he@inf.ethz.chMartin Vechev ET & Jingxuan He ETH Zurich, Switzerland jingxuan.he@inf.ethz.chMartin Vechev ETH Zurich, Switzerland martin.vechev@inf.ethz.ch & def & ~ & DL & Other & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623177.pdf & Attack Some while Protecting Others: Selective Attack Strategies for Attacking and Protecting Multiple Conceptsâˆ— Vibha Belavadi University of Texas at & and Protecting Multiple Conceptsâˆ— Vibha Belavadi University of Texas at Dallas Richardson, Texas, USA VibhaChandramouli.Belavadi@utdallas.edu & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623189.pdf & Evading Watermark based Detection of AI-Generated Content Zhengyuan Jiangâˆ— Duke University zhengyuan.jiang@duke.eduJinghuai Zhangâˆ— Duke University jin & Evading Watermark based Detection of AI-Generated Content Zhengyuan Jiangâˆ— Duke University zhengyuan.jiang@duke.eduJinghuai Zhangâˆ— Duke University & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623199.pdf & A Good Fishman Knows All the Angles: A Critical Evaluation of Googleâ€™s Phishing Page Classifier Changqing Miao School of Information, Renmin Universit & Changqing Miao School of Information, Renmin University of China Beijing, China miaochangqing@ruc.edu.cnJianan Feng & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623209.pdf & AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis Zhiyuan Yu Washington University in St. Louis St. Louis, USA yu.zhiyuan@wus & AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis Zhiyuan Yu & def & Evasion & DL & Audio & YES & NO & YES & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 0 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & ACM & 3576915.3623212.pdf & MESAS: Poisoning Defense for Federated Learning Resilient against Adaptive Attackers Torsten KrauÃŸ University of WÃ¼rzburg WÃ¼rzburg, Germany torsten.kr & against Adaptive Attackers Torsten KrauÃŸ University of WÃ¼rzburg WÃ¼rzburg, Germany torsten.krauss@uni-wuerzburg.deAlexandra Dmitrienko & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 10351028.pdf & Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models Rui Zhuâˆ—, Di Tangâˆ—, Siyua & Effects in Trojaned Machine Learning Models Rui Zhuâˆ—, Di Tangâˆ—, Siyuan Tang, XiaoFeng Wang, Haixu Tang Indiana University Bloomington \{zhu11, tangd, tangsi, xw7, hatang }@iu.edu Abstract â€”The extensiv & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2009.04131v9.pdf & SoK: Certiï¬ed Robustness for Deep Neural Networks Linyi LiTao XieyBo Li University of Illinois Urbana-Champaign, flinyi2,lbog@illinois.edu yKey Lab & Deep Neural Networks Linyi LiTao XieyBo Li University of Illinois Urbana-Champaign, flinyi2,lbog@illinois.edu yKey Laboratory of High Conï¬dence Software Technologies, MoE (Peking University), taoxi & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2112.04558v2.pdf & arXiv:2112.04558v2  [cs.CR]  15 Feb 2023SoK: Anti-Facial Recognition Technology Emily Wenger University of Chicago ewenger@uchicago.eduShawn Shan Univ & arXiv:2112.04558v2  [cs.CR]  15 Feb 2023SoK: Anti-Facial Recognition Technology Emily Wenger University of Chicago ewenger@uchicago.eduShawn Shan University of Chicago & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2201.02775v4.pdf & ADI: Adversarial Dominating Inputs in Vertical Federated Learning Systems Qi Pangâ€ , Yuanyuan Yuanâ€¡, Shuai Wangâ€¡1, Wenting Zhengâ€  â€ Carnegie Mellon Univ & Federated Learning Systems Qi Pangâ€ , Yuanyuan Yuanâ€¡, Shuai Wangâ€¡1, Wenting Zhengâ€  â€ Carnegie Mellon University,â€¡HKUST Abstract â€”Vertical federated learning (VFL) system has re- cently become prominent  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2208.12348v2.pdf & SNAP: Efficient Extraction of Private Properties with Poisoning Harsh Chaudhariâˆ—, John Abascalâˆ—, Alina Opreaâˆ—, Matthew Jagielskiâ€ , Florian TramÃ¨râ€¡, Jo & SNAP: Efficient Extraction of Private Properties with Poisoning Harsh Chaudhariâˆ—, John Abascalâˆ—, Alina Opreaâˆ—, Matthew Jagielskiâ€ , Florian TramÃ¨râ€¡, Jonathan Ullmanâˆ— âˆ—Northeastern University,â€ Google Re & atk & Poisoning & DL & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2210.10936v1.pdf & FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information Xiaoyu Caoâˆ—Jinyuan Jiaâˆ—Zaixi Zhang+Neil Zhenqiang Gon & Federated Learning using Historical Information Xiaoyu Caoâˆ—Jinyuan Jiaâˆ—Zaixi Zhang+Neil Zhenqiang Gongâˆ— âˆ—Duke University+University of Science and Technology of China \{xiaoyu.cao, jinyuan.jia, neil.go & def & Poisoning & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 2302.00539v4.pdf & Analyzing Leakage of Personally Identiï¬able Information in Language Models Nils LukasÂ§, Ahmed Salemy, Robert Simy, Shruti Topley, Lukas Wutschitzyand & Information in Language Models Nils LukasÂ§, Ahmed Salemy, Robert Simy, Shruti Topley, Lukas Wutschitzyand Santiago Zanella-B Â´egueliny University of Waterloo,yMicrosoft nlukas@uwaterloo.ca, ft-salem & atk & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 3DFed\_Adaptive\_and\_Extensible\_Framework\_for\_Covert\_Backdoor\_Attack\_in\_Federated\_Learning.pdf & 3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning Haoyang Li1, Qingqing Y e1, Haibo Hu1* , Jin Li2, Leixia Wan & Covert Backdoor Attack in Federated Learning Haoyang Li1, Qingqing Y e1, Haibo Hu1* , Jin Li2, Leixia Wang3, Chengfang Fang4, Jie Shi4 1The Hong Kong Polytechnic University, hao-yang9905.li@connect.po & atk & Poisoning & DL & Images & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 3d-spoof-sp23.pdf & DepthFake : Spooï¬ng 3D Face Authentication with a 2D Photo Zhihao Wu1, Yushi Cheng2, Jiahui Yang1, Xiaoyu Ji1â€ , Wenyuan Xu1â€  1Ubiquitous System Securi & DepthFake : Spooï¬ng 3D Face Authentication with a 2D Photo Zhihao Wu1, Yushi Cheng2, Jiahui Yang1, Xiaoyu Ji1â€ , Wenyuan Xu1â€  1Ubiquitous System Security Lab (USSLAB), Zhejiang University 2Beijing Nati & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a019.pdf & Deepfake Text Detection: Limitations and Opportunities Jiameng Puâˆ—Â¶, Zain Sarwarâ€ Â¶, Sifat Muhammad Abdullahâˆ—, Abdullah Rehmanâˆ—, Yoonjin Kimâˆ—, Parantap & Jiameng Puâˆ—Â¶, Zain Sarwarâ€ Â¶, Sifat Muhammad Abdullahâˆ—, Abdullah Rehmanâˆ—, Yoonjin Kimâˆ—, Parantapa BhattacharyaÂ§, Mobin Javedâ€¡, Bimal Viswanathâˆ— âˆ—Virginia Tech,â€ University of Chicago,â€¡LUMS Pakistan,Â§Uni & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a076.pdf & Private, Efï¬cient, and Accurate: Protecting Models Trained by Multi-party Learning with Differential Privacy Wenqiang Ruan\$, Mingxin Xu\$, Wenjing Fang & Multi-party Learning with Differential Privacy Wenqiang Ruan\$, Mingxin Xu\$, Wenjing Fang+,L iW a n g+, Lei Wang+, Weili Han\$ \$Laboratory of Data Analytics and Security, Fudan University,+Ant Group \$\{w & def & Privacy & Both & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a327.pdf & SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning Ahmed Salemâˆ—â€¡, Giovanni Cherubinâˆ—, David Evansâ€ , B & Andrew Paverdâˆ—, Anshuman Suriâ€ , Shruti Topleâˆ—, Santiago Zanella-B Â´eguelinâˆ—â€¡ âˆ—Microsoft \{t-salem.ahmed, giovanni.cherubin, boris.koepf, andrew.paverd, shruti.tople, santiago }@microsoft.com â€ Universit & def & Privacy & Both & Other & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a346.pdf & Analyzing Leakage of Personally Identifiable Information in Language Models Nils Lukasâˆ—Â§, Ahmed Salemâ€ , Robert Simâ€ , Shruti Topleâ€ , Lukas Wutschitzâ€ an & Information in Language Models Nils Lukasâˆ—Â§, Ahmed Salemâ€ , Robert Simâ€ , Shruti Topleâ€ , Lukas Wutschitzâ€ and Santiago Zanella-B Â´eguelinâ€  âˆ—University of Waterloo,â€ Microsoft Research nlukas@uwaterloo.ca, & atk & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a432.pdf & D-DAE: Defense-Penetrating Model Extraction Attacks Yanjiao Chen1, Rui Guan2, Xueluan Gong1âˆ—, Jianshuo Dong3, and Meng Xue1 1School of Computer Scienc & Extraction Attacks Yanjiao Chen1, Rui Guan2, Xueluan Gong1âˆ—, Jianshuo Dong3, and Meng Xue1 1School of Computer Science, Wuhan University, China 2School of Mathematics and Statistics, Wuhan University, & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a719.pdf & Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classiï¬ers Limin Yang*, Zhi Chen*, Jacopo Cortellazziyz, Feargus Pendleburyz, Kevin Tu* Fa & Limin Yang*, Zhi Chen*, Jacopo Cortellazziyz, Feargus Pendleburyz, Kevin Tu* Fabio Pierazziy, Lorenzo Cavallaroz, Gang Wang* *University of Illinois at Urbana-ChampaignyKingâ€™s College LondonzUniversit & atk & Poisoning & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a755.pdf & REDEEM MYSELF : Purifying Backdoors in Deep Learning Models using Self Attention Distillation Xueluan Gong1, Yanjiao Chen2âˆ—, Wang Yang3, Qian Wang3âˆ—Yu & Learning Models using Self Attention Distillation Xueluan Gong1, Yanjiao Chen2âˆ—, Wang Yang3, Qian Wang3âˆ—Yuzhe Gu3, Huayang Huang3, and Chao Shen4 1School of Computer Science, Wuhan University, China 2 & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a853.pdf & On The Empirical Effectiveness of Unrealistic Adversarial Hardening Against Realistic Adversarial Attacks 1stSalijona Dyrmishi University of Luxembour & Attacks 1stSalijona Dyrmishi University of Luxembourg salijona.dyrmishi@uni.lu2ndSalah Ghamizi University of Luxembourg & both & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600a906.pdf & TrojanModel: A Practical Trojan Attack against Automatic Speech Recognition Systems Wei Zongâˆ—B, Yang-Wai Chowâˆ—, Willy Susiloâˆ—, Kien Doâ€ and Svetha Venk & Automatic Speech Recognition Systems Wei Zongâˆ—B, Yang-Wai Chowâˆ—, Willy Susiloâˆ—, Kien Doâ€ and Svetha Venkateshâ€  âˆ—Institute of Cybersecurity and Cryptology (iC2), University of Wollongong, Australia \{wzo & atk & Evasion & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600b239.pdf & PublicCheck: Public Integrity Veriï¬cation for Services of Run-time Deep Models Shuo Wangy, Sharif Abuadbbay, Sidharth Agarwalz, Kristen Moorey, Ruo & yCybersecurity CRC, Australia zIndian Institute of Technology Delhi, India xUniversity of New South Wales, Australia Abstract â€”Existing integrity veriï¬cation approaches for deep models are designed fo & def & ~ & DL & Images & YES & NO & NO & White-box & ~ & NO & Low & Low & 0 & 0 & 1 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600b524.pdf & GEESOLVER : A Generic, Efficient, and Effortless Solver with Self-Supervised Learning for Breaking Text Captchas Ruijie Zhaoâ€ Â§, Xianwen Dengâ€ Â§âˆ—, Yanha & Ruijie Zhaoâ€ Â§, Xianwen Dengâ€ Â§âˆ—, Yanhao Wangâ€¡, Zhicong Yanâ€ , Zhengguang Hanâ€ â€ , Libo Chenâ€ , Zhi Xueâ€ âˆ—, and Yijun Wangâ€ âˆ— â€ Shanghai Jiao Tong Universityâ€¡QI-ANXINâ€ â€ QI-AN Pangu (Shanghai) InfoTech Co., Ltd. & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600b901.pdf & Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective Shahbaz Rezaei University of California Davis, CA, USA srezaei@ucdavis & A Membership Inference Perspective Shahbaz Rezaei University of California Davis, CA, USA srezaei@ucdavis.eduZubair Shafiq & both & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & 933600b935.pdf & SNAP: Efficient Extraction of Private Properties with Poisoning Harsh Chaudhariâˆ—, John Abascalâˆ—, Alina Opreaâˆ—, Matthew Jagielskiâ€ , Florian TramÃ¨râ€¡, Jo & SNAP: Efficient Extraction of Private Properties with Poisoning Harsh Chaudhariâˆ—, John Abascalâˆ—, Alina Opreaâˆ—, Matthew Jagielskiâ€ , Florian TramÃ¨râ€¡, Jonathan Ullmanâˆ— âˆ—Northeastern University,â€ Google Re & atk & Poisoning & DL & Other & YES & NO & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & AI-Guardian\_Defeating\_Adversarial\_Attacks\_using\_Backdoors.pdf & AI-Guardian: Defeating Adversarial Attacks using Backdoors Hong Zhu1,2, Shengzhi Zhang3, and Kai Chen1,2,âˆ— 1SKLOIS, Institute of Information Engineeri & Hong Zhu1,2, Shengzhi Zhang3, and Kai Chen1,2,âˆ— 1SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China 2School of Cyber Security, University of Chinese Academy of Sciences,  & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & BayBFed\_Bayesian\_Backdoor\_Defense\_for\_Federated\_Learning.pdf & BayBFed : Bayesian Backdoor Defense for Federated Learning Kavita Kumariâ€ âˆ—, Phillip Riegerâ€ , Hossein Fereidooniâ€ , Murtuza Jadliwalaâ€¡and Ahmad-Reza Sad & BayBFed : Bayesian Backdoor Defense for Federated Learning Kavita Kumariâ€ âˆ—, Phillip Riegerâ€ , Hossein Fereidooniâ€ , Murtuza Jadliwalaâ€¡and Ahmad-Reza Sadeghiâ€  â€ Technical University of Darmstadt,â€¡The Univ & def & Poisoning & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & Breaking\_Security-Critical\_Voice\_Authentication.pdf & Breaking Security-Critical V oice Authentication Andre Kassisâˆ—and Urs Hengartnerâ€  Cheriton School of Computer Science University of Waterloo Waterloo, & Andre Kassisâˆ—and Urs Hengartnerâ€  Cheriton School of Computer Science University of Waterloo Waterloo, Canada âˆ—akassis@uwaterloo.ca,â€ urs.hengartner@uwaterloo.ca & atk & Evasion & DL & Audio & YES & YES & NO & Black-box & Full & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & Disguising\_Attacks\_with\_Explanation-Aware\_Backdoors.pdf & Disguising Attacks with Explanation-Aware Backdoors Maximilian Noppel KASTEL Security Research Labs Karlsruhe Institute of Technology GermanyLukas Pet & KASTEL Security Research Labs Karlsruhe Institute of Technology GermanyLukas Peter KASTEL Security Research Labs Karlsruhe Institute of Technology GermanyChristian Wressnegger & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & ELSA\_Secure\_Aggregation\_for\_Federated\_Learning\_with\_Malicious\_Actors.pdf & ELSA: Secure Aggregation for Federated Learning with Malicious Actors Mayank Rathee1, Conghao Shen1,2, Sameer Wagh1,3, and Raluca Ada Popa1 University & ELSA: Secure Aggregation for Federated Learning with Malicious Actors Mayank Rathee1, Conghao Shen1,2, Sameer Wagh1,3, and Raluca Ada Popa1 University of California, Berkeley1 Stanford University2 Dev & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & ImU\_Physical\_Impersonating\_Attack\_for\_Face\_Recognition\_System\_with\_Natural\_Style\_Changes.pdf & ImU: Physical Impersonating Attack for Face Recognition System with Natural Style Changes Shengwei Anâ€ , Y uan Yaoâ€¡, Qiuling Xuâ€ , Shiqing MaÂ§, Guanhong & Shengwei Anâ€ , Y uan Yaoâ€¡, Qiuling Xuâ€ , Shiqing MaÂ§, Guanhong Taoâ€ , Siyuan Chengâ€ , Kaiyuan Zhangâ€ , Yingqi Liuâ€ , Guangyu Shenâ€ , Ian KelkÂ¶, Xiangyu Zhangâ€  â€ Purdue University,â€¡Nanjing University,Â§Rutgers  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & ObjectSeeker\_Certifiably\_Robust\_Object\_Detection\_against\_Patch\_Hiding\_Attacks\_via\_Patch-agnostic\_Masking.pdf & ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding Attacks via Patch-agnostic Masking Chong Xiang Princeton University cxiang@prin & Patch-agnostic Masking Chong Xiang Princeton University cxiang@princeton.eduAlexander Valtchanov Princeton University & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & On\_the\_Insecurity\_of\_Peer-to-Peer\_Decentralized\_Machine\_Learning.pdf & On the (In)security of Peer-to-Peer Decentralized Machine Learning Dario Pasquini SPRING Lab; EPFL, Switzerland dario.pasquini@epï¬‚.chMathilde Raynal S & Dario Pasquini SPRING Lab; EPFL, Switzerland dario.pasquini@epï¬‚.chMathilde Raynal SPRING Lab; EPFL, Switzerland mathilde.raynal@epï¬‚.chCarmela Troncoso & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & RAB\_Provable\_Robustness\_Against\_Backdoor\_Attacks.pdf & RAB: Provable Robustness Against Backdoor Attacks Maurice Weberâ€  âˆ—Xiaojun Xuâ€¡ âˆ—Bojan Karla Ë‡sâ€ Ce Zhangâ€ Bo Liâ€¡ â€ ETH Zurich, Switzerland \{maurice.weber, & RAB: Provable Robustness Against Backdoor Attacks Maurice Weberâ€  âˆ—Xiaojun Xuâ€¡ âˆ—Bojan Karla Ë‡sâ€ Ce Zhangâ€ Bo Liâ€¡ â€ ETH Zurich, Switzerland \{maurice.weber, karlasb, ce.zhang }@inf.ethz.ch â€¡University of Il & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & RoFL\_Robustness\_of\_Secure\_Federated\_Learning.pdf & RoFL: Robustness of Secure Federated Learning Hidde Lycklamaâˆ—, Lukas Burkhalterâˆ—, Alexander Viand, Nicolas K Â¨uchler, Anwar Hithnawi ETH Zurich Abstra & ETH Zurich Abstract â€”Even though recent years have seen many attacks exposing severe vulnerabilities in Federated Learning (FL), a holistic understanding of what enables these attacks and how they can & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & Spectral-DP\_Differentially\_Private\_Deep\_Learning\_through\_Spectral\_Perturbation\_and\_Filtering.pdf & Spectral-DP: D ifferentially P rivate Deep Learning through Spectral Perturbation and Filtering Ce Fengâˆ—1, Nuo Xuâˆ—1, Wujie Wen1, Parv V enkitasubraman & and Filtering Ce Fengâˆ—1, Nuo Xuâˆ—1, Wujie Wen1, Parv V enkitasubramaniam1, Caiwen Ding2 1Lehigh University,2University of Connecticut \{cef419, nux219, wuw219, pav309 }@lehigh.edu, caiwen.ding@uconn.edu & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & Spoofing\_Real-world\_Face\_Authentication\_Systems\_through\_Optical\_Synthesis.pdf & Spoofing Real-world Face Authentication Systems through Optical Synthesis Yueli Yan, Zhice Yang School of Information Science and Technology, Shanghai & through Optical Synthesis Yueli Yan, Zhice Yang School of Information Science and Technology, ShanghaiTech University, China Abstract â€”Facial information has been used for authentication purposes. Rec & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & IEEE & StyleFool\_Fooling\_Video\_Classification\_Systems\_via\_Style\_Transfer.pdf & StyleFool: Fooling Video Classiï¬cation Systems via Style Transfer Yuxin Cao, Xi Xiao, Ruoxi Suny, Derui Wangy, Minhui Xueyand Sheng Wenz Shenzhen I & StyleFool: Fooling Video Classiï¬cation Systems via Style Transfer Yuxin Cao, Xi Xiao, Ruoxi Suny, Derui Wangy, Minhui Xueyand Sheng Wenz Shenzhen International Graduate School, Tsinghua University, & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f103\_paper.pdf & OBS AN: An Out-Of-Bound Sanitizer to Harden DNN Executables Yanzuo Chen, Yuanyuan Yuan, Shuai Wang The Hong Kong University of Science and Technolog & DNN Executables Yanzuo Chen, Yuanyuan Yuan, Shuai Wang The Hong Kong University of Science and Technology fychenjo,yyuanaq,shuaiw g@cse.ust.hk Abstract â€”The rapid adoption of deep neural network (DN & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f243\_paper.pdf & Attacks as Defenses: Designing Robust Audio CAPTCHAs Using Attacks on Automatic Speech Recognition Systems Hadi Abdullah1âˆ—, Aditya Karleka2, Saurabh P & Hadi Abdullah1âˆ—, Aditya Karleka2, Saurabh Prasad2, Muhammad Sajidur Rahman2, Logan Blue2, Luke A. Bauer2, Vincent Bindschaedler2, Patrick Traynor2 Visa Research, Atlanta, GA1University of Florida, Gai & def & Evasion & DL & Audio & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f287\_paper.pdf & Backdoor Attacks Against Dataset Distillation Yugeng Liu,â€ Zheng Li,â€ Michael Backes,â€ Yun Shen,Â§and Yang Zhangâ€  â€ CISPA Helmholtz Center for Information  & Yugeng Liu,â€ Zheng Li,â€ Michael Backes,â€ Yun Shen,Â§and Yang Zhangâ€  â€ CISPA Helmholtz Center for Information SecurityÂ§NetApp \{yugeng.liu, zheng.li, director, zhang }@cispa.de, yun.shen@netapp.com Abstract  & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f394\_paper.pdf & Him of Many Faces: Characterizing Billion-scale Adversarial and Benign Browser Fingerprints on Commercial Websites Shujiang Wu, Pengfei Suny, Yao Zhao & Commercial Websites Shujiang Wu, Pengfei Suny, Yao Zhaoy, and Yinzhi Cao Johns Hopkins University,yF5, Inc. fswu68, yinzhi.caog@jhu.edu, fp.sun, y.zhaog@f5.com especially given that it is a weak means & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f444\_paper.pdf & REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service Wenjie Qu1, Jinyuan Jia2, Neil Zhenqiang Gong3 1Huazhong U & Classifiers via Robust Encoder as a Service Wenjie Qu1, Jinyuan Jia2, Neil Zhenqiang Gong3 1Huazhong University of Science and Technology, wen jiequ@outlook.com 2University of Illinois Urbana-Champaig & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f508\_paper.pdf & BARS: Local Robustness Certification for Deep Learning based Traffic Analysis Systems Kai Wangâˆ—â€ , Zhiliang Wangâˆ—â€ â€¡, Dongqi Hanâˆ—â€ , Wenqi Chenâˆ—â€ , Jiahai & Learning based Traffic Analysis Systems Kai Wangâˆ—â€ , Zhiliang Wangâˆ—â€ â€¡, Dongqi Hanâˆ—â€ , Wenqi Chenâˆ—â€ , Jiahai Yangâˆ—â€ â€¡, Xingang Shiâˆ—â€ , Xia Yinâ€ Â§ âˆ—Institute for Network Sciences and Cyberspace, BNRist, Tsing & def & Evasion & DL & Other & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f874\_paper.pdf & Focusing on Pinocchioâ€™s Nose: A Gradients Scrutinizer to Thwart Split-Learning Hijacking Attacks Using Intrinsic Attributes Jiayun Fuâˆ—, Xiaojing Ma1âˆ—, & Jiayun Fuâˆ—, Xiaojing Ma1âˆ—, Bin B. Zhuâ€ , Pingyi Huâˆ—, Ruixin Zhaoâˆ—, Yaru Jiaâˆ—, Peng Xuâˆ—, Hai Jinâˆ—, and Dongmei Zhangâ€  âˆ—Huazhong University of Science and Technology, Wuhan, China â€ Microsoft Research Asi & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f924\_paper.pdf & Adversarial Robustness for Tabular Data through Cost and Utility Awareness Klim Kireev,yBogdan Kulynych,yCarmela Troncoso EPFL SPRING Lab value of a p & Klim Kireev,yBogdan Kulynych,yCarmela Troncoso EPFL SPRING Lab value of a personâ€™s salary, another to their age, and another to a categorical value representing their marital status. The properties of & atk & Evasion & DL & Other & YES & NO & NO & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_f944\_paper.pdf & BEAGLE : Forensics of Deep Learning Backdoor Attack for Better Defense Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng,  & Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma:, Xiangyu Zhang Purdue University,:Rutgers University \{cheng535, taog & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s112\_paper.pdf & Securing Federated Sensitive Topic Classification against Poisoning Attacks Tianyue Chu IMDEA Networks Institute Universidad Carlos III de MadridAlvar & Universidad Carlos III de MadridAlvaro Garcia-Recuero IMDEA Networks InstituteCostas Iordanou Cyprus University of Technology Georgios Smaragdakis TU DelftNikolaos Laoutaris & def & Poisoning & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s165\_paper.pdf & RoVISQ: Reduction of Video Service Quality via Adversarial Attacks on Deep Learning-based Video Compression Jung-Woo Changâˆ—Mojan Javaheripiâˆ—Seira Hida & Deep Learning-based Video Compression Jung-Woo Changâˆ—Mojan Javaheripiâˆ—Seira Hidanoâ€ Farinaz Koushanfarâˆ— âˆ—University of California San Diegoâ€ KDDI Research, Inc. \{juc023, mojan, farinaz }@ucsd.edu, se-hi & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s171\_paper.pdf & PPA: Preference Profiling Attack Against Federated Learning Chunyi Zhouâ€ Â§âˆ—, Yansong Gaoâ€ âˆ—, Anmin Fuâ€ Â§â€¡, Kai ChenÂ§, Zhiyang Daiâ€ , Zhi ZhangÂ¶, Minhui Xu & Chunyi Zhouâ€ Â§âˆ—, Yansong Gaoâ€ âˆ—, Anmin Fuâ€ Â§â€¡, Kai ChenÂ§, Zhiyang Daiâ€ , Zhi ZhangÂ¶, Minhui XueÂ¶, and Yuqing Zhangâˆ¥ â€ School of Computer Science and Engineering, Nanjing University of Science and Technolog & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s69\_paper.pdf & The â€œBeatrixâ€ Resurrections: Robust Backdoor Detection via Gram Matrices Wanlun May, Derui Wangz, Ruoxi Sunz, Minhui Xuez, Sheng Weny, and Yang Xiangy & Robust Backdoor Detection via Gram Matrices Wanlun May, Derui Wangz, Ruoxi Sunz, Minhui Xuez, Sheng Weny, and Yang Xiangy ySwinburne University of Technology, Australia zCSIROâ€™s Data61, Australia BadN & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s70\_paper.pdf & Evasion Attacks and Defenses on Smart Home Physical Event Veriï¬cation Muslum Ozgur Ozmen, Ruoyu Song, Habiba Farrukh, and Z. Berkay Celik Purdue Unive & Physical Event Veriï¬cation Muslum Ozgur Ozmen, Ruoyu Song, Habiba Farrukh, and Z. Berkay Celik Purdue University \{mozmen, song464, hfarrukh, zcelik}@purdue.edu Abstract â€”In smart homes, when an actuat & def & Evasion & Both & Other & YES & YES & YES & Gray-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & NDS & ndss2023\_s87\_paper.pdf & Machine Unlearning of Features and Labels Alexander Warneckeâˆ—, Lukas Pirchâˆ—, Christian Wressneggerâ€ and Konrad Rieckâˆ— âˆ—Technische Universit Â¨at Braunsc & âˆ—Technische Universit Â¨at Braunschweig â€ KASTEL Security Research Labs, Karlsruhe Institute of Technology (KIT) Abstract â€”Removing information from a machine learning model is a non-trivial task that r & def & Privacy & Both & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & 2302.09491v1.pdf & XX-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection Aishan Liu1*, Jun Guo1*, Jiakai Wang2, Siyuan Liang3, Renshuai Tao & Aishan Liu1*, Jun Guo1*, Jiakai Wang2, Siyuan Liang3, Renshuai Tao1, Wenbo Zhou4, Cong Liu5, Xianglong Liu1;2;6â€ , Dacheng Tao7 1Beihang University,2Zhongguancun Laboratory,3Chinese Academy of Sciences & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23\_slides\_eykholt.pdf & URET: Universal Robustness Evaluation Toolkit (for Evasion)Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy and Masha Zorin & ~ & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-2-li-heng.pdf & Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information Heng Liâ€ , Zhang Chengâ€¡,â€ , Bang W & Detection under Incomplete Feature Information Heng Liâ€ , Zhang Chengâ€¡,â€ , Bang Wuâ€ , Liheng Y uanâ€ , Cuiying Gaoâ€ , Wei Y uanâ€ âˆ—, Xiapu Luoâ‹† â€ Huazhong University of Science and Technology â‹†The Hong Kong Po & atk & Evasion & DL & Malware & YES & NO & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-28-zhang-boyang.pdf & A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots Boyang Zhang1Xinlei He1Yun Shen2Tianhao Wang3Yang Zhang1 1CI & Scientific Plots Boyang Zhang1Xinlei He1Yun Shen2Tianhao Wang3Yang Zhang1 1CISPA Helmholtz Center for Information Security2NetApp3University of Virginia Abstract Building advanced machine learning (ML & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-34-liu-aishan.pdf & XX-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection Aishan Liu1*, Jun Guo1*, Jiakai Wang2, Siyuan Liang3, Renshuai Tao & Aishan Liu1*, Jun Guo1*, Jiakai Wang2, Siyuan Liang3, Renshuai Tao1, Wenbo Zhou4, Cong Liu5, Xianglong Liu1;2;6â€ , Dacheng Tao7 1Beihang University,2Zhongguancun Laboratory,3Chinese Academy of Sciences & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-353-sandoval.pdf & Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants Gustavo Sandovalâˆ—, Hammond Pearceâˆ—, Teo Nys, Ramesh Karri & of Large Language Model Code Assistants Gustavo Sandovalâˆ—, Hammond Pearceâˆ—, Teo Nys, Ramesh Karri, Siddharth Garg, Brendan Dolan-Gavitt New York University Abstract Large Language Models (LLMs) such a & def & ~ & DL & Other & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-421-li-xiaoguang.pdf & Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation Xiaoguang Li1,2âˆ—Ninghui Li2Wenhai Sun2Neil Zhen & for Mean and Variance Estimation Xiaoguang Li1,2âˆ—Ninghui Li2Wenhai Sun2Neil Zhenqiang Gong3Hui Li1 1Xidian University,2Purdue University,3Duke University Abstract Although local differential privacy ( & atk & Poisoning & Both & Other & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-427-yang-yuchen.pdf & PRIVATE FL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation Yuchen Yangâˆ—, Bo Huiâˆ—, Haolin Yuanâˆ—, Neil Gongâ€ ,  & via Personalized Data Transformation Yuchen Yangâˆ—, Bo Huiâˆ—, Haolin Yuanâˆ—, Neil Gongâ€ , and Yinzhi Cao The Johns Hopkins University,â€ Duke University Abstract Federated learning (FL) enables multiple cli & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23fall-prepub-85-fu-chong.pdf & FREE EAGLE : Detecting Complex Neural Trojans in Data-Free Cases Chong Fu1, Xuhong Zhang1, Shouling Ji1, Ting Wang2, Peng Lin3, Y anghe Feng4, and Jia & FREE EAGLE : Detecting Complex Neural Trojans in Data-Free Cases Chong Fu1, Xuhong Zhang1, Shouling Ji1, Ting Wang2, Peng Lin3, Y anghe Feng4, and Jianwei Yin1 1Zhejiang University ,2Pennsylvania Stat & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_136-li\_zheng-prepub.pdf & UnGANable: Defending Against GAN-based Face Manipulation Zheng Li1Ning Yu2Ahmed Salem3Michael Backes1Mario Fritz1Yang Zhang1 1CISPA Helmholtz Center f & 1CISPA Helmholtz Center for Information Security 2Salesforce Research3Microsoft Research Abstract Deepfakes pose severe threats of visual misinformation to our society. One representative deepfake app & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_146-prokos-prepub.pdf & Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning Jonathan Prokos1, Neil Fendley2, Matthew Green1, Roei Schuster3, E & Jonathan Prokos1, Neil Fendley2, Matthew Green1, Roei Schuster3, Eran Tromer4, Tushar M. Jois1, and Yinzhi Cao1 1Johns Hopkins University, jprokos4@gmail.com, \{jois, mgreen, yzcao}@cs.jhu.edu 2Johns  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_349-cao-prepub.pdf & You Canâ€™t See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks Yulong Cao University of MichiganS. Hrushikesh Bhupat & Vehicles Driving Frameworks Yulong Cao University of MichiganS. Hrushikesh Bhupathiraju University of FloridaPirouz Naghavi University of Florida & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_372-yue-prepub.pdf & Gradient Obfuscation Gives a False Sense of Security in Federated Learning Kai Yue,1Richeng Jin,2Chau-Wai Wong,1Dror Baron,1and Huaiyu Dai1 1North Car & Gradient Obfuscation Gives a False Sense of Security in Federated Learning Kai Yue,1Richeng Jin,2Chau-Wai Wong,1Dror Baron,1and Huaiyu Dai1 1North Carolina State University; \{kyue, chauwai.wong, dzbar & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_388-rosenberg-prepub (1).pdf & Fairness Properties of Face Recognition and Obfuscation Systems Harrison Rosenberg University of Wisconsinâ€“MadisonBrian Tang University of MichiganKas & Fairness Properties of Face Recognition and Obfuscation Systems Harrison Rosenberg University of Wisconsinâ€“MadisonBrian Tang University of MichiganKassem Fawaz University of Wisconsinâ€“Madison & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_388-rosenberg-prepub.pdf & Fairness Properties of Face Recognition and Obfuscation Systems Harrison Rosenberg University of Wisconsinâ€“MadisonBrian Tang University of MichiganKas & Fairness Properties of Face Recognition and Obfuscation Systems Harrison Rosenberg University of Wisconsinâ€“MadisonBrian Tang University of MichiganKassem Fawaz University of Wisconsinâ€“Madison & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & sec23summer\_406-liu\_zhibo-prepub.pdf & Decompiling x86 Deep Neural Network Executables Zhibo Liu, Yuanyuan Yuan, Shuai Wangâˆ— The Hong Kong University of Science and Technology \{zliudc,yyuan & Decompiling x86 Deep Neural Network Executables Zhibo Liu, Yuanyuan Yuan, Shuai Wangâˆ— The Hong Kong University of Science and Technology \{zliudc,yyuanaq,shuaiw}@cse.ust.hkXiaofei Xie Singapore Managem & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-ahmed-shimaa.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Tubes Among Us: Analog Attack on  Automatic Speaker Identification Shimaa Ahmed and Yash Wani, University of Wisconsin-Madison;   Ali Shahin Shamsabadi, Alan Turing Institute; M & atk & Evasion & DL & Audio & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-aonzo.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access to the Proceedings of the  32nd USENIX Security Symposium  is sponsored by USENIX.Humans vs. Machines in Malware Classification Simon & def & ~ & Both & Malware & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-bai.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Villain : Backdoor Attacks Against  Vertical Split Learning Yijie Bai and Yanjiao Chen, Zhejiang University; Hanlei Zhang and Wenyuan Xu,  Zhejing University; Haiqin Weng and Do & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-bethany.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Mazal Bethany, Andrew Seong, Samuel Henrique Silva,   Nicole Beebe, Nishant Vishwamitra, and Peyman Najafirad,   The University of Texas at San Antonio https://www.usenix.org/conference/usenixsecurity & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-carlini.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Extracting Training Data from Diffusion Models Nicholas Carlini, Google; Jamie Hayes, DeepMind; Milad Nasr and   Matthew Jagielski, Google; Vikash Sehwag, Princeton University;  & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-chen-guangke.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.QFA2SR: Query-Free Adversarial Transfer Attacks  to Speaker Recognition Systems Guangke Chen, Yedi Zhang, and Zhe Zhao, ShanghaiTech University; Fu Song,  ShanghaiTech Universit & atk & Evasion & DL & Audio & YES & YES & NO & Black-box & Full & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-chen-min.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Facial Recognition Systems Min Chen, CISPA Helmholtz Center for Information Security; Zhikun Zhang,   CISPA Helmholtz Center for Information Security and Stanford University;   Tianhao Wang, Universit & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-chen-yizheng.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access to the Proceedings of the  32nd USENIX Security Symposium  is sponsored by USENIX.Continuous Learning for Android Malware Detection Y & def & ~ & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-christou.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.IvySyn: Automated Vulnerability Discovery   in Deep Learning Frameworks Neophytos Christou, Di Jin, and Vaggelis Atlidakis, Brown University;   Baishakhi Ray, Columbia Universit & def & ~ & DL & Other & YES & YES & YES & White-box & Full & NO & High & Low & 0 & 1 & 1 & 0 & 0 & 0 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-deng-zizhuang.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Zizhuang Deng, Guozhu Meng, Kai Chen, Tong Liu, and Lu Xiang, SKLOIS,   Institute of Information Engineering, Chinese Academy of Sciences, China;   School of Cyber Security, University of Chinese Acad & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-eisenhofer.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.No more Reviewer \#2: Subverting Automatic   Paper-Reviewer Assignment using Adversarial Learning Thorsten Eisenhofer, Ruhr University Bochum; Erwin Quiring, Ruhr University Boch & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-eykholt.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Evaluation Toolkit (for Evasion) Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, and  Ian Molloy, IBM Research; Masha Zorin, University of Cambridge https://www.usenix.org/conference/usenixs & atk & Evasion & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-gao.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.PCAT: Functionality and Data Stealing   from Split Learning by Pseudo-Client Attack Xinben Gao and Lan Zhang, University of Science and Technology of China https://www.usenix.or & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-jia.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.PORE: Provably Robust Recommender Systems  against Data Poisoning Attacks Jinyuan Jia, The Pennsylvania State University;   Yupei Liu, Yuepeng Hu, and Neil Zhenqiang Gong, Duke  & def & Poisoning & Both & Other & YES & YES & NO & White-box & Full & NO & High & Low & 0 & 1 & 1 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-li-heng.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & FCG Based Android Malware Detection under  Incomplete Feature Information Heng Li, Huazhong University of Science and Technology; Zhang Cheng, NSFOCUS  Technologies Group Co., Ltd. and Huazhong Univer & atk & Evasion & DL & Malware & YES & NO & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-li-xinfeng.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Learning Normality is Enough: A Software-based  Mitigation against Inaudible Voice Attacks Xinfeng Li, Xiaoyu Ji, and Chen Yan, USSLAB, Zhejiang University; Chaohao Li,  USSLAB, & def & Evasion & DL & Audio & YES & NO & NO & Gray-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-liu-qi.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.NeuroPots : Realtime Proactive Defense against  Bit-Flip Attacks in Neural Networks Qi Liu, Lehigh University; Jieming Yin, Nanjing University of Posts and  Telecommunications;  & def & ~ & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-lucas.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Adversarial Training for Raw-Binary   Malware Classifiers Keane Lucas, Samruddhi Pai, Weiran Lin, and Lujo Bauer, Carnegie Mellon University;   Michael K. Reiter, Duke Universit & def & Evasion & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-lukas.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.PTW: Pivotal Tuning Watermarking   for Pre-Trained Image Generators Nils Lukas and Florian Kerschbaum, University of Waterloo https://www.usenix.org/conference/usenixsecurity23/ & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-lv.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Peizhuo Lv, Chang Yue, Ruigang Liang, and Yunfei Yang, SKLOIS, Institute of  Information Engineering, Chinese Academy of Sciences, China; School of   Cyber Security, University of Chinese Academy of S & atk & Poisoning & DL & Images & YES & YES & NO & White-box & ~ & YES & High & High & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-man.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Misclassification Attack Detection for Autonomous  Systems Using Spatiotemporal Consistency Yanmao Man, University of Arizona; Raymond Muller, Purdue University;   Ming Li, University of Arizona; Z. B & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-mink.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & A Qualitative Root Cause Analysis of Barriers to  Adversarial Machine Learning Defenses in Industry Jaron Mink, University of Illinois at Urbana-Champaign; Harjot Kaur,   Leibniz University Hannover;  & def & Multiple & Both & Other & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-mozaffari.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Federated Learning to Resist Poisoning Attacks Hamid Mozaffari, Virat Shejwalkar, and Amir Houmansadr,   University of Massachusetts Amherst https://www.usenix.org/conference/usenixsecurity23/presenta & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-mukherjee.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Kunal Mukherjee, Joshua Wiedemeier, Tianhao Wang, James Wei,  Feng Chen, Muhyun Kim, Murat Kantarcioglu, and Kangkook Jee,  The University of Texas at Dallas https://www.usenix.org/conference/usenixse & atk & Evasion & DL & Malware & YES & YES & NO & Black-box & Partial & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-pan.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & a Multiplicity of Deep Learning Paradigms Minzhou Pan and Yi Zeng, Virginia Tech; Lingjuan Lyu, Sony AI;   Xue Lin, Northeastern University; Ruoxi Jia, Virginia Tech https://www.usenix.org/conference/ & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-prokos.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Squint Hard Enough: Attacking Perceptual Hashing  with Adversarial Machine Learning Jonathan Prokos, Johns Hopkins University; Neil Fendley, Johns Hopkins University  Applied Ph & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-qi.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & for Detecting Backdoor Poison Samples Xiangyu Qi, Tinghao Xie, Jiachen T. Wang, Tong Wu, Saeed Mahloujifar,  and Prateek Mittal, Princeton University https://www.usenix.org/conference/usenixsecurity23 & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-rathee.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & 32nd USENIX Security Symposium  is sponsored by USENIX.Secure Floating-Point Training Deevashwer Rathee, University of California, Berkeley; Anwesh Bhattacharya,  Divya Gupta, and Rahul Sharma, Micros & def & ~ & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-shan.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & by Text-to-Image Models Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng,  Rana Hanocka, and Ben Y. Zhao, University of Chicago https://www.usenix.org/conference/usenixsecurity23/presentation/shan & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-sheatsley (1).pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.The Space of Adversarial Strategies Ryan Sheatsley, Blaine Hoak, Eric Pauley, and Patrick McDaniel,   University of Wisconsin-Madison https://www.usenix.org/conference/usenixsec & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-sheatsley.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.The Space of Adversarial Strategies Ryan Sheatsley, Blaine Hoak, Eric Pauley, and Patrick McDaniel,   University of Wisconsin-Madison https://www.usenix.org/conference/usenixsec & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-si.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access to the Proceedings of the  32nd USENIX Security Symposium  is sponsored by USENIX.Two-in-One: A Model Hijacking Attack  Against Text  & atk & Poisoning & DL & Text & YES & NO & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-tao.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Universal Adversarial Patch Attack Guanhong Tao, Shengwei An, Siyuan Cheng, Guangyu Shen,   and Xiangyu Zhang, Purdue University https://www.usenix.org/conference/usenixsecurity23/presentation/tao & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-tian.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Jianwen Tian, NKLSTISS, Institute of Systems Engineering, Academy of Military  Sciences, China; Kefan Qiu, School of Cyberspace Science and Technology, Beijing  Institute of Technology; Debin Gao, Sin & atk & Poisoning & DL & Malware & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-wang-junzhe.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Be Used for Others? Retargeted-Architecture   Binary Code Analysis Junzhe Wang, George Mason University; Matthew Sharp, University of South Carolina;   Chuxiong Wu, Qiang Zeng, and Lannan Luo, George  & def & ~ & DL & Malware & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-wei-chengan.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Aliasing Backdoor Attacks on Pre-trained Models Chengâ€™an Wei, SKLOIS, Institute of Information Engineering, Chinese Academy  of Sciences, China; School of Cyber Security, Univer & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-wu-xinghui.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.KenKu: Towards Efficient and Stealthy Black-box  Adversarial Attacks against ASR Systems Xinghui Wu, Xiâ€™an Jiaotong University; Shiqing Ma, University of Massachusetts  Amherst; & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-xu-xiaojun.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.How to Cover up Anomalous Accesses  to Electronic Health Records Xiaojun Xu, Qingying Hao, Zhuolin Yang, and Bo Li, University of Illinois at  Urbana-Champaign; David Liebovitz, & atk & Evasion & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-yan.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Rethinking White-Box Watermarks on Deep Learning  Models under Neural Structural Obfuscation Yifan Yan, Xudong Pan, Mi Zhang, and Min Yang, Fudan University https://www.usenix.o & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-yu-jiahao.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.AIRS: Explanation for Deep Reinforcement   Learning based Security Applications Jiahao Yu, Northwestern University; Wenbo Guo, Purdue University; Qi Qin,  ShanghaiTech Universit & def & Evasion & DL & Malware & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-yu-zhiyuan-smack.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.SMACK: Semantically Meaningful   Adversarial Audio Attack Zhiyuan Yu, Yuanhaur Chang, and Ning Zhang, Washington University in St. Louis;   Chaowei Xiao, Arizona State Universit & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 0 & 0 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-yuan-yuanyuan-certification.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.Precise and Generalized Robustness   Certification for Neural Networks Yuanyuan Yuan, The Hong Kong University of Science and Technology   and ETH Zurich;  Shuai Wang, The Hong  & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zeng.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access to the Proceedings of the  32nd USENIX Security Symposium  is sponsored by USENIX.Meta-Sift: How to Sift Out a Clean Subset  in the P & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zhang-jiawei.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.DiffSmooth: Certifiably Robust Learning   via Diffusion Models and Local Smoothing Jiawei Zhang, UIUC; Zhongzhu Chen, University of Michigan, Ann Arbor;  Huan Zhang, Carnegie Me & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zhang-shibo.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & is sponsored by USENIX.CAPatch: Physical Adversarial Patch   against Image Captioning Systems Shibo Zhang, USSLAB, Zhejiang University; Yushi Cheng, BNRist, Tsinghua University;   Wenjun Zhu, Xiaoyu J & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zhang-zhuo-pelican (1).pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Deep Learning Models In Binary Code Analysis Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu,   and Yapeng Ye, Purdue University; Yaoxuan Wu, University of California, Los  & atk & Evasion & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zhang-zhuo-pelican.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & Deep Learning Models In Binary Code Analysis Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu,   and Yapeng Ye, Purdue University; Yaoxuan Wu, University of California, Los  & atk & Evasion & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2023 & USENIX & usenixsecurity23-zhu.pdf & This paper is included in the Proceedings of the  32nd USENIX Security Symposium. August 9â€“11, 2023 â€¢ Anaheim, CA, USA 978-1-939133-37-3 Open access t & 32nd USENIX Security Symposium  is sponsored by USENIX.TPatch: A Triggered Physical Adversarial Patch Wenjun Zhu and Xiaoyu Ji, USSLAB, Zhejiang University; Yushi Cheng, BNRist,  Tsinghua University;  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 2309.03466v2.pdf & Neural Dehydration : Effective Erasure of Black-box Watermarks from DNNs with Limited Data Yifan Lu Fudan University Shanghai, China luyf23@m.fudan.ed & from DNNs with Limited Data Yifan Lu Fudan University Shanghai, China luyf23@m.fudan.edu.cnWenxuan Li & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670267.pdf & Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions Xueluan Gong School of Computer Science, Wuhan University, Wuhan, China xu & Xueluan Gong School of Computer Science, Wuhan University, Wuhan, China xueluangong@whu.edu.cnRubin Wei & def & Privacy & DL & Images & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670285.pdf & SafeEar: Content Privacy-Preserving Audio Deepfake Detection Xinfeng Liâˆ— Zhejiang University HangZhou, Zhejiang, China xinfengli@zju.edu.cnKai Liâˆ— Tsi & SafeEar: Content Privacy-Preserving Audio Deepfake Detection Xinfeng Liâˆ— Zhejiang University HangZhou, Zhejiang, China xinfengli@zju.edu.cnKai Liâˆ— & def & Privacy & DL & Audio & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670291.pdf & Avara: A Uniform Evaluation System for Perceptibility Analysis Against Adversarial Object Evasion Attacks Xinyao Maâˆ— Indiana University Bloomington Bl & Against Adversarial Object Evasion Attacks Xinyao Maâˆ— Indiana University Bloomington Bloomington, IN, USA maxiny@iu.eduChaoqi Zhangâˆ— & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670293.pdf & SUB-PLAY : Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems Oubo Ma Zhejiang University Hangzhou, China mob@ & Multi-Agent Reinforcement Learning Systems Oubo Ma Zhejiang University Hangzhou, China mob@zju.edu.cnYuwen Puâˆ— & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670295.pdf & SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models Xinfeng Liâˆ— Zhejiang University HangZhou, Zhejiang, China xinfengli@z & Text-to-Image Models Xinfeng Liâˆ— Zhejiang University HangZhou, Zhejiang, China xinfengli@zju.edu.cnYuchen Yangâˆ— & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670296.pdf & VisionGuard: Secure and Robust Visual Perception of Autonomous Vehicles in Practice Xingshuo Han xingshuo001@e.ntu.edu.sg Nanyang Technological Univer & Autonomous Vehicles in Practice Xingshuo Han xingshuo001@e.ntu.edu.sg Nanyang Technological University SingaporeHaozhao Wangâˆ— & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670298.pdf & Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols Wei Tong State Key Laboratory of Novel Software Technology, & Wei Tong State Key Laboratory of Novel Software Technology, Nanjing University Nanjing, China weitong@outlook.comHaoyu Chen & atk & Poisoning & Both & Other & YES & YES & NO & Gray-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670307.pdf & Byzantine-Robust Decentralized Federated Learning Minghong Fangâˆ— University of Louisville Louisville, KY, USAZifan Zhang North Carolina State Universi & Byzantine-Robust Decentralized Federated Learning Minghong Fangâˆ— University of Louisville Louisville, KY, USAZifan Zhang North Carolina State University & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670309.pdf & Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems Zheng Fangâˆ— Wuhan University Wuhan, China zhengfang618@whu.edu.cnTao W & Recognition Systems Zheng Fangâˆ— Wuhan University Wuhan, China zhengfang618@whu.edu.cnTao Wangâˆ— & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & ~ & High & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670317.pdf & I Donâ€™t Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors Zijin Lin IIE, CASâ€  School of Cyber  & Zijin Lin IIE, CASâ€  School of Cyber Security, UCASâ€¡ Beijing, ChinaYue Zhaoâˆ— IIE, CASâ€  & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670361.pdf & Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense Hua Ma CSIROâ€™s Data61 Sydney, AustraliaShang Wang University of Technology Syd & CSIROâ€™s Data61 Sydney, AustraliaShang Wang University of Technology Sydney Sydney, AustraliaYansong Gao & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670365.pdf & Not One Less: Exploring Interplay between User Profiles and Items in Untargeted Attacks against Federated Recommendation Yurong Hao Beijing Jiaotong U & Items in Untargeted Attacks against Federated Recommendation Yurong Hao Beijing Jiaotong University Beijing, China yurong.hao@bjtu.edu.cnXihui Chen & atk & Poisoning & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670370.pdf & PLeak: Prompt Leaking Attacks against Large Language Model Applications Bo Hui Johns Hopkins University Baltimore, MD, USA bo.hui@jhu.eduHaolin Yuan J & Applications Bo Hui Johns Hopkins University Baltimore, MD, USA bo.hui@jhu.eduHaolin Yuan & atk & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & YES & High & High & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670382.pdf & The Invisible Polyjuice Potion: An Effective Physical Adversarial Attack Against Face Recognition Ye Wang The University of Kansas Lawrence, KS, USA y & Attack Against Face Recognition Ye Wang The University of Kansas Lawrence, KS, USA yeah\_wong@ku.eduZeyan Liu & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670386.pdf & Inbox Invasion: Exploiting MIME Ambiguities to Evade Email Attachment Detectors Jiahe Zhang Tsinghua University Beijing, China zhjh23@mails.tsinghua.e & Attachment Detectors Jiahe Zhang Tsinghua University Beijing, China zhjh23@mails.tsinghua.edu.cnJianjun Chenâˆ— & atk & Evasion & DL & Malware & YES & YES & YES & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 0 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670388.pdf & â€œDo Anything Nowâ€: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models Xinyue Shen CISPA Helmholtz Center for Informa & Information Security SaarbrÃ¼cken, Germany xinyue.shen@cispa.deZeyuan Chen CISPA Helmholtz Center for Information Security & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3670395.pdf & Alchemy: Data-Free Adversarial Training Yijie Bai baiyj@zju.edu.cn Zhejiang University Hangzhou, Zhejiang, ChinaZhongming Ma allen191819@whu.edu.cn Zh & Alchemy: Data-Free Adversarial Training Yijie Bai baiyj@zju.edu.cn Zhejiang University Hangzhou, Zhejiang, ChinaZhongming Ma & def & Evasion & DL & Images & YES & YES & NO & White-box & ~ & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690185.pdf & ï¿½ï¿½2NeRF: Privacy-preserving Training Framework for NeRF Bokang Zhangâˆ— The Chinese University of Hong Kong, Shenzhen Shenzhen, China bokangzhang@link.cu & ï¿½ï¿½2NeRF: Privacy-preserving Training Framework for NeRF Bokang Zhangâˆ— The Chinese University of Hong Kong, Shenzhen Shenzhen, China & both & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690187.pdf & Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses Yuxin Yang yuxiny22@mails.jlu.edu.cn College of Computer Science and T & Certified Defenses Yuxin Yang yuxiny22@mails.jlu.edu.cn College of Computer Science and Technology, Jilin University & atk & Poisoning & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690194.pdf & Evaluations of Machine Learning Privacy Defenses are Misleading Michael Aerniâˆ— ETH Zurich Zurich, SwitzerlandJie Zhangâˆ— ETH Zurich Zurich, Switzerland & ETH Zurich Zurich, SwitzerlandJie Zhangâˆ— ETH Zurich Zurich, SwitzerlandFlorian TramÃ¨r ETH Zurich Zurich, Switzerland & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690202.pdf & A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability Jie Zhu Key Lab of High Confidence Software Technol & Jie Zhu Key Lab of High Confidence Software Technologies (Peking University), Ministry of Education, China School of Computer Science, Peking University, Beijing China & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690205.pdf & Understanding Implosion in Text-to-Image Generative Models Wenxin Ding University of Chicago Chicago, IL, USACathy Y. Li University of Chicago Chicago & Understanding Implosion in Text-to-Image Generative Models Wenxin Ding University of Chicago Chicago, IL, USACathy Y. Li & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690208.pdf & Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months Keane Lucas kjlucas@alumni.cmu.edu Carnegie Mellon University Pittsburgh, P & in Hours, not Months Keane Lucas kjlucas@alumni.cmu.edu Carnegie Mellon University Pittsburgh, Pennsylvania, USAWeiran Lin & def & Evasion & DL & Malware & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690226.pdf & A General Framework for Data-Use Auditing of ML Models Zonghao Huang Duke University Durham, NC, USA zonghao.huang@duke.eduNeil Zhenqiang Gong Duke Un & A General Framework for Data-Use Auditing of ML Models Zonghao Huang Duke University Durham, NC, USA zonghao.huang@duke.eduNeil Zhenqiang Gong & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690238.pdf & ProFake: Detecting Deepfakes in the Wild against Quality Degradation with Progressive Quality-adaptive Learning Huiyu Xuâ€  The State Key Laboratory of & The State Key Laboratory of Blockchain and Data Security Zhejiang University Hangzhou, Zhejiang, P. R. China huiyuxu@zju.edu.cnYaopeng Wangâ€  & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690250.pdf & Fisher Information guided Purification against Backdoor Attacks Nazmul Karimâˆ— nazmul.karim170@gmail.com University of Central Florida Orlando, Florida & Fisher Information guided Purification against Backdoor Attacks Nazmul Karimâˆ— nazmul.karim170@gmail.com University of Central Florida Orlando, Florida, USAAbdullah Al Arafatâˆ— & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690279.pdf & PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps Ruixuan Liu Emory University Atlanta, USA ruixuan.liu2@emory.eduTianhao W & into Privacy Traps Ruixuan Liu Emory University Atlanta, USA ruixuan.liu2@emory.eduTianhao Wang & atk & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690284.pdf & BadMerging: Backdoor Attacks Against Model Merging Jinghuai Zhang University of California, Los Angeles Los Angeles, USA jinghuai1998@g.ucla.eduJianfe & BadMerging: Backdoor Attacks Against Model Merging Jinghuai Zhang University of California, Los Angeles Los Angeles, USA jinghuai1998@g.ucla.eduJianfeng Chi & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690291 (1).pdf & Optimization-based Prompt Injection Attack to LLM-as-a-Judge Jiawen Shiâˆ— Huazhong University of Science and Technology Wuhan, China shijiawen@hust.edu & Optimization-based Prompt Injection Attack to LLM-as-a-Judge Jiawen Shiâˆ— Huazhong University of Science and Technology Wuhan, China & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690291.pdf & Optimization-based Prompt Injection Attack to LLM-as-a-Judge Jiawen Shiâˆ— Huazhong University of Science and Technology Wuhan, China shijiawen@hust.edu & Optimization-based Prompt Injection Attack to LLM-as-a-Judge Jiawen Shiâˆ— Huazhong University of Science and Technology Wuhan, China & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690292.pdf & Uncovering Gradient Inversion Risks in Practical Language Model Training Xinguo Feng The University of Queensland Brisbane, Australia s.feng@uq.edu.au & Model Training Xinguo Feng The University of Queensland Brisbane, Australia s.feng@uq.edu.auZhongkui Ma & atk & Privacy & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690295.pdf & Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack Guanzhong Ch & Shenzhen Shenzhen, China muxichenz@outlook.comZhenghan Qin Zhejiang University Hangzhou, China & atk & Privacy & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690297.pdf & ZeroFake: Zero-Shot Detection of Fake Images Generated and Edited by Text-to-Image Generation Models Zeyang Sha CISPA Helmholtz Center for Information & Information Security SaarbrÃ¼cken, Germany zeyang.sha@cispa.deYicong Tan CISPA Helmholtz Center for Information Security & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & ~ & High & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690304.pdf & Analyzing Inference Privacy Risks Through Gradients In Machine Learning Zhuohang Li Vanderbilt University Nashville, TN, USA zhuohang.li@vanderbilt.ed & Learning Zhuohang Li Vanderbilt University Nashville, TN, USA zhuohang.li@vanderbilt.eduAndrew Lowy & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690305.pdf & Blind and Low Vision Individualsâ€™ Detection of Audio Deepfakes Filipo Sharevski DePaul University Chicago, IL, United States fsharevs@depaul.eduAziz Z & Blind and Low Vision Individualsâ€™ Detection of Audio Deepfakes Filipo Sharevski DePaul University Chicago, IL, United States fsharevs@depaul.eduAziz Zeidieh & def & ~ & Both & Audio & NO & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 1 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690306.pdf & Membership Inference Attacks Against In-Context Learning Rui Wen CISPA Helmholtz Center for Information Security SaarbrÃ¼cken, Germany rui.wen@cispa.de & Information Security SaarbrÃ¼cken, Germany rui.wen@cispa.deZheng Liâˆ— CISPA Helmholtz Center for Information Security & atk & Privacy & DL & Text & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690311.pdf & Trident of Poseidon: A Generalized Approach for Detecting Deepfake Voices Thien-Phuc Doan phucdt@soongsil.ac.kr Soongsil University Seoul, South Korea & Deepfake Voices Thien-Phuc Doan phucdt@soongsil.ac.kr Soongsil University Seoul, South KoreaHung Dinh-Xuan & def & ~ & DL & Audio & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690316 (1).pdf & Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks Yu Heâˆ—â€  Wuhan University Wuhan, China yuherin@whu.edu.cnBoh & Membership Inference Attacks Yu Heâˆ—â€  Wuhan University Wuhan, China yuherin@whu.edu.cnBoheng Liâˆ—â€  & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690316.pdf & Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks Yu Heâˆ—â€  Wuhan University Wuhan, China yuherin@whu.edu.cnBoh & Membership Inference Attacks Yu Heâˆ—â€  Wuhan University Wuhan, China yuherin@whu.edu.cnBoheng Liâˆ—â€  & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690317.pdf & HyperTheft: Thieving Model Weights from TEE-Shielded Neural Networks via Ciphertext Side Channels Yuanyuan Yuan The Hong Kong University of Science an & Neural Networks via Ciphertext Side Channels Yuanyuan Yuan The Hong Kong University of Science and Technology Hong Kong, China & atk & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690325.pdf & 3658644.3690325 & ~ & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690327.pdf & Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies Peiran Wangâˆ— Tsinghua University Beijing, China while & Fine-grained Context-based Policies Peiran Wangâˆ— Tsinghua University Beijing, China whilebug@gmail.comQiyu Liâˆ— & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690334.pdf & Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data Yifan Lu Fudan University Shanghai, China luyf23@m.fudan.edu & from DNNs with Limited Data Yifan Lu Fudan University Shanghai, China luyf23@m.fudan.edu.cnWenxuan Li & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690335 (1).pdf & SeqMIA: Sequential-Metric Based Membership Inference Attack Hao Liâˆ— Institute of Software, Chinese Academy of Sciences Beijing, ChinaZheng Liâˆ— CISPA H & Institute of Software, Chinese Academy of Sciences Beijing, ChinaZheng Liâˆ— CISPA Helmholtz Center for Information Security SaarbrÃ¼cken, GermanySiyuan Wu & atk & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690335.pdf & SeqMIA: Sequential-Metric Based Membership Inference Attack Hao Liâˆ— Institute of Software, Chinese Academy of Sciences Beijing, ChinaZheng Liâˆ— CISPA H & Institute of Software, Chinese Academy of Sciences Beijing, ChinaZheng Liâˆ— CISPA Helmholtz Center for Information Security SaarbrÃ¼cken, GermanySiyuan Wu & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Full & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690337.pdf & Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines Eugene Bagdasarian University of Massachusetts Amherst Amherst, U & of Machine Learning Pipelines Eugene Bagdasarian University of Massachusetts Amherst Amherst, USA eugene@cs.umass.eduVitaly Shmatikov & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690338.pdf & Demystifying RCE Vulnerabilities in LLM-Integrated Apps Tong Liu IIE, CASâ€  School of Cyber Security, UCASâ€¡ Beijing, China liutong@iie.ac.cnZizhuang De & School of Cyber Security, UCASâ€¡ Beijing, China liutong@iie.ac.cnZizhuang Deng School of Cyber Science and Technology, Shandong University & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690343.pdf & Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence Hanbin Hong University of Connecticut S & Examples: Breaking Defenses with Provable Confidence Hanbin Hong University of Connecticut Storrs, Connecticut, USAXinyu Zhang Zhejiang University & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690346.pdf & SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via Substitution Zhongjie Ba zhongjieba@zju.edu.cn The State Key Laboratory of Bl & Models via Substitution Zhongjie Ba zhongjieba@zju.edu.cn The State Key Laboratory of Blockchain and Data Security, & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & ACM & 3658644.3690369.pdf & Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning Jonathan Knauer jonathan.knauer@stud.tu-darmstadt.de Technical University of Darmsta & Learning Jonathan Knauer jonathan.knauer@stud.tu-darmstadt.de Technical University of Darmstadt Darmstadt, GermanyPhillip Rieger & atk & Poisoning & DL & Images & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 2205.06900v2.pdf & MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic Hang Wang*, Zhen Xiang,*Davi & Pattern Types Using a Maximum Margin Statistic Hang Wang*, Zhen Xiang,*David J. Miller,George Kesidis Anomalee Inc., State College, PA, USA Pennsylvania State University, University Park, PA, USA Abst & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 2311.10500v2.pdf & From Principle to Practice: Vertical Data Minimization for Machine Learning Robin Staab ETH Zurich, Switzerland robin.staab@inf.ethz.chNikola Jovanovi & Robin Staab ETH Zurich, Switzerland robin.staab@inf.ethz.chNikola Jovanovi Â´c ETH Zurich, Switzerland nikola.jovanovic@inf.ethz.chMislav Balunovi Â´c & def & Privacy & Both & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a002.pdf & SoK: Privacy-Preserving Data Synthesis Yuzheng Huâˆ—1Fan Wuâˆ—1Qinbin Li2Yunhui Long1Gonzalo Munilla Garrido3 Chang Ge4Bolin Ding5David Forsyth1Bo Li1Dawn & Yuzheng Huâˆ—1Fan Wuâˆ—1Qinbin Li2Yunhui Long1Gonzalo Munilla Garrido3 Chang Ge4Bolin Ding5David Forsyth1Bo Li1Dawn Song2 1University of Illinois Urbana-Champaign2UC Berkeley 3Technische Universit Â¨at M Â¨ & def & Privacy & Both & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a030.pdf & LOKI: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation Joshua C. Zhao1, Atul Sharma1, Ahmed Roushdy Elkord & Joshua C. Zhao1, Atul Sharma1, Ahmed Roushdy Elkordy2, Yahya H. Ezzeldin2 Salman Avestimehr2, Saurabh Bagchi1 1Purdue University,2University of Southern California \{zhao1207,sharm438,sbagchi }@purdue. & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a052.pdf & No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML Ziqi Zhangâˆ—, Chen Gongâ€ , Yifeng Caiâˆ—, Yuanyuan Yuanâ€¡, Bin & Ziqi Zhangâˆ—, Chen Gongâ€ , Yifeng Caiâˆ—, Yuanyuan Yuanâ€¡, Bingyan LiuÂ§, Ding Liâˆ—, Yao Guoâˆ—, Xiangqun Chenâˆ— âˆ—Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Pekin & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a056.pdf & ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features Peng Chengâˆ—,\#, Yuwei Wangâˆ—,\#, Peng Huangâˆ—,\#, Zhongjie & Linguistic Features Peng Chengâˆ—,\#, Yuwei Wangâˆ—,\#, Peng Huangâˆ—,\#, Zhongjie Baâˆ—,\#,â€¡, Xiaodong Linâ€ , Feng Linâˆ—,\#,L iL uâˆ—,\#, Kui Renâˆ—,\# âˆ—Zhejiang University, Hangzhou, China \#ZJU-Hangzhou Global Scientiï¬c & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a061.pdf & You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content Xinlei He1Savvas Zannettou2Yun Shen3Yang & Language Models to Tackle Toxic Content Xinlei He1Savvas Zannettou2Yun Shen3Yang Zhang1 1CISPA Helmholtz Center for Information Security2Delft University of Technology3NetApp Abstract â€”The spread of t & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a065.pdf & Itâ€™s Simplex! Disaggregating Measures to Improve Certified Robustness Andrew C. Cullenâˆ—â€¡, Paul Montagueâ€ , Shijie Liuâˆ—, Sarah M. Erfaniâˆ—, and Benjamin  & Itâ€™s Simplex! Disaggregating Measures to Improve Certified Robustness Andrew C. Cullenâˆ—â€¡, Paul Montagueâ€ , Shijie Liuâˆ—, Sarah M. Erfaniâˆ—, and Benjamin I.P. Rubinsteinâˆ—, âˆ—School of Computing and Informa & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a068.pdf & BounceAttack: A Query-Efï¬cient Decision-based Adversarial Attack by Bouncing into the Wild Jie Wan1â€ , Jianhao Fu1â€ , Lijin Wang1, Ziqi Yang1,2âˆ— 1Zhejia & into the Wild Jie Wan1â€ , Jianhao Fu1â€ , Lijin Wang1, Ziqi Yang1,2âˆ— 1Zhejiang University 2ZJU-Hangzhou Global Scientiï¬c and Technological Innovation Center \{wanjie, 3180102970, wanglijin, yangziqi }@zju & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & 313000a072.pdf & Test-Time Poisoning Attacks Against Test-Time Adaptation Models Tianshuo Cong1Xinlei He2Yun Shen3Yang Zhang2 1Tsinghua University2CISPA Helmholtz Cent & Test-Time Poisoning Attacks Against Test-Time Adaptation Models Tianshuo Cong1Xinlei He2Yun Shen3Yang Zhang2 1Tsinghua University2CISPA Helmholtz Center for Information Security3NetApp Abstract â€”Deplo & atk & Poisoning & DL & Images & YES & YES & NO & Gray-box & Partial & YES & Low & Low & 1 & 0 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Backdooring\_Multimodal\_Learning.pdf & Backdooring Multimodal Learning Xingshuo Hanâ€ , Yutong Wuâ€ , Qingjie Zhangâ€¡, Yuan Zhouâ€ âˆ—, Yuan Xuâ€ , Han Qiuâ€¡Â§, Guowen Xuâ€ , Tianwei Zhangâ€  â€ Nanyang Techn & Xingshuo Hanâ€ , Yutong Wuâ€ , Qingjie Zhangâ€¡, Yuan Zhouâ€ âˆ—, Yuan Xuâ€ , Han Qiuâ€¡Â§, Guowen Xuâ€ , Tianwei Zhangâ€  â€ Nanyang Technological University, \{xingshuo001, yutong002}@e.ntu.edu.sg, \{y.zhou, xu.yuan, guow & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & BadVFL\_Backdoor\_Attacks\_in\_Vertical\_Federated\_Learning.pdf & BadVFL: Backdoor Attacks in Vertical Federated Learning Mohammad Naseri Flower Labs University College London mohammad.naseri.19@ucl.ac.ukY ufei Han I & Mohammad Naseri Flower Labs University College London mohammad.naseri.19@ucl.ac.ukY ufei Han INRIA Rennes & atk & Poisoning & DL & Images & YES & NO & NO & Gray-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & DeepShuffle\_A\_Lightweight\_Defense\_Framework\_against\_Adversarial\_Fault\_Injection\_Attacks\_on\_Deep\_Neural\_Networks\_in\_Multi-Tenant\_Cloud-FPGA.pdf & DeepShufï¬‚e: A Lightweight Defense Framework against Adversarial Fault Injection Attacks on Deep Neural Networks in Multi-Tenant Cloud-FPGA Yukui Luo N & Attacks on Deep Neural Networks in Multi-Tenant Cloud-FPGA Yukui Luo Northeastern University luo.yuk@northeastern.eduAdnan Siraj Rakin Binghamton University & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Distribution\_Preserving\_Backdoor\_Attack\_in\_Self-supervised\_Learning.pdf & Distribution Preserving Backdoor Attack in Self-supervised Learning Guanhong Tao1â‡¤, Zhenting Wang2â‡¤, Shiwei Feng1, Guangyu Shen1, Shiqing Ma3, Xiangyu & Distribution Preserving Backdoor Attack in Self-supervised Learning Guanhong Tao1â‡¤, Zhenting Wang2â‡¤, Shiwei Feng1, Guangyu Shen1, Shiqing Ma3, Xiangyu Zhang1 1Purdue University,2Rutgers University,3Un & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Dropout\_Attacks.pdf & Dropout Attacks Andrew Yuan, Alina Oprea, and Cheng Tan Northeastern University Abstract â€”Dropout is a common operator in deep learning, aiming to pre & Dropout Attacks Andrew Yuan, Alina Oprea, and Cheng Tan Northeastern University Abstract â€”Dropout is a common operator in deep learning, aiming to prevent overï¬tting by randomly dropping neurons & atk & Poisoning & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & GrOVe\_Ownership\_Verification\_of\_Graph\_Neural\_Networks\_using\_Embeddings.pdf & GROV E: Ownership Verification of Graph Neural Networks using Embeddings Asim Waheed University of Waterloo asim.waheed@uwaterloo.caVasisht Duddu Univ & GROV E: Ownership Verification of Graph Neural Networks using Embeddings Asim Waheed University of Waterloo asim.waheed@uwaterloo.caVasisht Duddu University of Waterloo & def & Evasion & DL & Other & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Multi-Instance\_Adversarial\_Attack\_on\_GNN-Based\_Malicious\_Domain\_Detection.pdf & Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection Mahmoud Nazzalâˆ—, Issa KhalilÂ§, Abdallah Khreishahâˆ—, NhatHai Phanâˆ—, and Yao M & Mahmoud Nazzalâˆ—, Issa KhalilÂ§, Abdallah Khreishahâˆ—, NhatHai Phanâˆ—, and Yao Maâˆ— âˆ—New Jersey Institute of Technology, Newark, NJ 07102, USA Â§Qatar Computing Research Institute (QCRI), Hamad Bin Khalifa  & atk & Evasion & DL & Other & YES & YES & NO & Black-box & Partial & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Sabre\_Cutting\_through\_Adversarial\_Noise\_with\_Adaptive\_Spectral\_Filtering\_and\_Input\_Reconstruction.pdf & Sabre: Cutting through Adversarial Noise with Adaptive Spectral Filtering and Input Reconstruction Alec F. Diallo School of Informatics The University & Alec F. Diallo School of Informatics The University of Edinburgh Edinburgh, Scotland, UKPaul Patras School of Informatics & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Side-Channel-Assisted\_Reverse-Engineering\_of\_Encrypted\_DNN\_Hardware\_Accelerator\_IP\_and\_Attack\_Surface\_Exploration.pdf & Side-Channel-Assisted Reverse-Engineering of Encrypted DNN Hardware Accelerator IP and Attack Surface Exploration Cheng Gongye, Yukui Luo, Xiaolin Xu, & Accelerator IP and Attack Surface Exploration Cheng Gongye, Yukui Luo, Xiaolin Xu, and Yunsi Fei Department of Electrical \& Computer Engineering Northeastern University, Boston, MA Email:\{gongye.c, lu & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & SoK\_Explainable\_Machine\_Learning\_in\_Adversarial\_Environments.pdf & SoK: Explainable Machine Learning in Adversarial Environments Maximilian Noppel KASTEL Security Research Labs Karlsruhe Institute of Technology German & KASTEL Security Research Labs Karlsruhe Institute of Technology GermanyChristian Wressnegger KASTEL Security Research Labs Karlsruhe Institute of Technology Germany & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Text-CRS\_A\_Generalized\_Certified\_Robustness\_Framework\_against\_Textual\_Adversarial\_Attacks.pdf & Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks Xinyu Zhangâˆ—â€ , Hanbin Hongâ€ , Yuan Hongâ€ B, Peng Huangâˆ—, Bing & Adversarial Attacks Xinyu Zhangâˆ—â€ , Hanbin Hongâ€ , Yuan Hongâ€ B, Peng Huangâˆ—, Binghui Wangâ€¡, Zhongjie Baâˆ—B, Kui Renâˆ— âˆ—Zhejiang University,â€ University of Connecticut,â€¡Illinois Institute of Technology \{xin & def & Evasion & DL & Text & NO & YES & NO & White-box & ~ & NO & ~ & Low & 0 & 0 & 1 & 1 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & IEEE & Why\_Does\_Little\_Robustness\_Help\_A\_Further\_Step\_Towards\_Understanding\_Adversarial\_Transferability.pdf & Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability Yechao Zhang1,2,3,4âˆ—, Shengshan Hu1,2,3,4âˆ—, Leo Yu Z & 2Services Computing Technology and System Lab3Hubei Engineering Research Center on Big Data Security 4Hubei Key Laboratory of Distributed System Security5Cluster and Grid Computing Lab âˆ—School of Cybe & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-115-paper.pdf & Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention Lujia Shen, Yuwen Pu,  & Large Language Models with Dynamic Attention Lujia Shen, Yuwen Pu,  & def & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-1190-paper.pdf & DEMASQ: Unmasking the ChatGPT Wordsmith Kavita Kumari Technical University of Darmstadt kavita.kumari@trust.tu-darmstadt.deAlessandro Pegoraro Technic & DEMASQ: Unmasking the ChatGPT Wordsmith Kavita Kumari Technical University of Darmstadt kavita.kumari@trust.tu-darmstadt.deAlessandro Pegoraro Technical University of Darmstadt & def & Evasion & DL & Text & YES & NO & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-1323-paper.pdf & SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems Guangke Chen ShanghaiTech University chengk@shanghaitech.edu. & Attacks against Speaker Recognition Systems Guangke Chen ShanghaiTech University chengk@shanghaitech.edu.cnYedi Zhang National University of Singapore & atk & Privacy & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-1366-paper.pdf & Automatic Adversarial Adaption for Stealthy Poisoning Attacks in Federated Learning Torsten KrauÃŸ University of W Â¨urzburg torsten.krauss@uni-wuerzbur & Poisoning Attacks in Federated Learning Torsten KrauÃŸ University of W Â¨urzburg torsten.krauss@uni-wuerzburg.deJan K Â¨onig University of W Â¨urzburg & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-14-paper.pdf & Overconï¬dence is a Dangerous Thing:  Mitigating Membership Inference Attacks  by Enforcing Less Conï¬dent Prediction Zitao Chen University of British C & by Enforcing Less Conï¬dent Prediction Zitao Chen University of British Columbia zitaoc@ece.ubc.caKarthik Pattabiraman University of British Columbia & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-158-paper.pdf & CamPro : Camera-based Anti-Facial Recognition Wenjun Zhu, Yuan Sun, Jiani Liu, Yushi Cheng, Xiaoyu Ji*, Wenyuan Xu USSLAB, Zhejiang University \{zwj ,s & CamPro : Camera-based Anti-Facial Recognition Wenjun Zhu, Yuan Sun, Jiani Liu, Yushi Cheng, Xiaoyu Ji*, Wenyuan Xu USSLAB, Zhejiang University \{zwj ,sytsang,jianiliu,yushicheng,xji,wyxu }@zju.edu.cn A & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-164-paper.pdf & Enhance Stealthiness and Transferability of Adversarial Attacks with Class Activation Mapping Ensemble Attack Hui Xia Ocean University of China xiahu & Ensemble Attack Hui Xia Ocean University of China xiahui@ouc.edu.cnRui Zhang Ocean University of China & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-188-paper.pdf & MASTER KEY: Automated Jailbreaking of Large Language Model Chatbots Gelei Deng1Â§, Yi Liu1Â§, Yuekang Li2â€ , Kailong Wang3, Ying Zhang4, Zefeng Li1, Haoy & Gelei Deng1Â§, Yi Liu1Â§, Yuekang Li2â€ , Kailong Wang3, Ying Zhang4, Zefeng Li1, Haoyu Wang3, Tianwei Zhang1, and Yang Liu1 1Nanyang Technological University,2University of New South Wales, 3Huazhong Uni & atk & Evasion & DL & Text & YES & NO & NO & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 1 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-200-paper.pdf & Detecting V oice Cloning Attacks via Timbre Watermarking Chang Liu1, Jie Zhang2â€ , Tianwei Zhang2, Xi Yang1, Weiming Zhang1â€ , and Nenghai Yu1 1Universi & Watermarking Chang Liu1, Jie Zhang2â€ , Tianwei Zhang2, Xi Yang1, Weiming Zhang1â€ , and Nenghai Yu1 1University of Science and Technology of China 2Nanyang Technological University â€ Corresponding Authors & def & Evasion & DL & Audio & YES & YES & YES & White-box & Full & NO & Low & Low & 0 & 0 & 1 & 0 & 0 & 0 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-216-paper.pdf & Attributions for ML-based ICS Anomaly Detection: From Theory to Practice Clement Fung Carnegie Mellon University clementf@cs.cmu.eduEric Zeng Carnegie & ICS Anomaly Detection: From Theory to Practice Clement Fung Carnegie Mellon University clementf@cs.cmu.eduEric Zeng Carnegie Mellon University & atk & Evasion & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-233-paper.pdf & CrowdGuard: Federated Backdoor Detection in Federated Learning Phillip Riegerâˆ— Technical University of Darmstadt phillip.rieger@trust.tu-darmstadt.deT & Federated Learning Phillip Riegerâˆ— Technical University of Darmstadt phillip.rieger@trust.tu-darmstadt.deTorsten KrauÃŸâˆ— University of W Â¨urzburg & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-238-paper.pdf & LMSanitator : Defending Prompt-Tuning Against Task-Agnostic Backdoors Chengkun Weiâˆ—Â¶, Wenlong Mengâˆ—Â¶, Zhikun Zhangâˆ—â€ â€¡âˆ¥, Min Chenâ€¡, Minghu Zhaoâˆ—, Wenji & Chengkun Weiâˆ—Â¶, Wenlong Mengâˆ—Â¶, Zhikun Zhangâˆ—â€ â€¡âˆ¥, Min Chenâ€¡, Minghu Zhaoâˆ—, Wenjing FangÂ§, Lei WangÂ§, Zihui Zhangâˆ—, Wenzhi Chenâˆ—âˆ¥ âˆ—Zhejiang University,â€ Stanford University,â€¡CISPA Helmholtz Center for I & def & Poisoning & DL & Text & YES & YES & NO & Black-box & ~ & YES & Low & Low & 1 & 0 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-30-paper.pdf & Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time Xinfeng Li Zhejiang University xinfengli@zju.edu.cn Zihan & Recognition of User Speech in Real Time Xinfeng Li Zhejiang University xinfengli@zju.edu.cn Zihan Zeng & atk & Evasion & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-325-paper (1).pdf & Transpose Attack: Stealing Datasets with Bidirectional Training Guy Amit Ben Gurion University guy5@post.bgu.ac.ilMoshe Levy Ben Gurion University mos & Transpose Attack: Stealing Datasets with Bidirectional Training Guy Amit Ben Gurion University guy5@post.bgu.ac.ilMoshe Levy Ben Gurion University & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-325-paper.pdf & Transpose Attack: Stealing Datasets with Bidirectional Training Guy Amit Ben Gurion University guy5@post.bgu.ac.ilMoshe Levy Ben Gurion University mos & Transpose Attack: Stealing Datasets with Bidirectional Training Guy Amit Ben Gurion University guy5@post.bgu.ac.ilMoshe Levy Ben Gurion University & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-326-paper.pdf & Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models Shiming Wang1, Zhe Ji1, Liyao Xiang1â€ , Hao Zhang1, Xinbing Wang & Inversion-based Identity Theft on Deep Models Shiming Wang1, Zhe Ji1, Liyao Xiang1â€ , Hao Zhang1, Xinbing Wang1, Chenghu Zhou2, Bo Li3 1Shanghai Jiao Tong University,2Chinese Academy of Science,3Hong K & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-334-paper.pdf & Sneaky Spikes: Uncovering Stealthy  Backdoor Attacks in Spiking Neural  Networks with Neuromorphic Data Gorka Abad Radboud University, The Netherlands & Networks with Neuromorphic Data Gorka Abad Radboud University, The Netherlands \& Ikerlan Research Centre, Spain abad.gorka@ru.nlOË˜guzhan Ersoy & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-360-paper.pdf & FP-Fed: Privacy-Preserving Federated Detection of Browser Fingerprinting Meenatchi Sundaram Muthu Selva Annamalai University College London meenatchi. & Browser Fingerprinting Meenatchi Sundaram Muthu Selva Annamalai University College London meenatchi.annamalai.22@ucl.ac.ukIgor Bilogrevic Google & def & Privacy & Traditional & Other & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-380-paper.pdf & MPCD IFF: Testing and Repairing MPC-Hardened Deep Learning Models Qi Pangy Carnegie Mellon University qpang@andrew.cmu.eduYuanyuan Yuan HKUST yyuanaq@ & Deep Learning Models Qi Pangy Carnegie Mellon University qpang@andrew.cmu.eduYuanyuan Yuan HKUST & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-441-paper.pdf & GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks Bang Wuâˆ—â€ 1, He Zhangâ€ , Xiangwen Yangâ€ , Shuo Wangâˆ—â€¡, Minhui Xueâˆ—, & Bang Wuâˆ—â€ 1, He Zhangâ€ , Xiangwen Yangâ€ , Shuo Wangâˆ—â€¡, Minhui Xueâˆ—, Shirui PanÂ§and Xingliang Yuanâ€  âˆ—CSIROâ€™s Data61, Australia â€ Monash University, Australia â€¡Shanghai Jiao Tong University, China Â§Griffith & def & Privacy & DL & Other & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-450-paper.pdf & Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering Rui Zhuâ‡¤, Di Tangâ‡¤, Siyuan Tangâ‡¤, Zihao Wangâ‡¤, Guanhong Taoâ€ , Shiqing Maâ€¡, Xia & Against Reverse Engineering Rui Zhuâ‡¤, Di Tangâ‡¤, Siyuan Tangâ‡¤, Zihao Wangâ‡¤, Guanhong Taoâ€ , Shiqing Maâ€¡, Xiaofeng Wangâ‡¤, Haixu Tangâ‡¤ â‡¤Indiana University Bloomington Emails: zhu11@iu.edu, tangd@iu.edu, t & atk & Poisoning & DL & Images & YES & YES & NO & Black-box & Partial & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-545-paper.pdf & Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models Rui Duan University of Sou & Speaker Recognition Models Rui Duan University of South Florida ruiduan@usf.eduZhe Qu Central South University & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-620-paper.pdf & FreqFed : A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning Hossein Fereidooni Technical University of Darmst & Mitigating Poisoning Attacks in Federated Learning Hossein Fereidooni Technical University of Darmstadt1 hossein.fereidooni@trust.tu-darmstadt.deAlessandro Pegoraro Technical University of Darmstadt & def & Poisoning & DL & Images & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-81-paper.pdf & Low-Quality Training Data Only? A Robust Framework for Detecting Encrypted Malicious Network Traffic Yuqi QingÂ§âˆ—, Qilei Yinâ€ âˆ—, Xinhao DengÂ§, Yihao Che & for Detecting Encrypted Malicious Network Traffic Yuqi QingÂ§âˆ—, Qilei Yinâ€ âˆ—, Xinhao DengÂ§, Yihao ChenÂ¶, Zhuotao LiuÂ§, Kun Sunâ€¡, Ke XuÂ¶, Jia ZhangÂ§, Qi LiÂ§, Â§Institute for Network Sciences and Cyberspac & def & ~ & DL & Malware & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-84-paper.pdf & Group-based Robustness: A General Framework for Customized Robustness in the Real World Weiran Lin Carnegie Mellon University weiranl@andrew.cmu.eduKe & in the Real World Weiran Lin Carnegie Mellon University weiranl@andrew.cmu.eduKeane Lucas Carnegie Mellon University & both & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-90-paper.pdf & TextGuard: Provable Defense against Backdoor Attacks on Text Classification Hengzhi Pei1, Jinyuan Jia1,3, Wenbo Guo2,4, Bo Li1, Dawn Song2 1UIUC,2UC B & Attacks on Text Classification Hengzhi Pei1, Jinyuan Jia1,3, Wenbo Guo2,4, Bo Li1, Dawn Song2 1UIUC,2UC Berkeley,3Penn State,4Purdue University \{hpei4, lbo }@illinois.edu, jinyuan@psu.edu, henrygwb@be & def & Poisoning & DL & Text & YES & YES & NO & White-box & Full & NO & Low & Low & 0 & 0 & 1 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & NDS & 2024-920-paper.pdf & DorPatch: Distributed and Occlusion-Robust Adversarial Patch to Evade Certifiable Defenses Chaoxiang Heâˆ—, Xiaojing Maâˆ—1, Bin B. Zhuâ€ , Yimiao Zengâˆ—, Ha & Chaoxiang Heâˆ—, Xiaojing Maâˆ—1, Bin B. Zhuâ€ , Yimiao Zengâˆ—, Hanqing Huâˆ—, Xiaofan Baiâˆ—, Hai Jinâˆ—, and Dongmei Zhangâ€  âˆ—Huazhong University of Science and Technology â€ Microsoft Emails: \{hechaoxiang, lindahu & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & 2402.18104v2.pdf & Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction Tong Liu1,2, Yingjie Zhang1,2, Zhe Zhao3 & Tong Liu1,2, Yingjie Zhang1,2, Zhe Zhao3, Yinpeng Dong3,4, Guozhu Meng1,2,âˆ—, Kai Chen1,2 1Institute of Information Engineering, Chinese Academy of Sciences, China 2School of Cyber Security, University & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & USINEX Adversarial ML.pdf & Hardware   Attacks   on   ML   1. & Attacks   on   ML & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec23winter-prepub-118-sun.pdf & Neural Network Semantic Backdoor Detection and Mitigation: A Causality-Based Approach Bing Sun Singapore Management UniversityJun Sun Singapore Manage & Approach Bing Sun Singapore Management UniversityJun Sun Singapore Management University Wayne Koh & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec23winter-prepub-37-zhang-qingzhao.pdf & On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures Qingzhao Zhang1, Shuowei Jin1, Ruiyang Zhu1, Jiachen Sun1, Xumi & Qingzhao Zhang1, Shuowei Jin1, Ruiyang Zhu1, Jiachen Sun1, Xumiao Zhang1, Qi Alfred Chen2, Z. Morley Mao1,3 1University of Michigan,2University of California, Irvine,3Google Abstract Collaborative per & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec23winter-prepub-4-ren.pdf & Accelerating Secure Collaborative Machine Learning with Protocol-Aware RDMA Zhenghang Ren1, Mingxuan Fan1, Zilong Wang1, Junxue Zhang1, Chaoliang Zeng & Zhenghang Ren1, Mingxuan Fan1, Zilong Wang1, Junxue Zhang1, Chaoliang Zeng1, Zhicong Huang2, Cheng Hong2, and Kai Chen1,3 1iSING Lab@The Hong Kong University of Science and Technology2Ant Group 3Unive & def & ~ & Both & Other & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-1157-wang-haichen.pdf & dp-promise: Differentially Private Diffusion Probabilistic Models for Image Synthesis Haichen Wang1Shuchao Pang1âˆ—Zhigang Lu2âˆ—Yihang Rao1Yongbin Zhou1M & Synthesis Haichen Wang1Shuchao Pang1âˆ—Zhigang Lu2âˆ—Yihang Rao1Yongbin Zhou1Minhui Xue3 1Nanjing University of Science and Technology, China 2James Cook University, Australia 3CSIROâ€™s Data61, Australia & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-1479-layton.pdf & SoK: The Good, The Bad, and The Unbalanced: Measuring Structural Limitations of Deepfake Media Datasets Seth Layton, Tyler Tucker, Daniel Olszewski, K & Measuring Structural Limitations of Deepfake Media Datasets Seth Layton, Tyler Tucker, Daniel Olszewski, Kevin Warren, Kevin Butler, and Patrick Traynor University of Florida Abstract Deepfake media r & def & ~ & DL & Audio & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-1500-yu-zhiyuan.pdf & Donâ€™t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models Zhiyuan Yuâ€ , Xiaogeng LiuÂ§, Shunning Liangâ€ , Zach Cameronâ€¡, & Large Language Models Zhiyuan Yuâ€ , Xiaogeng LiuÂ§, Shunning Liangâ€ , Zach Cameronâ€¡, Chaowei XiaoÂ§, Ning Zhangâ€  â€ Washington University in St. Louis,Â§University of Wisconsin - Madison,â€¡John Burroughs Scho & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-180-xiang-chong (1).pdf & PATCH CURE : Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses Chong Xiang1, Tong Wu1, Sihui D & Efficiency of Adversarial Patch Defenses Chong Xiang1, Tong Wu1, Sihui Dai1, Jonathan Petit2, Suman Jana3, Prateek Mittal1 1Princeton University,2Qualcomm Technologies, Inc.,3Columbia University Abstr & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-180-xiang-chong.pdf & PATCH CURE : Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses Chong Xiang1, Tong Wu1, Sihui D & Efficiency of Adversarial Patch Defenses Chong Xiang1, Tong Wu1, Sihui Dai1, Jonathan Petit2, Suman Jana3, Prateek Mittal1 1Princeton University,2Qualcomm Technologies, Inc.,3Columbia University Abstr & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-199-grosse.pdf & Towards More Practical Threat Models in Artificial Intelligence Security Kathrin Grosse,1Lukas Bieringer,2Tarek R. Besold,3Alexandre Alahi1 1EPFL, Swi & Kathrin Grosse,1Lukas Bieringer,2Tarek R. Besold,3Alexandre Alahi1 1EPFL, Switzerland,2QuantPi, Germany,3TU Eindhoven, The Netherlands Abstract Recent works have identified a gap between research and  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-200-wang-shuo.pdf & DNN-GP: Diagnosing and Mitigating Modelâ€™s Faults Using Latent Concepts Shuo Wang Shanghai Jiao Tong UniversityHongsheng Hu CSIROâ€™s Data61Jiamin Chang & DNN-GP: Diagnosing and Mitigating Modelâ€™s Faults Using Latent Concepts Shuo Wang Shanghai Jiao Tong UniversityHongsheng Hu CSIROâ€™s Data61Jiamin Chang University of New South Wales & both & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2129-yuan.pdf & MD-ML: Super Fast Privacy-Preserving Machine Learning for Malicious Security with a Dishonest Majority Boshi Yuan1, Shixuan Yang1, Yongxiang Zhang1, N & for Malicious Security with a Dishonest Majority Boshi Yuan1, Shixuan Yang1, Yongxiang Zhang1, Ning Ding1,2,*, Dawu Gu1,2,*, and Shi-Feng Sun1,2 1Shanghai Jiao Tong University, China 2Shanghai Jiao To & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2154-pegoraro (1).pdf & DeepEclipse : How to Break White-Box DNN-Watermarking Schemes Alessandro Pegoraro Technical University of DarmstadtCarlotta Segna Technical University & DeepEclipse : How to Break White-Box DNN-Watermarking Schemes Alessandro Pegoraro Technical University of DarmstadtCarlotta Segna Technical University of Darmstadt Kavita Kumari & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2154-pegoraro.pdf & DeepEclipse : How to Break White-Box DNN-Watermarking Schemes Alessandro Pegoraro Technical University of DarmstadtCarlotta Segna Technical University & DeepEclipse : How to Break White-Box DNN-Watermarking Schemes Alessandro Pegoraro Technical University of DarmstadtCarlotta Segna Technical University of Darmstadt Kavita Kumari & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2341-nayan.pdf & SoK: All You Need to Know About On-Device ML Model Extraction - The Gap Between Research and Practice Tushar Nayanâˆ— Florida Intl. UniversityQiming Guo & Between Research and Practice Tushar Nayanâˆ— Florida Intl. UniversityQiming Guoâˆ— Florida Intl. UniversityMohammed Al Duniawi Florida Intl. University & atk & Multiple & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2353-gohil (1).pdf & AttackGNN : Red-Teaming GNNs in Hardware Security Using Reinforcement Learning Vasudev Gohilâ€ ,, Satwik Patnaikâ€¡, Dileep Kalathilâ€ , Jeyavijayan Rajendr & Red-Teaming GNNs in Hardware Security Using Reinforcement Learning Vasudev Gohilâ€ ,, Satwik Patnaikâ€¡, Dileep Kalathilâ€ , Jeyavijayan Rajendranâ€  â€ Texas A\&M University, USA,â€¡University of Delaware, USA â€ \{ & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2353-gohil.pdf & AttackGNN : Red-Teaming GNNs in Hardware Security Using Reinforcement Learning Vasudev Gohilâ€ ,, Satwik Patnaikâ€¡, Dileep Kalathilâ€ , Jeyavijayan Rajendr & Red-Teaming GNNs in Hardware Security Using Reinforcement Learning Vasudev Gohilâ€ ,, Satwik Patnaikâ€¡, Dileep Kalathilâ€ , Jeyavijayan Rajendranâ€  â€ Texas A\&M University, USA,â€¡University of Delaware, USA â€ \{ & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2868-wang-lijin.pdf & Property Existence Inference against Generative Models Lijin Wang1, Jingjing Wang1, Jie Wan1, Lin Long1, Ziqi Yang1,2â‡¤, and Zhan Qin1,2 1Zhejiang Univ & Property Existence Inference against Generative Models Lijin Wang1, Jingjing Wang1, Jie Wan1, Lin Long1, Ziqi Yang1,2â‡¤, and Zhan Qin1,2 1Zhejiang University 2ZJU-Hangzhou Global Scientiï¬c and Technolo & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Full & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-2979-krauss.pdf & ClearStamp: A Human-Visible and Robust Model-Ownership Proof based on Transposed Model Training Torsten KrauÃŸ University of WÃ¼rzburgJasper Stang Unive & Transposed Model Training Torsten KrauÃŸ University of WÃ¼rzburgJasper Stang University of WÃ¼rzburgAlexandra Dmitrienko University of WÃ¼rzburg & def & ~ & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-37-jiang-zhifeng.pdf & Lotto: Secure Participant Selection against Adversarial Servers in Federated Learning Zhifeng Jiang1Peng Ye1Shiqi He2,âˆ—Wei Wang1Ruichuan Chen3Bo Li1 1 & in Federated Learning Zhifeng Jiang1Peng Ye1Shiqi He2,âˆ—Wei Wang1Ruichuan Chen3Bo Li1 1HKUST2University of Michigan3Nokia Bell Labs Abstract In Federated Learning (FL), many privacy-enhancing tech- & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-490-jin.pdf & FaceObfuscator: Defending Deep Learning-based Privacy Attacks with Gradient Descent-resistant Features in Face Recognition Shuaifan Jinâ€ ,â‰€He Wangâ€ ,â‰€Zh & Shuaifan Jinâ€ ,â‰€He Wangâ€ ,â‰€Zhibo Wangâ€ ,â‰€,âˆ—Feng Xiao/naturalJiahui Huâ€ ,â‰€Yuan Heâ€¡ Wenwen Zhangâ€¡Zhongjie Baâ€ ,â‰€Weijie Fang/sharpShuhong Yuan/sharpKui Renâ€ ,â‰€ â€ The State Key Laboratory of Blockchain and DataS & def & Privacy & DL & Images & YES & YES & YES & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-877-shen-xinyue (1).pdf & Prompt Stealing Attacks Against Text-to-Image Generation Models Xinyue Shen Yiting Qu Michael Backes Yang Zhang CISPA Helmholtz Center for Information & CISPA Helmholtz Center for Information Security Abstract Text-to-Image generation models have revolutionized the art- work design process and enabled anyone to create high-quality images by entering t & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24fall-prepub-877-shen-xinyue.pdf & Prompt Stealing Attacks Against Text-to-Image Generation Models Xinyue Shen Yiting Qu Michael Backes Yang Zhang CISPA Helmholtz Center for Information & CISPA Helmholtz Center for Information Security Abstract Text-to-Image generation models have revolutionized the art- work design process and enabled anyone to create high-quality images by entering t & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-1096-wang-zihao.pdf & Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep Neural Networks for Runtime Trojan Injectionâˆ— Zihao Wang1, Di Tang1, XiaoFeng Wang1, Wei & Runtime Trojan Injectionâˆ— Zihao Wang1, Di Tang1, XiaoFeng Wang1, Wei He2, Zhaoyang Geng2, Wenhao Wang2 1Indiana University Bloomington 2SKLOIS, Institute of Information Engineering, Chinese Academy  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-171-levi.pdf & Splitting the Difference on Adversarial Training Matan Levi Ben-Gurion University of the Negev matanle@post.bgu.ac.ilAryeh Kontorovich Ben-Gurion Univ & Splitting the Difference on Adversarial Training Matan Levi Ben-Gurion University of the Negev matanle@post.bgu.ac.ilAryeh Kontorovich Ben-Gurion University of the Negev & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-176-wu-yixin.pdf & Quantifying Privacy Risks of Prompts in Visual Prompt Learning Yixin Wu1Rui Wen1Michael Backes1Pascal Berrang2Mathias Humbert3Yun Shen4Yang Zhang1 1CI & Yixin Wu1Rui Wen1Michael Backes1Pascal Berrang2Mathias Humbert3Yun Shen4Yang Zhang1 1CISPA Helmholtz Center for Information Security 2University of Birmingham3University of Lausanne4Netapp Abstract La & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-349-li-changjiang.pdf & On the Difficulty of Defending Contrastive Learning against Backdoor Attacks Changjiang Liâ‹†Ren Pangâ€ Bochuan Caoâ€ Zhaohan Xiâ€ Jinghui Chenâ€  Shouling Jiâ€¡T & Changjiang Liâ‹†Ren Pangâ€ Bochuan Caoâ€ Zhaohan Xiâ€ Jinghui Chenâ€  Shouling Jiâ€¡Ting Wangâ‹† â‹†Stony Brook Universityâ€ Pennsylvania State Universityâ€¡Zhejiang University meet.cjli@gmail.com, \{rbp5354, bccao, zxx51 & atk & Poisoning & DL & Images & YES & YES & NO & Black-box & Full & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-365-zhang-guangsheng.pdf & How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers Guangsheng Zhang1Bo & Guangsheng Zhang1Bo Liu1Huan Tian1Tianqing Zhu1 Ming Ding2Wanlei Zhou3 1University of Technology Sydney2Data 61, Australia3City University of Macau Abstract As a booming research area in the past deca & atk & Privacy & DL & Images & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-373-diaa.pdf & Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions Abdulrahman Diaaâˆ—1, Lucas Fenauxâˆ—1, Thomas Humphriesâˆ—1, Marian & Bailey Kacsmar1, Xinda Li1, Nils Lukas1, Rasoul Akhavan Mahdavi1, Simon Oya1, Ehsan Amjadian1, 2, and Florian Kerschbaum1 1University of Waterloo 2Royal Bank of Canada \{abdulrahman.diaa, lucas.fenaux, & def & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-385-shen-meng.pdf & Transferability of White-box Perturbations: Query-Efficient Adversarial Attacks against Commercial DNN Services Meng Shen1, Changyue Li1, Qi Li2, Hao  & Meng Shen1, Changyue Li1, Qi Li2, Hao Lu3, Liehuang Zhu1, and Ke Xu4 1School of Cyberspace Science and Technology, Beijing Institute of Technology, China 2Institute for Network Sciences and Cyberspace & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-409-tang.pdf & MODEL GUARD : Information-Theoretic Defense Against Model Extraction Attacks Minxue Tang1, Anna Dai1, Louis DiValentin2, Aolin Ding2, Amin Hass2, Neil & "Minxue Tang1 & Anna Dai1 & Louis DiValentin2 & Aolin Ding2 & Amin Hass2 & Neil Zhenqiang Gong1 & Yiran Chen1 & Hai ""Helen"" Li1 1Department of Electrical and Computer Engineering & Duke University 2Cyber Secur" & def & Privacy & DL & Images & YES & YES & NO & White-box & ~ & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 \\ \hline
        2024 & USENIX & sec24summer-prepub-617-zhang-boyang.pdf & SECURITY NET: Assessing Machine Learning Vulnerabilities on Public Models Boyang Zhang Zheng Li Ziqing Yang Xinlei He Michael Backes Mario Fritz Yang & CISPA Helmholtz Center for Information Security Abstract While advanced machine learning (ML) models are de- ployed in numerous real-world applications, previous works demonstrate these models have se & atk & Privacy & DL & Images & YES & YES & NO & Black-box & Partial & NO & High & High & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-641-liu-jian.pdf & False Claims against Model Ownership Resolutionâˆ— Jian Liuâ€  â€  Zhejiang University jian.liu@zju.edu.cnRui Zhangâ€  Zhejiang University zhangrui98@zju.edu. & False Claims against Model Ownership Resolutionâˆ— Jian Liuâ€  â€  Zhejiang University jian.liu@zju.edu.cnRui Zhangâ€  Zhejiang University & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-659-zhu.pdf & AE-Morpher: Improve Physical Robustness of Adversarial Objects against LiDAR-based Detectors via Object Reconstruction Shenchen Zhu1,2,Yue Zhao1,Kai  & Shenchen Zhu1,2,Yue Zhao1,Kai Chen1,2,Bo Wang3,Hualong Ma1,2,Chengâ€™an Wei1,2 1Institute of Information Engineering, Chinese Academy of Sciences, China, 2School of Cyber Security, University of Chine & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-705-zhuang.pdf & Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks? Yuanxin Zhuang Chuan Shiâˆ—Mengme & through Data-Free Model Extraction Attacks? Yuanxin Zhuang Chuan Shiâˆ—Mengmei Zhang Beijing University of Posts and Telecommunications Key Laboratory of Trustworthy Distributed Computing and Service (B & atk & Privacy & DL & Other & YES & NO & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-743-li.pdf & Yes, One-Bit-Flip Matters! Universal DNN Model Inference Depletion with Runtime Code Fault Injection Shaofeng Li Peng Cheng LaboratoryXinyu Wang Shang & Shaofeng Li Peng Cheng LaboratoryXinyu Wang Shanghai Jiao Tong UniversityMinhui Xue CSIROâ€™s Data61Haojin Zhu Shanghai Jiao Tong University & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-832-liu-hongbin.pdf & Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models Hongbin Liu Michael K. Reiter Neil Zhenqiang Gong Duke University \{hongbin.liu, mic & Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models Hongbin Liu Michael K. Reiter Neil Zhenqiang Gong Duke University \{hongbin.liu, michael.reiter, neil.gong}@duke.edu Abstract & def & Poisoning & DL & Images & YES & NO & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & sec24summer-prepub-920-dahiya.pdf & Machine Learning needs Better Randomness Standards: Randomised Smoothing andPRNG -based attacks Pranav Dahiya University of CambridgeIlia Shumailov Un & Randomised Smoothing andPRNG -based attacks Pranav Dahiya University of CambridgeIlia Shumailov University of OxfordRoss Anderson University of Cambridge & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-an.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & 33rd USENIX Security Symposium   is sponsored by USENIX.Rethinking the Invisible Protection against  Unauthorized Image Usage in Stable Diffusion Shengwei An, Lu Yan, Siyuan Cheng, Guangyu Shen, Kaiyu & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-annamalai-linear.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.A Linear Reconstruction Approach for Attribute  Inference Attacks against Synthetic Data Meenatchi Sundaram Muthu Selva Annamalai, University College London;   Andrea Gadotti an & atk & Privacy & DL & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-ao.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.AutoFHE: Automated Adaption of CNNs   for Efficient Evaluation over FHE Wei Ao and Vishnu Naresh Boddeti, Michigan State University https://www.usenix.org/conference/usenixsecur & def & ~ & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-bethany.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & of Large Language Semantics for Detecting   Human vs. Machine-Generated Text Mazal Bethany, The University of Texas at San Antonio and Secure AI and  Autonomy Lab; Brandon Wherry, The University of Te & def & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-bouhoula.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Automated Large-Scale Analysis of   Cookie N & def & Privacy & Both & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-cai-yifeng.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Contra stive Learning Yifeng Cai, Key Laboratory of High Confidence Software Technologies ( PKU),  Ministry of Education; School of Computer Science, Peking University; Ziqi Zhang,  Department of Comp & def & Privacy & DL & Other & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-chang.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & 33rd USENIX Security Symposium   is sponsored by USENIX.Efficient Privacy Auditing in Federated Learning Hongyan Chang, National University of Singapore; Brandon Edwards,   Intel Corporation; Anindya  & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-chen-baodong.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Adversary is on the Road: Attacks on Visual  SLAM using Unnoticeable Adversarial Patch Baodong Chen, The Ohio State University; Wei Wang and Pascal Sikorski,  Saint Louis Univer & atk & Evasion & DL & Images & YES & YES & NO & Gray-box & Full & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-chen-meng.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Devil in the Room: Triggering Audio Backdoors  in the Physical World Meng Chen, Zhejiang University; Xiangyu Xu, Southeast University;   Li Lu, Zhongjie Ba, Feng Lin, and Kui Re & atk & Poisoning & DL & Audio & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-debenedetti.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & 33rd USENIX Security Symposium   is sponsored by USENIX.Privacy Side Channels in Machine Learning Systems Edoardo Debenedetti, ETH Zurich; Giorgio Severi, Northeastern University;  Nicholas Carlini, C & atk & Privacy & DL & Text & YES & NO & YES & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 1 & 0 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-dentan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Reconstructing training data from   document & atk & Privacy & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-ge-attacks (1).pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Recognition Systems by Inferring Feature Extractor Yunjie Ge, Pinji Chen, Qian Wang, Lingchen Zhao, and Ningping Mou,  Wuhan University; Peipei Jiang, Wuhan University; City University of Hong Kong;   & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-ge-attacks.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Recognition Systems by Inferring Feature Extractor Yunjie Ge, Pinji Chen, Qian Wang, Lingchen Zhao, and Ningping Mou,  Wuhan University; Peipei Jiang, Wuhan University; City University of Hong Kong;   & atk & Evasion & DL & Audio & YES & YES & YES & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-ge-hijacking (1).pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Hijacking Attacks against Neural Network   by Analyzing Training Data Yunjie Ge, Qian Wang, and Huayang Huang, Wuhan University;   Qi Li, Tsinghua University; BNRist; Cong Wang, & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-ge-hijacking.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Hijacking Attacks against Neural Network   by Analyzing Training Data Yunjie Ge, Qian Wang, and Huayang Huang, Wuhan University;   Qi Li, Tsinghua University; BNRist; Cong Wang, & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-hao-qingying.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.It Doesnâ€™t Look Like Anything to Me: Using Diffusion  Model to Subvert Visual Phishing Detectors Qingying Hao and Nirav Diwan, University of Illinois at Urbana-Champaign;   Ying & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-he-haojie.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & for Binary Code Similarity Detection Haojie He, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong  University; Xingwei Lin, Ant Group; Ziang Weng and Ruijie Zhao, School  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-huang-zirui.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.UBA-Inf: Unlearning Activated Backdoor Attack  with Influence-Driven Camouflage Zirui Huang, Yunlong Mao, and Sheng Zhong, Nanjing University https://www.usenix.org/conference/u & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-jiang-nan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & on Voice Authentication Systems   with a Single Face Image Nan Jiang, Bangjie Sun, and Terence Sim, National University of Singapore;   Jun Han, KAIST https://www.usenix.org/conference/usenixsecurity2 & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-jin-shuaifan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Privacy Attacks with Gradient Descent-resistant  Features in Face Recognition Shuaifan Jin, He Wang, and Zhibo Wang, Zhejiang University;   Feng Xiao, Palo Alto Networks; Jiahui Hu, Zhejiang Universit & def & Privacy & DL & Images & YES & YES & YES & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-joslin.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Double Face: Leveraging User Intelligence to  Characterize and Recognize AI-synthesized Faces Matthew Joslin, Xian Wang, and Shuang Hao, University of Texas at Dallas https://ww & def & ~ & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-krauss-verify\_1.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Verify your Labels! Trustworthy Predictions   and Datasets via Confidence Scores Torsten KrauÃŸ, Jasper Stang, and Alexandra Dmitrienko, University of WÃ¼rzburg https://www.usenix & def & Poisoning & DL & Images & YES & NO & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-kumari.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Xplain: Analyzing Invisible Correlations   in Model Explanation Kavita Kumari and Alessandro Pegoraro, Technical University of Darmstadt;  Hossein Fereidooni, Kobil; Ahmad-Reza  & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-li-jiacheng.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Attacks Through Membership-Invariant   Subspace Training Jiacheng Li, Ninghui Li, and Bruno Ribeiro, Purdue University https://www.usenix.org/conference/usenixsecurity24/presentation/li-jiacheng & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-li-songze.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.BackdoorIndicator: Leveraging OOD Data for   Proactive Backdoor Detection in Federated Learning Songze Li, Southeast University; Yanbo Dai, HKUST (GZ) https://www.usenix.org/con & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-lin-zilong.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Model Integrated Malicious Services Zilong Lin, Jian Cui, Xiaojing Liao, and XiaoFeng Wang,  Indiana University Bloomington https://www.usenix.org/conference/usenixsecurity24/presentation/lin-zilong & atk & Evasion & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-liu-shigang.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.EaTVul: ChatGPT-based Evasion Attack  Against Software Vulnerability Detection Shigang Liu, CSIROâ€™s Data61 and Swinburne University of Technology;   Di Cao, Swinburne University & atk & Evasion & DL & Other & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-lorch.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Zooming Into the Directionality of Digital   Images With Security Implications Benedikt Lorch and Rainer BÃ¶hme, University of Innsbruck https://www.usenix.org/conference/usenixsecurity24/presentation/ & both & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-lou.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.A First Physical-World Trajectory Prediction Attack via  LiDAR-induced Deceptions in Autonomous Driving Yang Lou, City University of Hong Kong; Yi Zhu, State University of New Y & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-lyu.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Backdoor Attacks against Personalized   Federated Learning Xiaoting Lyu, Beijing Jiaotong University; Yufei Han, INRIA; Wei Wang, Jingkai Liu,  and Yongsheng Zhu, Beijing Jiaotong University; Guangqua & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-meeus.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Did the Neurons Read your Book? Document-lev & atk & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-muller.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Vogues : Validation of O bject G uise u sing   Estimated Component s Raymond Muller, Purdue University; Yanmao Man and Ming Li,   University of Arizona; Ryan Gerdes, Virginia Te & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-nazari.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Forget and Rewire: Enhancing the Resilience of  Transformer-based Models against Bit-Flip Attacks Najmeh Nazari, Hosein Mohammadi Makrani, and Chongzhou Fang, University   of Ca & def & ~ & DL & Text & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-risse.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Uncovering the Limits of Machine Learning fo & def & ~ & DL & Other & YES & YES & NO & White-box & Full & NO & High & Low & 0 & 1 & 1 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-shao.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.FVD-DPM: Fine-grained Vulnerability Detectio & def & ~ & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-shen-meng.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Meng Shen and Changyue Li, School of Cyberspace Science and Technology,   Beijing Institute of Technology, China; Qi Li, Institute for Network Sciences and  Cyberspace, Tsinghua University, China; Hao & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-shimmi.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.VulSim: Leveraging Similarity of Multi-Dimensional  Neighbor Embeddings for Vulnerability Detection Samiha Shimmi, Ashiqur Rahman, and Mohan Gadde, Northern Illinois University; & def & ~ & DL & Other & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-song-wei.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Correction-based Defense Against Adversarial & def & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-sun-bing.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Neural Network Semantic Backdoor Detection   and Mitigation: A Causality-Based Approach Bing Sun, Jun Sun, and Wayne Koh, Singapore Management University;   Jie Shi, Huawei Sing & def & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-tan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Defending Against Data Reconstruction Attacks in  Federated Learning: An Information Theory Approach Qi Tan, Department of Computer Science and Technology, Tsinghua University;  & def & Privacy & DL & Images & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-thirumuruganathan\_1.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open access to the Proceedings of the  33rd USENIX Security Symposium   is sponsored by USENIX.Detecting and Mitigating Sampling Bias in  C & def & ~ & Both & Malware & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-tiwari.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Information Flow Control in Machine Learning  through Modular Model Architecture Trishita Tiwari, Cornell University; Suchin Gururangan, University of Washington;  Chuan Guo, FA & def & Privacy & DL & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-wang-jialai.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Detection by Assessing and Deprioritizing   Control Flow Graph Features Jialai Wang, Tsinghua University; Chao Zhang, Tsinghua University and  Zhongguancun Laboratory; Longfei Chen and Yi Rong, Tsingh & def & ~ & Both & Malware & YES & YES & NO & White-box & Full & NO & Low & Low & 0 & 0 & 1 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-wang-kun.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Plug-and-play Adversarial Example   Detection Method for Speaker Recognition Kun Wang, Zhejiang University; Xiangyu Xu, Southeast University;   Li Lu, Zhongjie Ba, Feng Lin, and Kui Ren, Zhejiang Univ & def & Evasion & DL & Audio & YES & NO & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 1 & 1 & 5 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-xu-dandan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Learning on Counterexamples Dandan Xu, SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences,  China, and School of Cyber Security, University of Chinese Academy of Sciences, China & def & Evasion & Both & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-xu-zhangchen.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.ACE: A Model Poisoning Attack on Contribution  Evaluation Methods in Federated Learning Zhangchen Xu, Fengqing Jiang, and Luyao Niu, University of Washington;   Jinyuan Jia, Pen & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-xu-zhibo.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.OblivGNN: Oblivious Inference on Transductive  and Inductive Graph Neural Network Zhibo Xu, Monash University and CSIROâ€™s Data61; Shangqi Lai, CSIROâ€™s Data61;  Xiaoning Liu, RMI & def & Privacy & DL & Other & YES & NO & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 1 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-yan.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & on Code Completion Models: Injecting Disguised  Vulnerabilities against Strong Detection Shenao Yan, University of Connecticut; Shen Wang and Yue Duan,  Singapore Management University; Hanbin Hong, U & atk & Poisoning & DL & Other & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-yu-jiahao.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.LLM-Fuzzer: Scaling Assessment of   Large Language Model Jailbreaks Jiahao Yu, Northwestern University; Xingwei Lin, Ant Group;   Zheng Yu and Xinyu Xing, Northwestern Universit & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhang-qingzhao.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Perception: Attacks and Countermeasures Qingzhao Zhang, Shuowei Jin, Ruiyang Zhu, Jiachen Sun, and Xumiao Zhang,  University of Michigan; Qi Alfred Chen, University of California, Irvine;   Z. Morley  & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhang-rui.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.Instruction Backdoor Attacks Against   Customized LLMs Rui Zhang and Hongwei Li, University of Electronic Science and Technology of  China; Rui Wen, CISPA Helmholtz Center for I & atk & Poisoning & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & High & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhang-ruisi.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Framework for Generative Large Language Models Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara,  and Farinaz Koushanfar, University of California, San Diego https://www.usenix.org/conference/us & def & ~ & DL & Text & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhang-tingwei.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & 33rd USENIX Security Symposium   is sponsored by USENIX.Adversarial Illusions in Multi-Modal Embeddings Tingwei Zhang and Rishi Jha, Cornell University; Eugene Bagdasaryan,   University of Massachuset & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zheng.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & on Monocular Depth Estimation with  Perspective Hijacking Tianyue Zheng, Southern University of Science and Technology; Jingzhi Hu and  Rui Tan, Nanyang Technological University; Yinqian Zhang, Southe & atk & Evasion & DL & Images & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhu-chang.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & is sponsored by USENIX.TyGr: Type Inference on Stripped Binaries   using Graph Neural Networks Chang Zhu, Arizona State University; Ziyang Li and Anton Xue, University of  Pennsylvania; Ati Priya Baja & def & ~ & DL & Malware & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24-zhu-shenchen.pdf & This paper is included in the Proceedings of the  33rd USENIX Security Symposium. August 14â€“16, 2024 â€¢ Philadelphia, PA, USA 978-1-939133-44-1 Open ac & Detectors via Object Reconstruction Shenchen Zhu, Institute of Information Engineering, Chinese Academy of Sciences,  China; School of Cyber Security, University of Chinese Academy of Sciences, China; & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24\_slides-guo-keyan.pdf & Moderating Illicit Online Image Promotion for Unsafe User Generated Content Games Using large Vision-Language ModelsKeyan Guo*, Ayush Utkarsh*, WenboD & ~ & def & ~ & DL & Images & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24\_slides-ling.pdf & usenixsecurity24\_slides-ling & ~ & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2024 & USENIX & usenixsecurity24\_slides-noorbakhsh.pdf & Inf2Guard: An Information -Theoretic Framework for  Learning Privacy -Preserving Representations against  Inference Attacks ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½, & Inference Attacks ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½,âˆ—,ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â„Žï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½â„Žï¿½ï¿½ï¿½ï¿½ï¿½ï¿½1,âˆ—,ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½2,ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â„Žï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½1 & def & Privacy & DL & Images & YES & NO & NO & Gray-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 1 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2403.02817v2.pdf & Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications Stav Cohen1, Ron Bitton2, and Ben Nassi1 1Technion - Israel & 1Technion - Israel Institute of Technology, Haifa, Israel 2Intuit, Petach-Tikva, Israel cohnstav@campus.technion.ac.il, ron\_bitton@intuit.com, nassiben@technion.ac.il https://sites .google .com/view/c & atk & Evasion & DL & Text & YES & YES & NO & Black-box & ~ & NO & High & Low & 0 & 1 & 0 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2406.05810v1.pdf & ControlLoc: Physical-World Hijacking Attack on Visual Perception in Autonomous Driving Chen Maâ‹†,â€ Ningfei Wangâ‹†,â€¡Zhengyu Zhaoâ€ Qian WangÂ¶Qi Alfred Chenâ€¡ & in Autonomous Driving Chen Maâ‹†,â€ Ningfei Wangâ‹†,â€¡Zhengyu Zhaoâ€ Qian WangÂ¶Qi Alfred Chenâ€¡Chao Shenâ€  â€ Xiâ€™an Jiaotong Universityâ€¡University of California, IrvineÂ¶Wuhan University Abstract â€”Recent research i & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2501.05928v2.pdf & arXiv:2501.05928v2  [cs.CR]  24 Jun 2025Towards Backdoor Stealthiness in Model Parameter Space Xiaoyun Xu Radboud University Nijmegen, The Netherlands & arXiv:2501.05928v2  [cs.CR]  24 Jun 2025Towards Backdoor Stealthiness in Model Parameter Space Xiaoyun Xu Radboud University Nijmegen, The Netherlands xiaoyun.xu@ru.nlZhuoran Liuâˆ— & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2501.06533v2.pdf & arXiv:2501.06533v2  [cs.CV]  24 Jun 2025DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition against Dynamic FR Strategy Wensh & Anti-Facial Recognition against Dynamic FR Strategy Wenshu Fanâˆ— University of Electronic Science and Technology of China fws@std.uestc.edu.cnMinxing Zhangâˆ— & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2504.15942v1.pdf & Adversarial Observations in Weather Forecasting Erik Imgrund BIFOLD \& TU Berlin GermanyThorsten Eisenhofer BIFOLD \& TU Berlin GermanyKonrad Rieck BIFO & BIFOLD \& TU Berlin GermanyThorsten Eisenhofer BIFOLD \& TU Berlin GermanyKonrad Rieck BIFOLD \& TU Berlin Germany & atk & Evasion & DL & Other & YES & YES & NO & White-box & Full & YES & High & High & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2505.19840v2.pdf & One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP Binyan Xu The Chinese University of Hong Kong Hong & Targeted Adversarial Attacks with CLIP Binyan Xu The Chinese University of Hong Kong Hong Kong, Hong Kong binyxu@ie.cuhk.edu.hkXilin Dai & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2505.24842v2.pdf & Cascading Adversarial Bias from Injection to Distillation in Language Models Harsh Chaudhariâ€  Northeastern University Boston, USAJamie Hayesâˆ— Google D & Language Models Harsh Chaudhariâ€  Northeastern University Boston, USAJamie Hayesâˆ— Google Deepmind & atk & Poisoning & DL & Text & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2506.05402v1.pdf & arXiv:2506.05402v1  [cs.CR]  4 Jun 2025Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning Tianyu Qi & Models via Collaborative Fine-tuning Tianyu Qi Sun Yat-sen University Shenzhen, China qity9@mail2.sysu.edu.cnLei Xue & def & Evasion & DL & Images & YES & NO & YES & Gray-box & Partial & YES & High & High & 1 & 1 & 0 & 0 & 1 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2506.21874v1.pdf & arXiv:2506.21874v1  [cs.CR]  27 Jun 2025On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling Stanley Wu University of C & Adversarial Mislabeling Stanley Wu University of Chicago Chicago, IL, USA stanleywu@cs.uchicago.eduRonik Bhaskar & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2509.06071v1.pdf & Asymmetry Vulnerability and Physical Attacks on Online Map Construction for Autonomous Driving Yang Lou* City University of Hong Kong Hong Kong, China & Construction for Autonomous Driving Yang Lou* City University of Hong Kong Hong Kong, China yanglou3-c@my.cityu.edu.hkHaibo Hu* & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2509.11745v3.pdf & Removal Attack and Defense on AI-generated Content Latent-based Watermarking De Zhang Lee National University of Singapore Singapore dezhanglee@comp.n & Latent-based Watermarking De Zhang Lee National University of Singapore Singapore dezhanglee@comp.nus.edu.sgHan Fangâˆ— & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2509.15499v1.pdf & Adversarially Robust Assembly Language Model for Packed Executables Detection Shijia Li China Electronics Corporation; Nankai University Shenzhen, Gua & Shijia Li China Electronics Corporation; Nankai University Shenzhen, Guangdong, China lishijia@cec.com.cnJiang Ming & def & Evasion & DL & Malware & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & 2510.01676v1.pdf & Evaluating the Robustness of a Production Malware Detection System to Transferable Adversarial Attacks Milad Nasr1â€ , Yanick Fratantonio2, Luca Inverni & Milad Nasr1â€ , Yanick Fratantonio2, Luca Invernizzi2, Ange Albertini2, Loua Farah2, Alex Petit-Bianco2, Andreas Terzisr1, Kurt Thomas2, Elie Bursztein2, Nicholas Carlini1â€¡ 1Google DeepMind2Google Abstr & atk & Evasion & DL & Malware & YES & YES & YES & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 0 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & VNET.pdf & VillainNet: Targeted Poisoning Attacks Against SuperNets Along the Accuracy-Latency Pareto Frontier Anonymous Author(s) ABSTRACT State-of-the-art (SOT & VillainNet: Targeted Poisoning Attacks Against SuperNets Along the Accuracy-Latency Pareto Frontier Anonymous Author(s) ABSTRACT State-of-the-art (SOTA) weight-shared SuperNets dynamically & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & ACM & ccs25.pdf & Deep Learning from Imperfectly Labeled Malware Data Fahad Alotaibi f.alotaibi21@imperial.ac.uk Department of Computing Imperial College London London, & Deep Learning from Imperfectly Labeled Malware Data Fahad Alotaibi f.alotaibi21@imperial.ac.uk Department of Computing Imperial College London & def & ~ & DL & Malware & YES & YES & NO & Black-box & ~ & NO & ~ & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-18-zhou.pdf & DORMANT : Defending against Pose-driven Human Image Animation Jiachen Zhou1,2, Mingsi Wang1,2, Tianlin Li3, Guozhu Meng1,2,âˆ—, Kai Chen1,2,âˆ— 1Institute & Jiachen Zhou1,2, Mingsi Wang1,2, Tianlin Li3, Guozhu Meng1,2,âˆ—, Kai Chen1,2,âˆ— 1Institute of Information Engineering, Chinese Academy of Sciences, China 2School of Cyber Security, University of Chinese & def & Evasion & DL & Images & YES & YES & YES & Black-box & ~ & YES & High & High & 1 & 1 & 0 & 0 & 0 & 0 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-341-zhang-shenyi.pdf & JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation Shenyi Zhang1, Yuchen Zhai1, Keya & Lingchen Zhao1, Chao Shen3, Cong Wang4, and Qian Wang1âˆ— 1Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan U & def & Evasion & DL & Text & YES & YES & NO & White-box & Full & NO & Low & Low & 0 & 0 & 1 & 0 & 0 & 1 & 2 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-389-lin-chenhao.pdf & Revisiting Training-Inference Trigger Intensity in Backdoor Attacks Chenhao Lin, Chenyang Zhao, Shiwei Wang, Longtian Wang, Chao Shen, Zhengyu Zhaoâˆ— X & Revisiting Training-Inference Trigger Intensity in Backdoor Attacks Chenhao Lin, Chenyang Zhao, Shiwei Wang, Longtian Wang, Chao Shen, Zhengyu Zhaoâˆ— Xiâ€™an Jiaotong University Abstract Backdoor attacks & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-402-zhang-zhisheng.pdf & SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis Zhisheng Zhang1,Derui Wang2, Qianyi Yang1, Pengyang Huang1, Junh & Zhisheng Zhang1,Derui Wang2, Qianyi Yang1, Pengyang Huang1, Junhan Pu1,Yuxin Cao3,Kai Ye4,Jie Hao1, and Yixian Yang1 1Beijing University of Posts and Telecommunications2CSIROâ€™s Data61 3National Univ & def & Privacy & DL & Audio & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-510-li-jiate.pdf & AGNNCert : Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification Jiate Li1, Binghui Wang1,âˆ— 1Illinois Insti & with Deterministic Certification Jiate Li1, Binghui Wang1,âˆ— 1Illinois Institute of Technology,âˆ—Corresponding Author Abstract Graph neural networks (GNNs) achieve the state-of-the-art & def & Evasion & DL & Other & YES & YES & NO & White-box & Full & NO & High & Low & 0 & 1 & 1 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-670-guo-zhen.pdf & Persistent Backdoor Attacks in Continual Learning Zhen Guo Saint Louis University zhen.guo.2@slu.eduAbhinav Kumar Saint Louis University abhinav.kumar & Persistent Backdoor Attacks in Continual Learning Zhen Guo Saint Louis University zhen.guo.2@slu.eduAbhinav Kumar Saint Louis University & atk & Poisoning & DL & Images & YES & YES & NO & White-box & ~ & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & sec25cycle1-prepub-702-wang-lijin.pdf & From Purity to Peril: Backdooring Merged Models From â€œHarmlessâ€ Benign Components Lijin Wang1, Jingjing Wang2, Tianshuo Cong3â‡¤, Xinlei He1â‡¤, Zhan Qin2 & Benign Components Lijin Wang1, Jingjing Wang2, Tianshuo Cong3â‡¤, Xinlei He1â‡¤, Zhan Qin2, and Xinyi Huang4 1The Hong Kong University of Science and Technology (Guangzhou) 2Zhejiang University,3Tsinghua  & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-foerster.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.LightShed: Defeating Perturbation-based   Image Copyright Protections Hanna Foerster, University of Cambridge; Sasha Behrouzi and Phillip Rieger,  & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-kobayashi.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.Invisible but Detected: Physical Adversarial Shadow  Attack and Defense on LiDAR Object Detection Ryunosuke Kobayashi, Waseda University; Kazuki N & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-li-changjiang.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.Watch the Watchers! On the Security Risks   of Robustness-Enhancing Diffusion Models Changjiang Li, Stony Brook University; Ren Pang, Bochuan Cao, & atk & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-pang-xiaoyi.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & Byzantine-resilient Semi-asynchronous Federated Learning Xiaoyi Pang, The State Key Laboratory of Blockchain and Data Security, Zhejiang  University; Hangzhou High-Tech Zone ( Binjiang ) Institute of  & atk & Poisoning & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-popovic.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & Deep Models with Limited Data Dorde Popovic and Amin Sadeghi, Qatar Computing Research Institute,   Hamad Bin Khalifa University; Ting Yu, Mohamed bin Zayed University of   Artificial Intelligence; Sa & def & Poisoning & DL & Images & YES & YES & NO & Black-box & ~ & NO & Low & Low & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-sun-zekun.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.Pretender: Universal Active Defense against  Diffusion Finetuning Attacks Zekun Sun and Zijian Liu, Shanghai Jiao Tong University;   Shouling Ji,  & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-wang-derui.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & Derui Wang, Kristen Moore, Diksha Goel, and Minjune Kim, CSIROâ€™s Data61 and  Cyber Security Cooperative Research Centre; Gang Li, Yang Li, and Robin Doss,  Deakin University; Minhui Xue, CSIROâ€™s Data6 & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-yang-yuchen.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.CertPHasH: Towards Certified Perceptual Hashing   via Robust Training Yuchen Yang and Qichang Liu, The Johns Hopkins University; Christopher Brix, & def & Evasion & DL & Images & YES & YES & NO & White-box & Full & YES & High & Low & 1 & 1 & 1 & 0 & 0 & 1 & 4 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
        2025 & USENIX & usenixsecurity25-zhang-yinyuan.pdf & This paper is included in the Proceedings of the  34th USENIX Security Symposium. August 13â€“15, 2025 â€¢ Seattle, WA, USA 978-1-939133-52-6 Open access  & 34th USENIX Security Symposium is sponsored by USENIX.Fighting Fire with Fire: Continuous Attack for  Adversarial Android Malware Detection Yinyuan Zhang, School of Computer Science, Peking University & def & Evasion & DL & Malware & YES & YES & NO & Black-box & ~ & YES & High & Low & 1 & 1 & 0 & 0 & 0 & 1 & 3 & ~ & ~ & ~ & ~ & ~ & ~ & ~ & ~ \\ \hline
    \end{tabular}
\end{table}\end{document}
