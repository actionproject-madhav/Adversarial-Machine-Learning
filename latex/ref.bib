% =============================================================================
% REFERENCES FOR ADVERSARIAL ML LITERATURE REVIEW
% All citations extracted from the four conference literature reviews
% =============================================================================

% -----------------------------------------------------------------------------
% INTRODUCTION CONTEXT REFERENCES
% -----------------------------------------------------------------------------

@techreport{grother2019frvt,
  title        = {Face Recognition Vendor Test (FRVT) Part 3: Demographic Effects},
  author       = {Grother, Patrick and Ngan, Mei and Hanaoka, Kayee},
  institution  = {National Institute of Standards and Technology},
  number       = {NISTIR 8280},
  year         = {2019}
}

@article{dalpozzo2014fraud,
  title   = {Learned Lessons in Credit Card Fraud Detection from a Practitioner Perspective},
  author  = {Dal Pozzolo, Andrea and Caelen, Olivier and Johnson, Reid A and Bontempi, Gianluca},
  journal = {Expert Systems with Applications},
  volume  = {41},
  number  = {10},
  pages   = {4915--4928},
  year    = {2014}
}

@article{bojarski2016endtoend,
  title   = {End to End Learning for Self-Driving Cars},
  author  = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal = {arXiv preprint arXiv:1604.07316},
  year    = {2016}
}

@book{gillespie2018custodians,
  title     = {Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions that Shape Social Media},
  author    = {Gillespie, Tarleton},
  publisher = {Yale University Press},
  year      = {2018}
}

@article{biggio2018wild,
  title   = {Wild Patterns: Ten Years after the Rise of Adversarial Machine Learning},
  author  = {Biggio, Battista and Roli, Fabio},
  journal = {Pattern Recognition},
  volume  = {84},
  pages   = {317--331},
  year    = {2018}
}

@inproceedings{papernot2016sok,
  title     = {{SoK}: Security and Privacy in Machine Learning},
  author    = {Papernot, Nicolas and McDaniel, Patrick and Sinha, Arunesh and Wellman, Michael P},
  booktitle = {IEEE European Symposium on Security and Privacy},
  pages     = {399--414},
  year      = {2016}
}

@inproceedings{szegedy2014intriguing,
  title     = {Intriguing Properties of Neural Networks},
  author    = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  booktitle = {International Conference on Learning Representations},
  year      = {2014}
}

@inproceedings{goodfellow2015explaining,
  title     = {Explaining and Harnessing Adversarial Examples},
  author    = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle = {International Conference on Learning Representations},
  year      = {2015}
}

@inproceedings{biggio2012poisoning,
  title     = {Poisoning Attacks against Support Vector Machines},
  author    = {Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
  booktitle = {International Conference on Machine Learning},
  pages     = {1467--1474},
  year      = {2012}
}

@article{gu2017badnets,
  title   = {{BadNets}: Identifying Vulnerabilities in the Machine Learning Model Supply Chain},
  author  = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal = {arXiv preprint arXiv:1708.06733},
  year    = {2017}
}

@inproceedings{shokri2017membership,
  title     = {Membership Inference Attacks against Machine Learning Models},
  author    = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle = {IEEE Symposium on Security and Privacy},
  pages     = {3--18},
  year      = {2017}
}

@inproceedings{carlini2021extracting,
  title     = {Extracting Training Data from Large Language Models},
  author    = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
  booktitle = {USENIX Security Symposium},
  pages     = {2633--2650},
  year      = {2021}
}

@inproceedings{madry2018towards,
  title     = {Towards Deep Learning Models Resistant to Adversarial Attacks},
  author    = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}

@inproceedings{cohen2019certified,
  title     = {Certified Adversarial Robustness via Randomized Smoothing},
  author    = {Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico},
  booktitle = {International Conference on Machine Learning},
  pages     = {1310--1320},
  year      = {2019}
}

@misc{anthropic2025espionage,
  title        = {Disrupting the First Reported {AI}-Orchestrated Cyber Espionage Campaign},
  author       = {{Anthropic}},
  howpublished = {\url{https://www.anthropic.com/research/disrupting-the-first-reported-ai-orchestrated-cyber-espionage-campaign}},
  year         = {2025},
  note         = {Anthropic Research Blog}
}

@misc{anthropic2024mcp,
  title        = {Model Context Protocol},
  author       = {{Anthropic}},
  howpublished = {\url{https://modelcontextprotocol.io}},
  year         = {2024}
}

@inproceedings{wei2024jailbroken,
  title     = {Jailbroken: How Does {LLM} Safety Training Fail?},
  author    = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2024}
}

@inproceedings{gilmer2018notdetection,
  title     = {Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
  author    = {Gilmer, Justin and Adams, Ryan P and Goodfellow, Ian and Andersen, David and Dahl, George E},
  booktitle = {Proceedings of the 10th {ACM} Workshop on Artificial Intelligence and Security},
  pages     = {3--14},
  year      = {2018}
}

@inproceedings{kurakin2018physical,
  title     = {Adversarial Examples in the Physical World},
  author    = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  booktitle = {International Conference on Learning Representations},
  year      = {2018}
}

@misc{guardian2024deepfake,
  title        = {Finance Worker Pays Out \$25 Million after Video Call with Deepfake ``Chief Financial Officer''},
  author       = {{The Guardian}},
  howpublished = {\url{https://www.theguardian.com/}},
  year         = {2024},
  note         = {News article}
}

@inproceedings{mink2023barriers,
  title     = {{``Security is Not My Field, I'm a Stats Guy''}: A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry},
  author    = {Mink, Jaron and others},
  booktitle = {Proceedings of the 32nd {USENIX} Security Symposium},
  year      = {2023}
}

@inproceedings{kumar2020adversarial,
  title     = {Adversarial Machine Learning -- Industry Perspectives},
  author    = {Kumar, Ram Shankar Siva and Nystr{\"o}m, Magnus and Lambert, John and Marshall, Andrew and Goertzel, Mario and Comissoneru, Andi and Swann, Matt and Xia, Sharon},
  booktitle = {IEEE Security and Privacy Workshops},
  pages     = {69--75},
  year      = {2020}
}

@inproceedings{grosse2024threatmodels,
  title     = {Towards More Practical Threat Models in Artificial Intelligence Security},
  author    = {Grosse, Kathrin and Bieringer, Lukas and Besold, Tarek R and Hu, Hongxin},
  booktitle = {Proceedings of the 33rd {USENIX} Security Symposium},
  year      = {2024}
}

@techreport{eu2021aiact,
  title        = {Proposal for a Regulation on a European Approach for Artificial Intelligence},
  author       = {{European Commission}},
  number       = {COM(2021) 206 final},
  institution  = {European Commission},
  year         = {2021}
}

@inproceedings{arp2022dosdonts,
  title     = {Dos and Don'ts of Machine Learning in Computer Security},
  author    = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
  booktitle = {Proceedings of the 31st {USENIX} Security Symposium},
  year      = {2022}
}

@inproceedings{carlini2019evaluating,
  title     = {On Evaluating Adversarial Robustness},
  author    = {Carlini, Nicholas and Athalye, Anish and Papernot, Nicolas and Brendel, Wieland and Rauber, Jonas and Tsipras, Dimitris and Goodfellow, Ian and Madry, Aleksander and Kurakin, Alexey},
  booktitle = {arXiv preprint arXiv:1902.06705},
  year      = {2019}
}

@inproceedings{papernot2017practical,
  title     = {Practical Black-Box Attacks against Machine Learning},
  author    = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle = {{ACM} Asia Conference on Computer and Communications Security},
  pages     = {506--519},
  year      = {2017}
}

@inproceedings{chen2017zoo,
  title     = {{ZOO}: Zeroth Order Optimization Based Black-Box Attacks to Deep Neural Networks without Training Substitute Models},
  author    = {Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle = {Proceedings of the 10th {ACM} Workshop on Artificial Intelligence and Security},
  pages     = {15--26},
  year      = {2017}
}

@inproceedings{juuti2019prada,
  title     = {{PRADA}: Protecting against {DNN} Model Stealing Attacks},
  author    = {Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N},
  booktitle = {IEEE European Symposium on Security and Privacy},
  pages     = {512--527},
  year      = {2019}
}

@inproceedings{sculley2015debt,
  title     = {Hidden Technical Debt in Machine Learning Systems},
  author    = {Sculley, David and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Francois and Dennison, Dan},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {2503--2511},
  year      = {2015}
}

@inproceedings{bender2021stochasticparrots,
  title     = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author    = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle = {Proceedings of the 2021 {ACM} Conference on Fairness, Accountability, and Transparency},
  pages     = {610--623},
  year      = {2021}
}

@inproceedings{herley2014science,
  title     = {{SoK}: Science, Security and the Elusive Goal of Security as a Scientific Pursuit},
  author    = {Herley, Cormac and Van Oorschot, Paul C},
  booktitle = {IEEE Symposium on Security and Privacy},
  pages     = {99--120},
  year      = {2014}
}

@article{pineau2021reproducibility,
  title   = {Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)},
  author  = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Larivi{\`e}re, Vincent and Beygelzimer, Alina and d'Alch{\'e}-Buc, Florence and Fox, Emily and Larochelle, Hugo},
  journal = {Journal of Machine Learning Research},
  volume  = {22},
  number  = {164},
  pages   = {1--20},
  year    = {2021}
}

@inproceedings{tao2023patchattack,
  title     = {Hard-Label Black-Box Universal Adversarial Patch Attack},
  author    = {Tao, Guanhong and others},
  booktitle = {Proceedings of the 32nd {USENIX} Security Symposium},
  year      = {2023}
}

@inproceedings{eykholt2023uret,
  title     = {{URET}: Universal Robustness Evaluation Toolkit (for Evasion)},
  author    = {Eykholt, Kevin and others},
  booktitle = {Proceedings of the 32nd {USENIX} Security Symposium},
  year      = {2023}
}

@inproceedings{zou2023universal,
  title     = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author    = {Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {36},
  year      = {2023}
}

@inproceedings{liu2024promptinjection,
  title     = {Formalizing and Benchmarking Prompt Injection Attacks and Defenses},
  author    = {Liu, Yupei and Jia, Jinyuan and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  booktitle = {{USENIX} Security Symposium},
  year      = {2024}
}

@inproceedings{wallace2019triggers,
  title     = {Universal Adversarial Triggers for Attacking and Analyzing {NLP}},
  author    = {Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  pages     = {2153--2162},
  year      = {2019}
}

@inproceedings{carlini2018audio,
  title     = {Audio Adversarial Examples: Targeted Attacks on Speech-to-Text},
  author    = {Carlini, Nicholas and Wagner, David},
  booktitle = {IEEE Security and Privacy Workshops},
  pages     = {1--7},
  year      = {2018}
}

@inproceedings{chen2023obsan,
  title     = {{OBSAN}: An Out-of-Bound Sanitizer to Harden {DNN} Executables},
  author    = {Chen, Yanzuo and others},
  booktitle = {Proceedings of the 32nd {USENIX} Security Symposium},
  year      = {2023}
}

@article{bommasani2021foundation,
  title   = {On the Opportunities and Risks of Foundation Models},
  author  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal = {arXiv preprint arXiv:2108.07258},
  year    = {2021}
}

@article{wang2024agents,
  title   = {A Survey on Large Language Model Based Autonomous Agents},
  author  = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal = {Frontiers of Computer Science},
  volume  = {18},
  number  = {6},
  pages   = {1--26},
  year    = {2024}
}

@inproceedings{qi2024visual,
  title     = {Visual Adversarial Examples Jailbreak Aligned Large Language Models},
  author    = {Qi, Xiangyu and Zeng, Kaixuan and Xie, Tinghao and Chen, Pin-Yu and Henderson, Peter and Fredrikson, Matt and Zhu, Siheng},
  booktitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  volume    = {38},
  pages     = {21527--21536},
  year      = {2024}
}
% -----------------------------------------------------------------------------
% PRIMARY SOURCE
% -----------------------------------------------------------------------------
@article{apruzzese2022real,
  title={``Real Attackers Don't Compute Gradients'': Bridging the Gap Between Adversarial ML Research and Practice},
  author={Apruzzese, Giovanni and Anderson, Hyrum S and Dambra, Savino and Freeman, David and Pierazzi, Fabio and Roundy, Kevin A},
  journal={arXiv preprint arXiv:2212.14315},
  year={2022}
}

% -----------------------------------------------------------------------------
% USENIX SECURITY PAPERS
% -----------------------------------------------------------------------------
@inproceedings{ahmed2022keyword,
  title={Towards More Robust Keyword Spotting for Voice Assistants},
  author={Ahmed, Shimaa and Shumailov, Ilia and Papernot, Nicolas and Fawaz, Kassem},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{ahmed2023tubes,
  title={Tubes Among Us: Analog Attack on Automatic Speaker Identification},
  author={Ahmed, Shimaa and others},
  booktitle={Proceedings of the 32nd USENIX Security Symposium},
  year={2023}
}

@inproceedings{arp2022dos,
  title={Dos and Don'ts of Machine Learning in Computer Security},
  author={Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{cao2023lidar,
  title={You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks},
  author={Cao, Yulong and others},
  booktitle={Proceedings of the 32nd USENIX Security Symposium},
  year={2023}
}

@inproceedings{debenedetti2024privacy,
  title={Privacy Side Channels in Machine Learning Systems},
  author={Debenedetti, Edoardo and others},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{dentan2024cdmi,
  title={Reconstructing Training Data from Document Understanding Models},
  author={Dentan, Julien and others},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{duan2022perception,
  title={Perception-Aware Attack: Creating Adversarial Music via Reverse Engineering},
  author={Duan, Rui and others},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{ge2024cleansheet,
  title={Hijacking Attacks against Neural Network by Analyzing Training Data},
  author={Ge, Yunjie and others},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{grosse2024practical,
  title={Towards More Practical Threat Models in Artificial Intelligence Security},
  author={Grosse, Kathrin and Bieringer, Lukas and Besold, Tarek R and Hu, Hongxin},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{guo2025persistent,
  title={Persistent Backdoor Attacks in Continual Learning},
  author={Guo, Zhen and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{hallyburton2022frustum,
  title={Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles},
  author={Hallyburton, R Spencer and Liu, Yupei and Cao, Yulong and Mao, Z Morley and Pajic, Miroslav},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{kobayashi2025shadow,
  title={Invisible but Detected: Physical Adversarial Shadow Attack and Defense on LiDAR Object Detection},
  author={Kobayashi, Ryunosuke and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{layton2024sok,
  title={{SoK}: The Good, The Bad, and The Unbalanced: Measuring Structural Limitations of Deepfake Media Datasets},
  author={Layton, Samuel and Tucker, Tyler and Olszewski, Dominik and Warren, Kevin and Butler, Kevin and Traynor, Patrick},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{li2022blacklight,
  title={Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks},
  author={Li, Huiying and Shan, Shawn and Wenger, Emily and Zhang, Jiayun and Zheng, Haitao and Zhao, Ben Y},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{li2024mist,
  title={{MIST}: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training},
  author={Li, Jiacheng and others},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{liu2022poisonedencoder,
  title={{PoisonedEncoder}: Poisoning the Unlabeled Pre-training Data in Contrastive Learning},
  author={Liu, Hongbin and Jia, Jinyuan and Gong, Neil Zhenqiang},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{liu2022mldoctor,
  title={{ML-Doctor}: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models},
  author={Liu, Yugeng and Wen, Rui and He, Xinlei and Salem, Ahmed and Zhang, Zheng and Backes, Michael and De Cristofaro, Emiliano and Fritz, Mario and Zhang, Yang},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{liu2023xadv,
  title={{X-Adv}: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection},
  author={Liu, Siyuan and others},
  booktitle={Proceedings of the 32nd USENIX Security Symposium},
  year={2023}
}

@inproceedings{liu2024jailbreaking,
  title={Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction},
  author={Liu, Haoyu and Zhang, Yuxuan and Zhao, Zihan and Dong, Yunjie and Meng, Guozhu and Chen, Kai},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{lyu2024pfl,
  title={Lurking in the Shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning},
  author={Lyu, Xiaoting and others},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{nayan2024sok,
  title={{SoK}: All You Need to Know About On-Device {ML} Model Extraction - The Gap Between Research and Practice},
  author={Nayan, Tanvir and Guo, Qian and Al Duniawi, Mohammed and Botacin, Marcus and Uluagac, Selcuk and Sun, Ruimin},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{popovic2025debackdoor,
  title={{DeBackdoor}: A Deductive Framework for Detecting Backdoor Attacks on Deep Models with Limited Data},
  author={Popovic, Dusan and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{ren2024rdma,
  title={Accelerating Secure Collaborative Machine Learning with Protocol-Aware {RDMA}},
  author={Ren, Zhenghao and Fan, Mingxuan and Wang, Zilong and Zhang, Junxue and Zeng, Chaoliang and Huang, Zhicong and Hong, Cheng and Chen, Kai},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{risse2024vulnerability,
  title={Uncovering the Limits of Machine Learning for Automatic Vulnerability Detection},
  author={Risse, Niklas and B{\"o}hme, Marcel},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{tang2022membership,
  title={Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture},
  author={Tang, Xinyu and Mahloujifar, Saeed and Song, Liwei and Shejwalkar, Virat and Nasr, Milad and Houmansadr, Amir and Mittal, Prateek},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{tao2023hardbeat,
  title={Hard-label Black-box Universal Adversarial Patch Attack},
  author={Tao, Guanhong and others},
  booktitle={Proceedings of the 32nd USENIX Security Symposium},
  year={2023}
}

@inproceedings{wang2025camp,
  title={{CAMP} in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization},
  author={Wang, Dingwen and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{wang2025mergebackdoor,
  title={From Purity to Peril: Backdooring Merged Models From ``Harmless'' Benign Components},
  author={Wang, Lu and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{xiang2022patchcleanser,
  title={{PatchCleanser}: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier},
  author={Xiang, Chong and Mahloujifar, Saeed and Mittal, Prateek},
  booktitle={Proceedings of the 31st USENIX Security Symposium},
  year={2022}
}

@inproceedings{xiang2024patchcure,
  title={{PATCHCURE}: Improving Certifiable Robustness, Model Utility, and Computation Efficiency of Adversarial Patch Defenses},
  author={Xiang, Chong and Wu, Tong and Dai, Sihui and Petit, Jonathan and Jana, Suman and Mittal, Prateek},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{yang2025certphash,
  title={{CertPHasH}: Towards Certified Perceptual Hashing via Robust Training},
  author={Yang, Yizheng and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{yu2024jailbreak,
  title={Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models},
  author={Yu, Zhiyuan and Liu, Xiaogeng and Liang, Shunning and Cameron, Zach and Xiao, Chaowei and Zhang, Ning},
  booktitle={Proceedings of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{yue2023gradient,
  title={Gradient Obfuscation Gives a False Sense of Security in Federated Learning},
  author={Yue, Lun and others},
  booktitle={Proceedings of the 32nd USENIX Security Symposium},
  year={2023}
}

@inproceedings{zhang2025jbshield,
  title={{JBShield}: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation},
  author={Zhang, Shenyi and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{zhang2025atkscopes,
  title={{ATKSCOPES}: Multiresolution Adversarial Perturbation as a Unified Attack on Perceptual Hashing and Beyond},
  author={Zhang, Yizheng and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

@inproceedings{zhang2025safespeech,
  title={{SafeSpeech}: Robust and Universal Voice Protection Against Malicious Speech Synthesis},
  author={Zhang, Zhiyuan and others},
  booktitle={Proceedings of the 34th USENIX Security Symposium},
  year={2025}
}

% -----------------------------------------------------------------------------
% ACM CCS PAPERS
% -----------------------------------------------------------------------------
@inproceedings{calzavara2023verification,
  title={Verification of Machine Learning Based Cyber-Physical Systems: A Comparative Study},
  author={Calzavara, Stefano and others},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  year={2023}
}

@inproceedings{cong2022sslguard,
  title={{SSLGuard}: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders},
  author={Cong, Tianshuo and others},
  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  year={2022}
}

@inproceedings{li2023advdroiadzero,
  title={{AdvDroidZero}: A Zero-Knowledge Android Malware Detection Framework via Adversarial Learning},
  author={Li, Yuwei and others},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  year={2023}
}

@inproceedings{lu2024neural,
  title={Neural Dehydration: Effective Erasure of Black-box Watermarks from {DNNs} with Limited Data},
  author={Lu, Yifan and others},
  booktitle={Proceedings of the 2024 ACM SIGSAC Conference on Computer and Communications Security},
  year={2024}
}

@inproceedings{ma2024avara,
  title={{Avara}: Measuring Human Perception of Adversarial Traffic Sign Examples Using Virtual and Augmented Reality},
  author={Ma, Yueqi and others},
  booktitle={Proceedings of the 2024 ACM SIGSAC Conference on Computer and Communications Security},
  year={2024}
}

@inproceedings{muller2022attrackzone,
  title={{AttrackZone}: An Attention-guided Backdoor Attack against Deep Reinforcement Learning},
  author={M{\"u}ller, Nicolas and others},
  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  year={2022}
}

@inproceedings{nasr2025magika,
  title={Exploiting Component Vulnerabilities in Production {ML} Pipelines},
  author={Nasr, Milad and others},
  booktitle={Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
  year={2025}
}

@inproceedings{qu2023encoderservice,
  title={Encoder-as-a-Service: Privacy Leakage from Pre-trained Language Model Encoders},
  author={Qu, Yue and others},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  year={2023}
}

@inproceedings{shen2022mnemon,
  title={{MNEMON}: Graph Recovery via Matrix Decomposition and Transformers},
  author={Shen, Yun and others},
  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  year={2022}
}

@inproceedings{shen2024llm,
  title={Dynamic Attention-based Approaches for LLM Robustness},
  author={Shen, Xinyue and others},
  booktitle={Proceedings of the 2024 ACM SIGSAC Conference on Computer and Communications Security},
  year={2024}
}

@inproceedings{xu2025univintruder,
  title={{UnivIntruder}: Universal Black-box Adversarial Examples against Commercial Search Engines},
  author={Xu, Wei and others},
  booktitle={Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
  year={2025}
}

@inproceedings{zeng2023narcissus,
  title={{Narcissus}: A Practical Clean-Label Backdoor Attack with Limited Information},
  author={Zeng, Yi and others},
  booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  year={2023}
}

% -----------------------------------------------------------------------------
% IEEE S&P PAPERS
% -----------------------------------------------------------------------------
@inproceedings{carlini2022membership,
  title={Membership Inference Attacks From First Principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy},
  year={2022}
}

@inproceedings{chaudhari2023snap,
  title={{SNAP}: Efficient Extraction of Private Properties with Poisoning},
  author={Chaudhari, Harsh and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{chaudhari2025distillation,
  title={Knowledge Distillation Amplifies Bias Leakage},
  author={Chaudhari, Harsh and others},
  booktitle={Proceedings of the 2025 IEEE Symposium on Security and Privacy},
  year={2025}
}

@inproceedings{li2023sok,
  title={{SoK}: Certified Robustness for Deep Neural Networks},
  author={Li, Linyi and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{lukas2023pii,
  title={Analyzing Leakage of Personally Identifiable Information in Language Models},
  author={Lukas, Nils and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{naseri2024badvfl,
  title={{BadVFL}: Backdoor Attacks in Vertical Federated Learning},
  author={Naseri, Mohammad and others},
  booktitle={Proceedings of the 2024 IEEE Symposium on Security and Privacy},
  year={2024}
}

@inproceedings{rezaei2023accuracy,
  title={On the Accuracy-Privacy Trade-off of Deep Ensembles},
  author={Rezaei, Shahbaz and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{wan2024bounceattack,
  title={{BounceAttack}: A Query-Efficient Decision-based Black-box Attack},
  author={Wan, Yuying and others},
  booktitle={Proceedings of the 2024 IEEE Symposium on Security and Privacy},
  year={2024}
}

@inproceedings{wenger2023whitebox,
  title={On the Limitations of White-box Assumptions in Adversarial ML},
  author={Wenger, Emily and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{yang2023jigsaw,
  title={Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers},
  author={Yang, Yiming and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{zhao2024loki,
  title={{LOKI}: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation},
  author={Zhao, Joshua and others},
  booktitle={Proceedings of the 2024 IEEE Symposium on Security and Privacy},
  year={2024}
}

% -----------------------------------------------------------------------------
% NDSS PAPERS
% -----------------------------------------------------------------------------
@inproceedings{abdullah2023asr,
  title={{ASR}-based {CAPTCHA} Generation for Voice Security},
  author={Abdullah, Hadi and others},
  booktitle={Proceedings of the 2023 Network and Distributed System Security Symposium},
  year={2023}
}

@inproceedings{chang2023video,
  title={Video Compression as a Defense Against Adversarial Attacks},
  author={Chang, Zhiyuan and others},
  booktitle={Proceedings of the 2023 Network and Distributed System Security Symposium},
  year={2023}
}

@inproceedings{jia2022physical,
  title={Physical Adversarial Attack on Vehicle Detector in the Carla Simulation Environment},
  author={Jia, Yaomin and others},
  booktitle={Proceedings of the 2022 Network and Distributed System Security Symposium},
  year={2022}
}

@inproceedings{kireev2023cost,
  title={On the Robustness of Machine Learning Models Beyond Adversarial Settings},
  author={Kireev, Klim and others},
  booktitle={Proceedings of the 2023 Network and Distributed System Security Symposium},
  year={2023}
}

@inproceedings{krauss2024autoadapt,
  title={{AutoAdapt}: Automated Adaptive Adversary Evaluation},
  author={Krau{\ss}, Philipp and others},
  booktitle={Proceedings of the 2024 Network and Distributed System Security Symposium},
  year={2024}
}

@inproceedings{liu2023distillation,
  title={Dataset Distillation Poisoning: Backdoor Attack against Dataset Compression},
  author={Liu, Yang and others},
  booktitle={Proceedings of the 2023 Network and Distributed System Security Symposium},
  year={2023}
}

@inproceedings{naseri2022dp,
  title={Local and Central Differential Privacy for Robustness and Privacy in Federated Learning},
  author={Naseri, Mohammad and others},
  booktitle={Proceedings of the 2022 Network and Distributed System Security Symposium},
  year={2022}
}

@inproceedings{rieger2022deepsight,
  title={{DeepSight}: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection},
  author={Rieger, Phillip and others},
  booktitle={Proceedings of the 2022 Network and Distributed System Security Symposium},
  year={2022}
}

@inproceedings{wu2023fingerprinting,
  title={On the Limitations of Browser Fingerprinting Datasets},
  author={Wu, Xiaoming and others},
  booktitle={Proceedings of the 2023 Network and Distributed System Security Symposium},
  year={2023}
}

@inproceedings{wu2025vlm,
  title={Vision-Language Model Injection Cascades to Text-to-Image},
  author={Wu, Yiting and others},
  booktitle={Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
  year={2025}
}

% -----------------------------------------------------------------------------
% ADDITIONAL CROSS-VENUE PAPERS
% -----------------------------------------------------------------------------
@inproceedings{hui2024prompt,
  title={Prompt Injection Attacks Against Commercial {LLM} Services},
  author={Hui, Bo and others},
  booktitle={Proceedings of the 2024 ACM SIGSAC Conference on Computer and Communications Security},
  year={2024}
}

@inproceedings{cao2023fedrecover,
  title={{FedRecover}: Recovering from Poisoning Attacks in Federated Learning using Historical Information},
  author={Cao, Xiaoyu and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{stephenson2022arvr,
  title={Authentication in {AR/VR} Environments: Usability and Security Challenges},
  author={Stephenson, Sophie and others},
  booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy},
  year={2022}
}

@inproceedings{cheng2024query,
  title={Query-Efficient Decision-based Adversarial Attacks},
  author={Cheng, Minhao and others},
  booktitle={Proceedings of the 2024 Network and Distributed System Security Symposium},
  year={2024}
}

@inproceedings{wang2023realtime,
  title={Real-time Constraints in Adversarial Attack Optimization},
  author={Wang, Ziyu and others},
  booktitle={Proceedings of the 2023 IEEE Symposium on Security and Privacy},
  year={2023}
}

@inproceedings{deng2022deployment,
  title={Model Deployment Security: From Framework to Production},
  author={Deng, Yingjie and others},
  booktitle={Proceedings of the 2022 USENIX Security Symposium},
  year={2022}
}

@inproceedings{luo2024hardware,
  title={Hardware-Level Constraints in {ML} Security},
  author={Luo, Cong and others},
  booktitle={Proceedings of the 2024 IEEE Symposium on Security and Privacy},
  year={2024}
}

% =============================================================================
% ADDITIONAL REFERENCES FROM BACKGROUND PAPER
% Add these entries to your existing ref.bib file
% =============================================================================

% -----------------------------------------------------------------------------
% FOUNDATIONAL ADVERSARIAL ML PAPERS
% -----------------------------------------------------------------------------
@inproceedings{szegedy2013intriguing,
  title={Intriguing Properties of Neural Networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  booktitle={International Conference on Learning Representations},
  year={2014}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and Harnessing Adversarial Examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{moosavi2016deepfool,
  title={{DeepFool}: A Simple and Accurate Method to Fool Deep Neural Networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards Evaluating the Robustness of Neural Networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={IEEE Symposium on Security and Privacy},
  pages={39--57},
  year={2017}
}

@inproceedings{carlini2017detecting,
  title={Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={ACM Workshop on Artificial Intelligence and Security},
  pages={3--14},
  year={2017}
}

% -----------------------------------------------------------------------------
% DEFENSES
% -----------------------------------------------------------------------------
@inproceedings{papernot2016distillation,
  title={Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={IEEE Symposium on Security and Privacy},
  pages={582--597},
  year={2016}
}

@inproceedings{tramer2017ensemble,
  title={Ensemble Adversarial Training: Attacks and Defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Boneh, Dan and McDaniel, Patrick},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{li2020sok,
  title={{SoK}: Certified Robustness for Deep Neural Networks},
  author={Li, Linyi and Xie, Tao and Li, Bo},
  booktitle={IEEE Symposium on Security and Privacy},
  year={2023}
}

% -----------------------------------------------------------------------------
% PRIVACY ATTACKS
% -----------------------------------------------------------------------------
@inproceedings{ye2021enhanced,
  title={Enhanced Membership Inference Attacks Against Machine Learning Models},
  author={Ye, Jiayuan and Maddi, Aadyaa and Murakonda, Sasi Kumar and Bindschaedler, Vincent and Shokri, Reza},
  booktitle={ACM Conference on Computer and Communications Security},
  pages={3093--3106},
  year={2022}
}

% -----------------------------------------------------------------------------
% TRAINING TIME ATTACKS
% -----------------------------------------------------------------------------
@article{jia2021badencoder,
  title={{BadEncoder}: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning},
  author={Jia, Jinyuan and Liu, Yupei and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2108.00352},
  year={2021}
}

@inproceedings{tao2024distribution,
  title={Distribution Preserving Backdoor Attack in Self-Supervised Learning},
  author={Tao, Guanhong and Wang, Zhenting and Feng, Shiwei and Shen, Guangyu and Ma, Shiqing and Zhang, Xiangyu},
  booktitle={IEEE Symposium on Security and Privacy},
  year={2024}
}

@inproceedings{tramer2022truth,
  title={Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets},
  author={Tram{\`e}r, Florian and Shokri, Reza and Joaquin, Ayrton San and Le, Hoang Manh and Jagielski, Matthew and Hong, Sanghyun and Carlini, Nicholas},
  booktitle={ACM Conference on Computer and Communications Security},
  pages={2779--2792},
  year={2022}
}

% -----------------------------------------------------------------------------
% PHYSICAL WORLD ATTACKS
% -----------------------------------------------------------------------------
@inproceedings{kurakin2016adversarial,
  title={Adversarial Examples in the Physical World},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  booktitle={International Conference on Learning Representations Workshop},
  year={2017}
}

% -----------------------------------------------------------------------------
% INDUSTRY PERSPECTIVES
% -----------------------------------------------------------------------------



@techreport{nist2023airisk,
  title        = {{Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations}},
  author       = {Vassilev, Apostol and Oprea, Alina and Fordyce, Alie and Anderson, Hyrum},
  institution  = {National Institute of Standards and Technology},
  number       = {NIST AI 100-2e2023},
  year         = {2023},
  url          = {https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf}
}

@misc{mitre2024atlas,
  title        = {{MITRE ATLAS: Adversarial Threat Landscape for Artificial-Intelligence Systems}},
  author       = {{MITRE Corporation}},
  year         = {2024},
  url          = {https://atlas.mitre.org},
  note         = {Accessed: 2025-01-12}
}

@inproceedings{nassi2024comworm,
  title        = {{ComWorm: A Generative AI-Powered Worm}},
  author       = {Nassi, Ben and Mirsky, Yisroel and Elovici, Yuval},
  booktitle    = {Proceedings of the IEEE Symposium on Security and Privacy (S\&P)},
  year         = {2024}
}

@inproceedings{croce2020autoattack,
  title        = {{Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-Free Attacks}},
  author       = {Croce, Francesco and Hein, Matthias},
  booktitle    = {Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year         = {2020}
}

@article{croce2021robustbench,
  title        = {{RobustBench: A Standardized Adversarial Robustness Benchmark}},
  author       = {Croce, Francesco and Andriushchenko, Maksym and Sehwag, Vikash and Debenedetti, Edoardo and Flammarion, Nicolas and Chiang, Mung and Mittal, Prateek and Hein, Matthias},
  journal      = {Datasets and Benchmarks Track, NeurIPS},
  year         = {2021}
}

@inproceedings{mazeika2024harmbench,
  title        = {{HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}},
  author       = {Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and Forsyth, David and Hendrycks, Dan},
  booktitle    = {arXiv preprint arXiv:2402.04249},
  year         = {2024}
}

@inproceedings{chao2024jailbreakbench,
  title        = {{JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models}},
  author       = {Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Kolter, J. Zico and Bai, Kai and others},
  booktitle    = {arXiv preprint arXiv:2404.01318},
  year         = {2024}
}

@misc{anthropic2024modelevals,
  title        = {{Claude Model Evaluations}},
  author       = {{Anthropic}},
  year         = {2024},
  url          = {https://www.anthropic.com/research},
  note         = {Technical report}
}

@inproceedings{schulhoff2024satmlctf,
  title        = {{The SaTML '24 CNN Classifier Backdoor and LLM Prompt Injection Competitions}},
  author       = {Schulhoff, Sander and Wen, Chenlu and Parekh, Yuvraj and Mu, Norman and Hendrycks, Dan},
  booktitle    = {SaTML 2024 Workshop},
  year         = {2024}
}

@inproceedings{pierazzi2020intriguing,
  title        = {{Intriguing Properties of Adversarial ML Attacks in the Problem Space}},
  author       = {Pierazzi, Fabio and Pendlebury, Feargus and Cortellazzi, Jacopo and Cavallaro, Lorenzo},
  booktitle    = {Proceedings of the IEEE Symposium on Security and Privacy (S\&P)},
  pages        = {1332--1349},
  year         = {2020}
}

@article{pineau2021reforms,
  title        = {{Improving Reproducibility in Machine Learning Research}},
  author       = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Larivi{\`e}re, Vincent and Beygelzimer, Alina and d'Alch{\'e}-Buc, Florence and Fox, Emily and Larochelle, Hugo},
  journal      = {Journal of Machine Learning Research},
  volume       = {22},
  number       = {164},
  pages        = {1--20},
  year         = {2021}
}

@misc{usenix2025artifacts,
  title        = {{USENIX Security '25 Call for Artifacts}},
  author       = {{USENIX}},
  year         = {2025},
  url          = {https://www.usenix.org/conference/usenixsecurity25/call-for-artifacts}
}

@misc{satml2025cfp,
  title        = {{IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2025 Call for Papers}},
  author       = {{IEEE SaTML}},
  year         = {2025},
  url          = {https://satml.org/participate-cfp/}
}

@inproceedings{aisec2024,
  title        = {{Proceedings of the 17th ACM Workshop on Artificial Intelligence and Security}},
  booktitle    = {AISec '24},
  year         = {2024},
  publisher    = {ACM}
}

@misc{microsoft2024pyrit,
  title        = {{PyRIT: Python Risk Identification Toolkit for Generative AI}},
  author       = {{Microsoft Security Response Center}},
  year         = {2024},
  url          = {https://github.com/Azure/PyRIT}
}

@misc{anthropic2024redteam,
  title        = {{Anthropic Red Teaming Methodology}},
  author       = {{Anthropic}},
  year         = {2024},
  url          = {https://www.anthropic.com/news/frontier-red-team}
}

@techreport{google2024saif,
  title        = {{Secure AI Framework (SAIF)}},
  author       = {{Google Cloud}},
  year         = {2024},
  url          = {https://saif.google/secure-ai-framework}
}

@misc{owasp2025llmtop10,
  title        = {{OWASP Top 10 for Large Language Model Applications v2.0}},
  author       = {{OWASP Foundation}},
  year         = {2025},
  url          = {https://genai.owasp.org/}
}

@misc{owasp2025agentic,
  title        = {{OWASP Top 10 for Agentic AI Security}},
  author       = {{OWASP GenAI Security Project}},
  year         = {2025},
  url          = {https://genai.owasp.org/2025/12/09/owasp-genai-security-project-releases-top-10-risks-and-mitigations-for-agentic-ai-security/}
}

@article{harang2024promptinjection,
  title        = {{Defending Against Prompt Injection Attacks Through Isolation and Defense in Depth}},
  author       = {Harang, Richard and Debar, Herv{\'e}},
  journal      = {arXiv preprint arXiv:2507.13169},
  year         = {2024}
}

@misc{promptfoo2024harmbench,
  title        = {{Promptfoo: LLM Evaluation and Red Teaming Framework}},
  author       = {{Promptfoo}},
  year         = {2024},
  url          = {https://www.promptfoo.dev/}
}

@misc{deepeval2024,
  title        = {{DeepEval: The LLM Evaluation Framework}},
  author       = {{Confident AI}},
  year         = {2024},
  url          = {https://github.com/confident-ai/deepeval}
}

@misc{anthropic2024adaptive,
  title        = {{Many-Shot Jailbreaking}},
  author       = {Anil, Cem and Deutsch, Daniel and Perez, Ethan and others},
  year         = {2024},
  howpublished = {Anthropic Technical Report}
}

@misc{cosai2024,
  title        = {{Coalition for Secure AI (CoSAI)}},
  author       = {{OASIS Open}},
  year         = {2024},
  url          = {https://oasis-open.org/coalitions/secure-ai/}
}

@misc{darpa2024gard,
  title        = {{DARPA GARD: Guaranteeing AI Robustness Against Deception}},
  author       = {{DARPA}},
  year         = {2024},
  url          = {https://www.darpa.mil/research/programs/guaranteeing-ai-robustness-against-deception}
}

@misc{darpa2024saber,
  title        = {{DARPA SABER: Securing Artificial Intelligence for Battlefield Effective Robustness}},
  author       = {{DARPA}},
  year         = {2024},
  url          = {https://www.darpa.mil/research/programs/saber-securing-artificial-intelligence}
}

@misc{nsf2022aiinstitutes,
  title        = {{NSF National Artificial Intelligence Research Institutes Program Solicitation}},
  author       = {{National Science Foundation}},
  number       = {NSF 22-502},
  year         = {2022}
}

@misc{nist2024dioptra,
  title        = {{Dioptra: A Software Engineering Approach to Machine Learning Security Testbed}},
  author       = {{NIST}},
  year         = {2024},
  url          = {https://pages.nist.gov/dioptra/}
}

@misc{ukaisafety2024grants,
  title        = {{UK AI Safety Institute Systemic Safety Grants Programme}},
  author       = {{UK AI Safety Institute}},
  year         = {2024},
  url          = {https://www.gov.uk/government/news/research-programme-to-ensure-uk-economy-uses-ai-to-grow-safely}
}

@misc{sphere2024,
  title        = {{SPHERE: Enabling Reproducibility through Research Infrastructure}},
  author       = {{SPHERE Consortium}},
  year         = {2024},
  url          = {https://www.ndss-symposium.org/wp-content/uploads/2025-poster-31.pdf}
}

@article{yu2025humanfactors,
  title        = {{Position: Human Factors Reshape Adversarial Analysis in Human-AI Decision-Making Systems}},
  author       = {Yu, Jinghan and Yang, Yang and Huang, Xiaozhuan and others},
  journal      = {arXiv preprint arXiv:2509.21436},
  year         = {2025}
}

@article{grosse2024economics,
  title        = {{On the Economics of Adversarial Machine Learning}},
  author       = {Grosse, Kathrin and Terzis, Sotirios and Chothia, Tom and Smith, Matthew},
  journal      = {IEEE Transactions on Dependable and Secure Computing},
  year         = {2024},
  doi          = {10.1109/TDSC.2024.3376499}
}

@article{xu2025agentsurvey,
  title        = {{A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends}},
  author       = {Xu, Daizong and Parhi, Keshab K.},
  journal      = {arXiv preprint arXiv:2407.07403},
  year         = {2025}
}

@misc{euaiact2024,
  title        = {{Regulation (EU) 2024/1689 of the European Parliament and of the Council on Artificial Intelligence (AI Act)}},
  author       = {{European Parliament and Council}},
  year         = {2024},
  url          = {https://artificialintelligenceact.eu/}
}

@misc{nist2024cosais,
  title        = {{NIST COSAIS: Control Overlays for Securing AI Systems}},
  author       = {{NIST}},
  year         = {2024},
  note         = {Public draft forthcoming FY2026}
}